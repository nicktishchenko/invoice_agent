{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35da08",
   "metadata": {},
   "source": [
    "# AI Agent for Invoice Processing with RAG + Local LLM (Ollama)\n",
    "\n",
    "This notebook implements a **Complete Invoice Processing Pipeline** using **RAG (Retrieval-Augmented Generation)** with local Ollama models.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook performs two main functions:\n",
    "1. **Rule Extraction** - Extracts invoice processing rules from contract documents using RAG\n",
    "2. **Invoice Processing** - Processes invoices against extracted rules with intelligent validation\n",
    "\n",
    "**Version:** 2.0 - RAG Edition  \n",
    "**Author:** r4 Technologies, Inc 2025\n",
    "\n",
    "## Key Features:\n",
    "- **RAG Architecture** - Retrieval-Augmented Generation for context-aware rule extraction\n",
    "- **Local LLM** - Ollama gemma3:270m (no API keys needed)\n",
    "- **Vector Store** - FAISS for fast semantic search\n",
    "- **Document Processing** - Supports PDF, DOCX, and scanned images (OCR)\n",
    "- **Invoice Validation** - Rule-based compliance checking with detailed reporting\n",
    "- **Automatic Setup** - Auto-generates sample documents if needed\n",
    "- **Cross-Platform** - Works on Windows, Mac, and Linux\n",
    "\n",
    "## Notebook Structure:\n",
    "- **Cells 1-4:** Documentation and setup requirements\n",
    "- **Cells 5-6:** Package installation (document processing + RAG packages)\n",
    "- **Cell 7:** Import all required packages\n",
    "- **Cell 8:** Check and auto-generate sample documents if needed\n",
    "- **Cell 9:** Test Ollama connection and initialize models\n",
    "- **Cells 10-13:** Helper functions and RAG agent class definition\n",
    "- **Cells 14-18:** Part 1 - Rule extraction from contracts\n",
    "- **Cells 19-25:** Part 2 - Invoice processing and validation\n",
    "- **Cells 26-33:** Complete pipeline test and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2ae9",
   "metadata": {},
   "source": [
    "## Quick Start Guide\n",
    "\n",
    "### Execution Order:\n",
    "\n",
    "1. **Run Cells 5-6:** Install all required packages\n",
    "2. **Run Cell 7:** Import all libraries\n",
    "3. **Run Cell 8:** Check for sample documents (auto-generates if missing)\n",
    "4. **Run Cell 9:** Test Ollama connection (requires Ollama running)\n",
    "5. **Run Cells 14-18:** Extract rules from contract documents\n",
    "6. **Run Cells 19-25:** Process invoices using extracted rules\n",
    "7. **Run Cell 29:** Complete pipeline test (extract rules + process invoices)\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- **Python 3.10+**\n",
    "- **Ollama** installed and running (https://ollama.ai)\n",
    "- **Tesseract OCR** binary (for scanned document processing)\n",
    "- Required Ollama models:\n",
    "  ```bash\n",
    "  ollama pull gemma3:270m\n",
    "  ollama pull nomic-embed-text\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc30410",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "### Python Dependencies\n",
    "All dependencies are installed automatically by running the installation cells:\n",
    "\n",
    "- **Cell 5:** Document processing packages\n",
    "  - pdfplumber (PDF parsing)\n",
    "  - python-docx (Word document parsing)\n",
    "  - Pillow (image processing)\n",
    "  - reportlab (PDF generation)\n",
    "  - matplotlib (visualization)\n",
    "\n",
    "- **Cell 6:** RAG and ML packages\n",
    "  - langchain-core, langchain-community, langchain\n",
    "  - langchain-ollama (Ollama integration)\n",
    "  - faiss-cpu (vector store)\n",
    "  - pytesseract (OCR wrapper)\n",
    "  - numpy, pydantic, ipywidgets\n",
    "\n",
    "### External Dependencies\n",
    "\n",
    "**Tesseract OCR Binary** (required for scanned documents):\n",
    "- **macOS:** `brew install tesseract`\n",
    "- **Linux:** `sudo apt-get install tesseract-ocr`\n",
    "- **Windows:** Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
    "\n",
    "**Ollama** (required for local LLM):\n",
    "- Download and install from https://ollama.ai\n",
    "- Pull required models (see Cell 9 for instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6392028",
   "metadata": {},
   "source": [
    "## RAG Setup Requirements\n",
    "\n",
    "### Required Packages\n",
    "All RAG packages are installed automatically in **Cell 6**. The notebook uses:\n",
    "- LangChain framework for RAG orchestration\n",
    "- FAISS vector store for semantic search\n",
    "- Ollama for local LLM processing (no API keys needed)\n",
    "\n",
    "### Ollama Models\n",
    "Make sure Ollama is running and you have the required models:\n",
    "\n",
    "```bash\n",
    "# Pull the LLM model (for rule extraction)\n",
    "ollama pull gemma3:270m\n",
    "\n",
    "# Pull the embedding model (for vector search)\n",
    "ollama pull nomic-embed-text\n",
    "```\n",
    "\n",
    "**Note:** Cell 9 will test the Ollama connection and verify these models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81bc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Document processing packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Install document processing packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Platform-independent pip installation\n",
    "result = subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"pdfplumber\",\n",
    "        \"python-docx\",\n",
    "        \"Pillow\",\n",
    "        \"reportlab\",\n",
    "        \"matplotlib\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(\"[OK] Document processing packages installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38b3614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All packages installed with numpy 1.26.4\n",
      "[OK] pytesseract installed (lightweight OCR)\n",
      "[OK] No dependency conflicts!\n",
      "\n",
      "[INFO] OCR Note: pytesseract requires Tesseract binary to be installed:\n",
      "  - macOS: brew install tesseract\n",
      "  - Linux: sudo apt-get install tesseract-ocr\n",
      "  - Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
      "\n",
      "Make sure Ollama is running with models:\n",
      "  ollama pull gemma3:270m\n",
      "  ollama pull nomic-embed-text\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Install RAG packages (with pytesseract - stable and lightweight)\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Install core packages with numpy constraint\n",
    "subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"numpy==1.26.4\",\n",
    "        \"pdfplumber\",\n",
    "        \"Pillow\",\n",
    "        \"matplotlib\",\n",
    "        \"python-docx\",\n",
    "        \"reportlab\",\n",
    "        \"langchain-core==0.3.6\",\n",
    "        \"langchain-community==0.3.1\",\n",
    "        \"langchain==0.3.1\",\n",
    "        \"langchain-ollama==0.2.0\",\n",
    "        \"faiss-cpu\",\n",
    "        \"ipywidgets\",\n",
    "        \"pydantic==2.9.2\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "# Install pytesseract (lightweight, uses external Tesseract binary)\n",
    "subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"pytesseract\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(\"[OK] All packages installed with numpy 1.26.4\")\n",
    "print(\"[OK] pytesseract installed (lightweight OCR)\")\n",
    "print(\"[OK] No dependency conflicts!\")\n",
    "print(\"\\n[INFO] OCR Note: pytesseract requires Tesseract binary to be installed:\")\n",
    "print(\"  - macOS: brew install tesseract\")\n",
    "print(\"  - Linux: sudo apt-get install tesseract-ocr\")\n",
    "print(\"  - Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\")\n",
    "print(\"\\nMake sure Ollama is running with models:\")\n",
    "print(\"  ollama pull gemma3:270m\")\n",
    "print(\"  ollama pull nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3027e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All packages imported successfully\n",
      "Platform: Darwin\n",
      "[APPLE] Detected: Apple Silicon (ARM64)\n",
      "[OK] Environment configured - Using pytesseract for image processing\n"
     ]
    }
   ],
   "source": [
    "# Import all required packages\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from collections import Counter\n",
    "from contextlib import redirect_stderr\n",
    "import multiprocessing\n",
    "\n",
    "# Document processing\n",
    "import pdfplumber  # For PDF parsing\n",
    "from docx import Document  # For Word (.docx) parsing\n",
    "from PIL import Image, ImageEnhance  # For image processing\n",
    "\n",
    "# RAG and ML\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document as LangchainDocument\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"[OK] All packages imported successfully\")\n",
    "\n",
    "# Cell 7: Configure environment variables + Platform-specific settings\n",
    "import os\n",
    "import warnings\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Detect platform\n",
    "PLATFORM = platform.system()  # 'Darwin' (Mac), 'Windows', 'Linux'\n",
    "IS_MAC = PLATFORM == \"Darwin\"\n",
    "IS_WINDOWS = PLATFORM == \"Windows\"\n",
    "IS_APPLE_SILICON = IS_MAC and platform.machine() == \"arm64\"\n",
    "\n",
    "print(f\"Platform: {PLATFORM}\")\n",
    "if IS_APPLE_SILICON:\n",
    "    print(\"[APPLE] Detected: Apple Silicon (ARM64)\")\n",
    "elif IS_MAC:\n",
    "    print(\"[APPLE] Detected: macOS (Intel)\")\n",
    "elif IS_WINDOWS:\n",
    "    print(\"[WIN] Detected: Windows\")\n",
    "\n",
    "# Environment variables (cross-platform)\n",
    "os.environ[\"USER_AGENT\"] = \"InvoiceProcessingRAGAgent\"\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "print(\"[OK] Environment configured - Using pytesseract for image processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b6f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents already exist. Skipping generation.\n",
      "  Contracts: 5 files\n",
      "  Invoices: 10 files\n"
     ]
    }
   ],
   "source": [
    "# Check if sample documents exist, generate if needed\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Define directories\n",
    "data_dir = Path(\"docs\")\n",
    "contracts_dir = data_dir / \"contracts\"\n",
    "invoices_dir = data_dir / \"invoices\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "contracts_dir.mkdir(parents=True, exist_ok=True)\n",
    "invoices_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if directories contain any files\n",
    "contracts_has_files = any(f.is_file() for f in contracts_dir.iterdir())\n",
    "invoices_has_files = any(f.is_file() for f in invoices_dir.iterdir())\n",
    "\n",
    "if not contracts_has_files or not invoices_has_files:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Sample documents not found. Generating sample documents...\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nRunning Generate_Sample_Documents.ipynb...\")\n",
    "    \n",
    "    # Execute the generation notebook using nbconvert\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"jupyter\", \"nbconvert\", \"--to\", \"notebook\", \"--execute\", \"--inplace\", \"Generate_Sample_Documents.ipynb\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=Path.cwd()\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n[OK] Sample documents generated successfully!\")\n",
    "        else:\n",
    "            print(f\"\\n[ERROR] Failed to generate documents.\")\n",
    "            print(f\"Error: {result.stderr[:500] if result.stderr else 'Unknown error'}\")\n",
    "            print(\"\\nPlease run Generate_Sample_Documents.ipynb manually.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[WARN] Could not auto-generate documents: {e}\")\n",
    "        print(\"\\nPlease run Generate_Sample_Documents.ipynb manually.\")\n",
    "else:\n",
    "    print(\"Sample documents already exist. Skipping generation.\")\n",
    "    print(f\"  Contracts: {len(list(contracts_dir.glob('*.*')))} files\")\n",
    "    print(f\"  Invoices: {len(list(invoices_dir.glob('*.*')))} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3d17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All libraries imported successfully (Standard + RAG components)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Import necessary libraries (Standard + RAG)\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from multiprocessing import Manager\n",
    "from datetime import datetime, timedelta\n",
    "from contextlib import redirect_stderr\n",
    "\n",
    "import pdfplumber  # For PDF parsing\n",
    "from docx import Document  # For Word (.docx) parsing\n",
    "from PIL import ImageEnhance  # For contrast enhancement in scanned PDFs\n",
    "\n",
    "# RAG imports\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document as LangchainDocument\n",
    "\n",
    "# Set up logging (prevent duplicate handlers when re-running cells)\n",
    "# Clear any existing handlers to prevent duplicates\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"[OK] All libraries imported successfully (Standard + RAG components)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3d17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:00,891 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama embeddings...\n",
      "[OK] Ollama embeddings working (nomic-embed-text)\n",
      "Testing Ollama LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:01,011 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Ollama LLM working (gemma3:270m)\n",
      "\n",
      "[OK] All Ollama models ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Test Ollama connection and initialize models (cross-platform)\n",
    "\n",
    "try:\n",
    "    # Test embeddings (suppress noise output)\n",
    "    print(\"Testing Ollama embeddings...\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        test_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        test_embedding.embed_query(\"test\")\n",
    "    print(\"[OK] Ollama embeddings working (nomic-embed-text)\")\n",
    "\n",
    "    # Initialize LLM with response length limit for faster generation\n",
    "    print(\"Testing Ollama LLM...\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        llm = ChatOllama(\n",
    "            model=\"gemma3:270m\",\n",
    "            temperature=0,\n",
    "            num_predict=100,  # Limit response length for speed\n",
    "        )\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "    print(\"[OK] Ollama LLM working (gemma3:270m)\")\n",
    "\n",
    "    # Initialize embeddings for later use\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "    print(\"\\n[OK] All Ollama models ready!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Ollama error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Make sure Ollama is running:\")\n",
    "    if IS_WINDOWS:\n",
    "        print(\"     - Windows: Check system tray for Ollama icon\")\n",
    "        print(\"     - Or run: ollama serve\")\n",
    "    elif IS_MAC:\n",
    "        print(\"     - Mac: Check menu bar for Ollama icon\")\n",
    "        print(\"     - Or run: ollama serve\")\n",
    "\n",
    "    print(\"\\n  2. Pull required models:\")\n",
    "    print(\"     ollama pull gemma3:270m\")\n",
    "    print(\"     ollama pull nomic-embed-text\")\n",
    "\n",
    "    print(\"\\n  3. Verify Ollama is accessible:\")\n",
    "    print(\"     ollama list\")\n",
    "\n",
    "    if IS_APPLE_SILICON:\n",
    "        print(\"\\n  4. Apple Silicon specific:\")\n",
    "        print(\"     - Make sure you have the ARM64 version of Ollama\")\n",
    "        print(\"     - Download from: https://ollama.ai/download\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee7af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Garbled text detection function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Helper function to detect garbled text\n",
    "\n",
    "\n",
    "def is_garbled_text(\n",
    "    text: str, non_alpha_threshold: float = 0.4, min_word_length: int = 3\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Detect if text is likely garbled (low-confidence OCR output).\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to check.\n",
    "        non_alpha_threshold (float): Max proportion of non-alphanumeric characters.\n",
    "        min_word_length (int): Minimum average word length to consider valid.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if text is likely garbled, False otherwise.\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return True\n",
    "\n",
    "    # Check proportion of non-alphanumeric characters\n",
    "    non_alpha_count = len(re.findall(r\"[^a-zA-Z0-9\\s]\", text))\n",
    "    if non_alpha_count / max(len(text), 1) > non_alpha_threshold:\n",
    "        return True\n",
    "\n",
    "    # Check average word length\n",
    "    words = [w for w in text.split() if w.strip()]\n",
    "    if not words:\n",
    "        return True\n",
    "    avg_word_length = sum(len(w) for w in words) / len(words)\n",
    "    if avg_word_length < min_word_length:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "print(\"[OK] Garbled text detection function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea1462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Invoice terms validation function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Helper function to validate invoice-related terms\n",
    "\n",
    "\n",
    "def validate_invoice_terms(text: str, min_terms: int = 2) -> bool:\n",
    "    \"\"\"\n",
    "    Validate if text contains enough invoice-related terms.\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to validate.\n",
    "        min_terms (int): Minimum number of invoice-related terms required.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if sufficient invoice-related terms are found, False otherwise.\n",
    "    \"\"\"\n",
    "    invoice_keywords = [\n",
    "        r\"\\bpayment\\b\",\n",
    "        r\"\\binvoice\\b\",\n",
    "        r\"\\bdue\\b\",\n",
    "        r\"\\bnet\\s*\\d+\\b\",\n",
    "        r\"\\bterms\\b\",\n",
    "        r\"\\bapproval\\b\",\n",
    "        r\"\\bpenalty\\b\",\n",
    "        r\"\\bPO\\s*number\\b\",\n",
    "        r\"\\btax\\b\",\n",
    "        r\"\\bbilling\\b\",\n",
    "    ]\n",
    "    found_terms = sum(\n",
    "        1 for keyword in invoice_keywords if re.search(keyword, text, re.IGNORECASE)\n",
    "    )\n",
    "    return found_terms >= min_terms\n",
    "\n",
    "\n",
    "print(\"[OK] Invoice terms validation function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985e5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InvoiceRuleExtractorAgent class defined with FAISS vector store\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: InvoiceRuleExtractorAgent class definition (RAG-powered with FAISS vector store)\n",
    "\n",
    "\n",
    "class InvoiceRuleExtractorAgent:\n",
    "    \"\"\"\n",
    "    AI Agent for extracting invoice processing rules from contract documents using RAG.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm=None, embeddings=None):\n",
    "        \"\"\"\n",
    "        Initialize the agent with RAG components.\n",
    "\n",
    "        Args:\n",
    "            llm: ChatOllama instance (defaults to gemma3:270m)\n",
    "            embeddings: OllamaEmbeddings instance (defaults to nomic-embed-text)\n",
    "        \"\"\"\n",
    "        logger.info(\"Initializing RAG-powered Invoice Rule Extractor Agent\")\n",
    "\n",
    "        # Use provided models or create defaults\n",
    "        # Set num_predict to limit response length (faster generation)\n",
    "        self.llm = (\n",
    "            llm\n",
    "            if llm\n",
    "            else ChatOllama(\n",
    "                model=\"gemma3:270m\",\n",
    "                temperature=0,\n",
    "                num_predict=100,  # Limit to ~100 tokens for faster responses\n",
    "            )\n",
    "        )\n",
    "        self.embeddings = (\n",
    "            embeddings if embeddings else OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        )\n",
    "\n",
    "        # Expanded keyword patterns for better matching\n",
    "        self.rule_keywords = [\n",
    "            \"payment\",\n",
    "            \"terms\",\n",
    "            \"due\",\n",
    "            \"net\",\n",
    "            \"days\",\n",
    "            \"invoice\",\n",
    "            \"approval\",\n",
    "            \"submission\",\n",
    "            \"requirement\",\n",
    "            \"late\",\n",
    "            \"fee\",\n",
    "            \"penalty\",\n",
    "            \"penalties\",\n",
    "            \"PO\",\n",
    "            \"purchase order\",\n",
    "            \"tax\",\n",
    "            \"dispute\",\n",
    "            \"month\",\n",
    "            \"overdue\",\n",
    "            \"rejection\",\n",
    "        ]\n",
    "\n",
    "        # RAG chain will be created after document parsing\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "        self.num_chunks = 0\n",
    "\n",
    "    def parse_document(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Parse the contract document (PDF or Word), extract text, and create vector store for RAG.\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Extract text from document\n",
    "            if file_path.suffix.lower() == \".pdf\":\n",
    "                logger.info(f\"Parsing PDF: {file_path}\")\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text + \"\\n\"\n",
    "                        else:\n",
    "                            # Use pytesseract for scanned pages\n",
    "                            import pytesseract\n",
    "                            import tempfile\n",
    "\n",
    "                            img = page.to_image().original\n",
    "                            # Optimize image for OCR\n",
    "                            img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                            img = ImageEnhance.Sharpness(img).enhance(1.5)\n",
    "\n",
    "                            # Save and process with tesseract\n",
    "                            with tempfile.NamedTemporaryFile(\n",
    "                                suffix=\".png\", delete=False\n",
    "                            ) as tmp:\n",
    "                                img.save(tmp.name, \"PNG\", optimize=True)\n",
    "                                try:\n",
    "                                    # Use optimized tesseract config\n",
    "                                    extracted_text = pytesseract.image_to_string(\n",
    "                                        tmp.name, config=\"--psm 6\"\n",
    "                                    )\n",
    "                                    if extracted_text.strip():\n",
    "                                        text += extracted_text + \"\\n\"\n",
    "                                except Exception as ocr_err:\n",
    "                                    logger.warning(f\"OCR failed for page: {ocr_err}\")\n",
    "                                finally:\n",
    "                                    Path(tmp.name).unlink()  # Clean up temp file\n",
    "\n",
    "            elif file_path.suffix.lower() == \".docx\":\n",
    "                logger.info(f\"Parsing Word doc: {file_path}\")\n",
    "                doc = Document(file_path)\n",
    "                for para in doc.paragraphs:\n",
    "                    if para.text.strip():\n",
    "                        text += para.text + \"\\n\"\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unsupported file format: {file_path.suffix}. Use PDF or DOCX.\"\n",
    "                )\n",
    "\n",
    "            if not text.strip():\n",
    "                raise ValueError(\n",
    "                    \"No text extracted from document. Check scan quality or OCR setup.\"\n",
    "                )\n",
    "\n",
    "            logger.info(f\"Successfully parsed {len(text)} characters.\")\n",
    "\n",
    "            # Create document chunks for RAG\n",
    "            logger.info(\"Creating vector store for RAG...\")\n",
    "            self._create_vectorstore(text)\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing document: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _create_vectorstore(self, text: str):\n",
    "        \"\"\"Create vector store from document text using FAISS.\"\"\"\n",
    "        from langchain_community.vectorstores import FAISS\n",
    "\n",
    "        # Create a document object\n",
    "        doc = LangchainDocument(page_content=text, metadata={\"source\": \"contract\"})\n",
    "\n",
    "        # Split document into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        self.num_chunks = len(splits)\n",
    "        logger.info(f\"Created {self.num_chunks} document chunks\")\n",
    "\n",
    "        # Create FAISS vector store (fast and reliable)\n",
    "        try:\n",
    "            with redirect_stderr(io.StringIO()):\n",
    "                self.vectorstore = FAISS.from_documents(\n",
    "                    documents=splits, embedding=self.embeddings\n",
    "                )\n",
    "            logger.info(\"[OK] Vector store created with FAISS\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to create FAISS vector store: {str(e)}\")\n",
    "\n",
    "        # Adaptive k: use min(3, num_chunks)\n",
    "        k_value = min(3, self.num_chunks)\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": k_value})\n",
    "        logger.info(\n",
    "            f\"Vector store created successfully (retrieving top {k_value} chunks)\"\n",
    "        )\n",
    "\n",
    "    def extract_rules(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Use RAG to extract invoice-related rules from the document.\n",
    "        \"\"\"\n",
    "        logger.info(\"Extracting rules using RAG...\")\n",
    "\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\n",
    "                \"Vector store not initialized. Call parse_document() first.\"\n",
    "            )\n",
    "\n",
    "        # Create RAG chain\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Extract invoice processing rules from this contract.\n",
    "\n",
    "Contract text:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer concisely with key details only (1-2 sentences). If not found, say \"Not specified\".\"\"\"\n",
    "        )\n",
    "\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Simplified questions for faster extraction\n",
    "        questions = {\n",
    "            \"payment_terms\": \"What are the payment terms (Net days, PO requirements)?\",\n",
    "            \"approval_process\": \"What is the invoice approval process?\",\n",
    "            \"late_penalties\": \"What are the late payment penalties?\",\n",
    "            \"submission_requirements\": \"What must be included on every invoice?\",\n",
    "        }\n",
    "\n",
    "        raw_rules = {}\n",
    "        for key, question in questions.items():\n",
    "            try:\n",
    "                with redirect_stderr(io.StringIO()):\n",
    "                    answer = rag_chain.invoke(question)\n",
    "\n",
    "                # Accept answer if it has substance\n",
    "                if (\n",
    "                    answer\n",
    "                    and len(answer.strip()) > 15\n",
    "                    and \"not specified\" not in answer.lower()\n",
    "                ):\n",
    "                    raw_rules[key] = answer.strip()\n",
    "                    logger.info(f\"Extracted {key}: {answer[:100]}...\")\n",
    "                else:\n",
    "                    raw_rules[key] = \"Not found\"\n",
    "                    logger.warning(f\"Rule {key} not found in contract\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error extracting {key}: {e}\")\n",
    "                raw_rules[key] = \"Not found\"\n",
    "\n",
    "        return raw_rules\n",
    "\n",
    "    def refine_rules(self, raw_rules: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Refine and structure the raw rules into a standardized format.\n",
    "        \"\"\"\n",
    "        logger.info(\"Refining rules...\")\n",
    "        structured_rules = []\n",
    "        rule_mapping = {\n",
    "            \"payment_terms\": {\"type\": \"payment_term\", \"priority\": \"high\"},\n",
    "            \"approval_process\": {\"type\": \"approval\", \"priority\": \"medium\"},\n",
    "            \"late_penalties\": {\"type\": \"penalty\", \"priority\": \"high\"},\n",
    "            \"submission_requirements\": {\"type\": \"submission\", \"priority\": \"medium\"},\n",
    "        }\n",
    "\n",
    "        for key, description in raw_rules.items():\n",
    "            if key in rule_mapping and description != \"Not found\":\n",
    "                # Accept if content is substantial (>15 chars)\n",
    "                if len(description.strip()) > 15:\n",
    "                    rule = {\n",
    "                        \"rule_id\": key,\n",
    "                        \"type\": rule_mapping[key][\"type\"],\n",
    "                        \"description\": description.strip(),\n",
    "                        \"priority\": rule_mapping[key][\"priority\"],\n",
    "                        \"confidence\": \"medium\",\n",
    "                    }\n",
    "                    structured_rules.append(rule)\n",
    "                    logger.info(\n",
    "                        f\"[OK] Structured rule: {rule['type']} - {rule['description'][:60]}...\"\n",
    "                    )\n",
    "                else:\n",
    "                    logger.warning(f\"Rule {key} too short: '{description}'\")\n",
    "\n",
    "        return structured_rules\n",
    "\n",
    "    def run(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Main execution method for the agent.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = self.parse_document(file_path)\n",
    "            raw_rules = self.extract_rules(text)\n",
    "            refined_rules = self.refine_rules(raw_rules)\n",
    "            logger.info(f\"Extraction complete. Found {len(refined_rules)} rules.\")\n",
    "            return refined_rules\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Agent run failed: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "print(\"[OK] InvoiceRuleExtractorAgent class defined with FAISS vector store\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42712e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Rule Extraction with RAG\n",
    "\n",
    "This section extracts invoice processing rules from contract documents using RAG.\n",
    "\n",
    "### Workflow:\n",
    "1. **Cell 14:** Initialize the RAG-powered agent\n",
    "2. **Cell 15:** Process a contract document and extract rules\n",
    "3. **Cell 16:** Save extracted rules to JSON file (`extracted_rules.json`)\n",
    "4. **Cell 17:** Display extracted rules in formatted output\n",
    "\n",
    "### Input:\n",
    "- Contract documents (PDF, DOCX, or scanned images) in `docs/contracts/` directory\n",
    "\n",
    "### Output:\n",
    "- `extracted_rules.json` - Structured rules ready for invoice validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476f9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:01,100 - INFO - Initializing RAG-powered Invoice Rule Extractor Agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] RAG-powered Agent initialized successfully\n",
      "  - LLM: gemma3:270m\n",
      "  - Embeddings: nomic-embed-text\n",
      "  - Vector Store: FAISS\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Initialize the RAG-powered agent\n",
    "\n",
    "# Use the global llm and embeddings initialized earlier\n",
    "agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "print(\"[OK] RAG-powered Agent initialized successfully\")\n",
    "print(f\"  - LLM: gemma3:270m\")\n",
    "print(f\"  - Embeddings: nomic-embed-text\")\n",
    "print(f\"  - Vector Store: FAISS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ececbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:01,112 - INFO - Parsing PDF: docs/contracts/sample_contract_net30.pdf\n",
      "2025-11-06 18:05:01,129 - INFO - Successfully parsed 1171 characters.\n",
      "2025-11-06 18:05:01,130 - INFO - Creating vector store for RAG...\n",
      "2025-11-06 18:05:01,130 - INFO - Created 2 document chunks\n",
      "2025-11-06 18:05:01,178 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:01,181 - INFO - Loading faiss.\n",
      "2025-11-06 18:05:01,192 - INFO - Successfully loaded faiss.\n",
      "2025-11-06 18:05:01,195 - INFO - [OK] Vector store created with FAISS\n",
      "2025-11-06 18:05:01,196 - INFO - Vector store created successfully (retrieving top 2 chunks)\n",
      "2025-11-06 18:05:01,196 - INFO - Extracting rules using RAG...\n",
      "2025-11-06 18:05:01,218 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing contract: docs/contracts/sample_contract_net30.pdf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:01,438 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:01,503 - INFO - Extracted payment_terms: The payment terms are Net 30 days from invoice date and in monthly installments.\n",
      "...\n",
      "2025-11-06 18:05:01,521 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:01,709 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:01,760 - INFO - Extracted approval_process: The invoice approval process is to approve invoices by the Project Manager.\n",
      "...\n",
      "2025-11-06 18:05:01,777 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:01,966 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:02,028 - INFO - Extracted late_penalties: The late payment penalty is 1.5% per month on overdue balance.\n",
      "...\n",
      "2025-11-06 18:05:02,045 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:02,231 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 18:05:02,586 - INFO - Extracted submission_requirements: The invoice processing rules are:\n",
      "\n",
      "*   All invoices must include:\n",
      "    *   Valid PO number (format: P...\n",
      "2025-11-06 18:05:02,587 - INFO - Refining rules...\n",
      "2025-11-06 18:05:02,587 - INFO - [OK] Structured rule: payment_term - The payment terms are Net 30 days from invoice date and in m...\n",
      "2025-11-06 18:05:02,589 - INFO - [OK] Structured rule: approval - The invoice approval process is to approve invoices by the P...\n",
      "2025-11-06 18:05:02,590 - INFO - [OK] Structured rule: penalty - The late payment penalty is 1.5% per month on overdue balanc...\n",
      "2025-11-06 18:05:02,591 - INFO - [OK] Structured rule: submission - The invoice processing rules are:\n",
      "\n",
      "*   All invoices must inc...\n",
      "2025-11-06 18:05:02,591 - INFO - Extraction complete. Found 4 rules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Extracted 4 rules using RAG:\n",
      "============================================================\n",
      "[\n",
      "  {\n",
      "    \"rule_id\": \"payment_terms\",\n",
      "    \"type\": \"payment_term\",\n",
      "    \"description\": \"The payment terms are Net 30 days from invoice date and in monthly installments.\",\n",
      "    \"priority\": \"high\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"approval_process\",\n",
      "    \"type\": \"approval\",\n",
      "    \"description\": \"The invoice approval process is to approve invoices by the Project Manager.\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"late_penalties\",\n",
      "    \"type\": \"penalty\",\n",
      "    \"description\": \"The late payment penalty is 1.5% per month on overdue balance.\",\n",
      "    \"priority\": \"high\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"submission_requirements\",\n",
      "    \"type\": \"submission\",\n",
      "    \"description\": \"The invoice processing rules are:\\n\\n*   All invoices must include:\\n    *   Valid PO number (format: PO-YYYY-####)\\n    *   Detailed description of services\\n    *   Invoice date and due date\\n    *   Vendor tax identification number\\n*   Invoices must be approved by the Project Manager\\n*   Approval required within 5 business days\\n*   Finance department will process payment after approval\\n*   Penalties and fees\\n*   Late\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"confidence\": \"medium\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Process a contract document with RAG - WITH DIAGNOSTICS\n",
    "\n",
    "# Use sample contract or specify your own path\n",
    "file_path = \"docs/contracts/sample_contract_net30.pdf\"  # Change this to your file path\n",
    "\n",
    "try:\n",
    "    print(f\"Processing contract: {file_path}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Use the agent initialized in Cell 14 (faster - no re-initialization)\n",
    "    # Note: If you need a clean state, uncomment the line below:\n",
    "    # agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "\n",
    "    rules = agent.run(file_path)\n",
    "\n",
    "    print(f\"\\n[OK] Extracted {len(rules)} rules using RAG:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(rules, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] File not found: {file_path}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error: {e}\")\n",
    "    print(\"\\nCreating fallback rules...\")\n",
    "\n",
    "    # Provide manual fallback rules\n",
    "    print(\"\\n1. Creating fallback rules (manual extraction)...\")\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number, Detailed description of services\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"approval_process\",\n",
    "            \"type\": \"approval\",\n",
    "            \"description\": \"All invoices must be approved by the Project Manager within 5 business days. Finance department will process payment after approval.\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    print(f\"[OK] Created {len(rules)} fallback rules\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(json.dumps(rules, indent=2))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"[WARN] Using manually extracted rules due to error\")\n",
    "    print(\"NOTE: These fallback rules work fine for testing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde6ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Rules saved to extracted_rules.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Save extracted rules to JSON file\n",
    "\n",
    "output_file = \"extracted_rules.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "    print(f\"[OK] Rules saved to {output_file}\")\n",
    "except NameError:\n",
    "    print(\"[WARN] No rules to save. Run Cell 15 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a29ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTED INVOICE PROCESSING RULES\n",
      "============================================================\n",
      "\n",
      "[Rule 1]\n",
      "Type: payment_term\n",
      "Priority: high\n",
      "Description: The payment terms are Net 30 days from invoice date and in monthly installments.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 2]\n",
      "Type: approval\n",
      "Priority: medium\n",
      "Description: The invoice approval process is to approve invoices by the Project Manager.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 3]\n",
      "Type: penalty\n",
      "Priority: high\n",
      "Description: The late payment penalty is 1.5% per month on overdue balance.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 4]\n",
      "Type: submission\n",
      "Priority: medium\n",
      "Description: The invoice processing rules are:\n",
      "\n",
      "*   All invoices must include:\n",
      "    *   Valid PO number (format: PO-YYYY-####)\n",
      "    *   Detailed description of services\n",
      "    *   Invoice date and due date\n",
      "    *   Vendor tax identification number\n",
      "*   Invoices must be approved by the Project Manager\n",
      "*   Approval required within 5 business days\n",
      "*   Finance department will process payment after approval\n",
      "*   Penalties and fees\n",
      "*   Late\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Display extracted rules in a formatted way\n",
    "\n",
    "try:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXTRACTED INVOICE PROCESSING RULES\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        print(f\"\\n[Rule {i}]\")\n",
    "        print(f\"Type: {rule['type']}\")\n",
    "        print(f\"Priority: {rule['priority']}\")\n",
    "        print(f\"Description: {rule['description']}\")\n",
    "        print(f\"Confidence: {rule['confidence']}\")\n",
    "        print(\"-\" * 60)\n",
    "except NameError:\n",
    "    print(\"[WARN] No rules to display. Run Cell 15 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b95f48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Invoice Processor - Apply Extracted Rules\n",
    "\n",
    "This section processes invoices against the extracted rules.\n",
    "\n",
    "### Components:\n",
    "- **Cell 19:** InvoiceProcessor class definition\n",
    "- **Cell 21:** Initialize processor with extracted rules\n",
    "- **Cell 22:** Process a single invoice (optional - for testing/debugging)\n",
    "- **Cell 23:** Batch process all invoices (recommended for production use)\n",
    "- **Cell 24:** Generate processing report\n",
    "\n",
    "### When to use each:\n",
    "- **Cell 22 (Single Invoice):** Use for testing, debugging, or when you need to process just one specific invoice with detailed output\n",
    "- **Cell 23 (Batch Processing):** Use for production workflows - processes all invoices and generates summary statistics\n",
    "\n",
    "### Input:\n",
    "- Invoice documents (PDF, DOCX, PNG, JPG, TIFF, BMP) in `docs/invoices/` directory\n",
    "- `extracted_rules.json` (generated in Part 1)\n",
    "\n",
    "### Output:\n",
    "- Validation results (APPROVED/FLAGGED/REJECTED)\n",
    "- Detailed processing reports\n",
    "- JSON output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be90fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InvoiceProcessor class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Invoice Processor Class Definition\n",
    "\n",
    "\n",
    "class InvoiceProcessor:\n",
    "    \"\"\"\n",
    "    AI-powered Invoice Processor that applies extracted rules to validate invoices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules_file: str = \"extracted_rules.json\"):\n",
    "        \"\"\"\n",
    "        Initialize the processor with extracted rules.\n",
    "\n",
    "        Args:\n",
    "            rules_file: Path to JSON file with extracted rules\n",
    "        \"\"\"\n",
    "        self.rules = self._load_rules(rules_file)\n",
    "        self.payment_terms = self._extract_payment_terms()\n",
    "        logger.info(f\"Invoice Processor initialized with {len(self.rules)} rules\")\n",
    "\n",
    "    def _load_rules(self, rules_file: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Load extracted rules from JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(rules_file, \"r\") as f:\n",
    "                rules_data = json.load(f)\n",
    "                # Handle both old format (list) and new format (dict with metadata)\n",
    "                if isinstance(rules_data, dict) and \"rules\" in rules_data:\n",
    "                    rules = rules_data[\"rules\"]\n",
    "                else:\n",
    "                    rules = rules_data  # Old format - rules is a list\n",
    "            logger.info(f\"Loaded {len(rules)} rules from {rules_file}\")\n",
    "            return rules\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(f\"Rules file not found: {rules_file}. Using empty rules.\")\n",
    "            return []\n",
    "\n",
    "    def _extract_payment_terms(self) -> Optional[int]:\n",
    "        \"\"\"Extract net days from payment terms rule.\"\"\"\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"payment_term\":\n",
    "                description = rule.get(\"description\", \"\")\n",
    "                # Look for \"net 30\", \"net 60\", etc.\n",
    "                match = re.search(r\"net\\s*(\\d+)\", description, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    def parse_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse invoice document and extract key fields.\n",
    "\n",
    "        Args:\n",
    "            invoice_path: Path to invoice PDF/image\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with invoice data\n",
    "        \"\"\"\n",
    "        logger.info(f\"Parsing invoice: {invoice_path}\")\n",
    "        invoice_path = Path(invoice_path)\n",
    "\n",
    "        if not invoice_path.exists():\n",
    "            raise FileNotFoundError(f\"Invoice not found: {invoice_path}\")\n",
    "\n",
    "        # Extract text from invoice\n",
    "        text = \"\"\n",
    "\n",
    "        # Handle image files (PNG, JPG, JPEG, TIFF, BMP) with pytesseract\n",
    "        if invoice_path.suffix.lower() in [\".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\"]:\n",
    "            try:\n",
    "                import pytesseract\n",
    "                from PIL import Image, ImageEnhance\n",
    "\n",
    "                logger.info(f\"Using pytesseract for image file: {invoice_path.name}\")\n",
    "\n",
    "                # Load and optimize image for OCR\n",
    "                img = Image.open(invoice_path)\n",
    "\n",
    "                # Convert to RGB if needed\n",
    "                if img.mode != \"RGB\":\n",
    "                    img = img.convert(\"RGB\")\n",
    "\n",
    "                # Enhance image quality for better OCR\n",
    "                img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                img = ImageEnhance.Sharpness(img).enhance(1.5)\n",
    "\n",
    "                # Extract text using tesseract with optimized config\n",
    "                # --psm 6: Assume a single uniform block of text\n",
    "                # --oem 3: Use LSTM OCR Engine\n",
    "                text = pytesseract.image_to_string(img, config=\"--psm 6 --oem 3\")\n",
    "\n",
    "                logger.info(f\"pytesseract extracted {len(text)} characters\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"pytesseract extraction failed: {e}\")\n",
    "                logger.info(\"Make sure Tesseract is installed:\")\n",
    "                logger.info(\"  macOS: brew install tesseract\")\n",
    "                logger.info(\"  Linux: sudo apt-get install tesseract-ocr\")\n",
    "                text = \"\"\n",
    "\n",
    "        # Handle PDF files\n",
    "        elif invoice_path.suffix.lower() == \".pdf\":\n",
    "            with pdfplumber.open(invoice_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "\n",
    "        # Extract key invoice fields using regex patterns\n",
    "        invoice_data = {\n",
    "            \"file\": invoice_path.name,\n",
    "            \"invoice_number\": self._extract_field(\n",
    "                text, r\"invoice\\s*#\\s*:?\\s*([A-Z0-9-]+)\", \"Invoice Number\"\n",
    "            ),\n",
    "            \"po_number\": self._extract_field(\n",
    "                text, r\"po\\s*(?:number|#)?:?\\s*(PO-[\\w-]+)\", \"PO Number\"\n",
    "            ),\n",
    "            \"invoice_date\": self._extract_date(\n",
    "                text, r\"invoice\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"due_date\": self._extract_date(\n",
    "                text, r\"due\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"total_amount\": self._extract_amount(text),\n",
    "            \"vendor_name\": self._extract_vendor_name(text),\n",
    "            \"raw_text\": text[:500],  # First 500 chars for reference\n",
    "        }\n",
    "\n",
    "        return invoice_data\n",
    "\n",
    "    def _extract_field(self, text: str, pattern: str, field_name: str) -> Optional[str]:\n",
    "        \"\"\"Extract a field using regex pattern.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        logger.warning(f\"{field_name} not found in invoice\")\n",
    "        return None\n",
    "\n",
    "    def _extract_vendor_name(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract vendor name from invoice with multiple pattern attempts.\"\"\"\n",
    "        patterns = [\n",
    "            # Pattern 1: After \"INVOICE\" heading, capture text before \"Invoice #\"\n",
    "            r\"INVOICE\\s*\\n\\s*(.+?)\\s+Invoice\\s*#\",\n",
    "            # Pattern 2: \"From:\" line (common in some formats)\n",
    "            r\"from:?\\s*([^\\n]+)\",\n",
    "            # Pattern 3: First line containing \"Inc.\" or \"LLC\" or \"Ltd\" or \"Corp\"\n",
    "            r\"(?:^|\\n)([^\\n]*?(?:Inc\\.|LLC|Ltd\\.|Corp\\.|Corporation|Company)[^\\n]*?)(?:\\s+Invoice|$)\",\n",
    "            # Pattern 4: Text between INVOICE and first address/date line\n",
    "            r\"INVOICE\\s*\\n\\s*([^\\n]+?)(?:\\s+\\d{1,4}\\s|$)\",\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                vendor = match.group(1).strip()\n",
    "                # Clean up and validate\n",
    "                # Remove trailing text after company name indicators\n",
    "                vendor = re.sub(\n",
    "                    r\"\\s+(Invoice|Tax|PO|Date).*$\", \"\", vendor, flags=re.IGNORECASE\n",
    "                )\n",
    "                # Filter out invalid extractions\n",
    "                if (\n",
    "                    vendor\n",
    "                    and len(vendor) > 3\n",
    "                    and not vendor.lower().startswith(\"invoice\")\n",
    "                ):\n",
    "                    return vendor\n",
    "\n",
    "        logger.warning(\"Vendor not found in invoice\")\n",
    "        return None\n",
    "\n",
    "    def _extract_date(self, text: str, pattern: str) -> Optional[datetime]:\n",
    "        \"\"\"Extract and parse a date field.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            date_str = match.group(1)\n",
    "            # Try common date formats\n",
    "            for fmt in [\n",
    "                \"%m/%d/%Y\",\n",
    "                \"%d/%m/%Y\",\n",
    "                \"%m-%d-%Y\",\n",
    "                \"%d-%m-%Y\",\n",
    "                \"%m/%d/%y\",\n",
    "                \"%d/%m/%y\",\n",
    "            ]:\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, fmt)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def _extract_amount(self, text: str) -> Optional[float]:\n",
    "        \"\"\"Extract total amount from invoice.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:total\\s*amount\\s*due|total|amount\\s*due|balance\\s*due)[:\\s]*\\$\\s*([\\d,]+\\.?\\d*)\",\n",
    "            r\"\\$\\s*([\\d,]+\\.\\d{2})\\s*$\",  # Last dollar amount in text\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                amount_str = match.group(1).replace(\",\", \"\")\n",
    "                try:\n",
    "                    return float(amount_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def validate_invoice(self, invoice_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate invoice against extracted rules.\n",
    "\n",
    "        Args:\n",
    "            invoice_data: Parsed invoice data\n",
    "\n",
    "        Returns:\n",
    "            Validation result with status and issues\n",
    "        \"\"\"\n",
    "        logger.info(f\"Validating invoice: {invoice_data['file']}\")\n",
    "\n",
    "        issues = []\n",
    "        warnings = []\n",
    "\n",
    "        # Check for required fields based on submission requirements rule\n",
    "        required_fields = self._get_required_fields()\n",
    "        for field in required_fields:\n",
    "            if not invoice_data.get(field):\n",
    "                issue_msg = f\"Missing required field: {field}\"\n",
    "                issues.append(issue_msg)\n",
    "                # Print critical validation issues to stdout (bypasses logging suppression)\n",
    "                print(f\"[!] VALIDATION ISSUE: {invoice_data['file']} - {issue_msg}\")\n",
    "\n",
    "        # Validate payment terms\n",
    "        if (\n",
    "            self.payment_terms\n",
    "            and invoice_data.get(\"invoice_date\")\n",
    "            and invoice_data.get(\"due_date\")\n",
    "        ):\n",
    "            expected_due = invoice_data[\"invoice_date\"] + timedelta(\n",
    "                days=self.payment_terms\n",
    "            )\n",
    "            actual_due = invoice_data[\"due_date\"]\n",
    "\n",
    "            if abs((actual_due - expected_due).days) > 2:  # Allow 2-day tolerance\n",
    "                issue_msg = (\n",
    "                    f\"Due date mismatch: Expected {expected_due.strftime('%m/%d/%Y')}, \"\n",
    "                    f\"got {actual_due.strftime('%m/%d/%Y')} (Net {self.payment_terms} terms)\"\n",
    "                )\n",
    "                issues.append(issue_msg)\n",
    "                print(f\"[!] VALIDATION ISSUE: {invoice_data['file']} - {issue_msg}\")\n",
    "\n",
    "        # Check if invoice is overdue\n",
    "        if invoice_data.get(\"due_date\"):\n",
    "            if invoice_data[\"due_date\"] < datetime.now():\n",
    "                days_overdue = (datetime.now() - invoice_data[\"due_date\"]).days\n",
    "                warnings.append(f\"Invoice is {days_overdue} days overdue\")\n",
    "\n",
    "                # Check for late penalties\n",
    "                penalty_rule = self._get_penalty_rule()\n",
    "                if penalty_rule:\n",
    "                    warnings.append(f\"Late penalty may apply: {penalty_rule}\")\n",
    "\n",
    "        # Determine approval status\n",
    "        if issues:\n",
    "            status = \"REJECTED\"\n",
    "            action = \"Manual review required\"\n",
    "        elif warnings:\n",
    "            status = \"FLAGGED\"\n",
    "            action = \"Review recommended\"\n",
    "        else:\n",
    "            status = \"APPROVED\"\n",
    "            action = \"Auto-approved for payment\"\n",
    "\n",
    "        result = {\n",
    "            \"invoice_file\": invoice_data[\"file\"],\n",
    "            \"invoice_number\": invoice_data.get(\"invoice_number\"),\n",
    "            \"status\": status,\n",
    "            \"action\": action,\n",
    "            \"issues\": issues,\n",
    "            \"warnings\": warnings,\n",
    "            \"invoice_data\": invoice_data,\n",
    "            \"validation_timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Validation complete: {status}\")\n",
    "        return result\n",
    "\n",
    "    def _get_required_fields(self) -> List[str]:\n",
    "        \"\"\"Extract required fields from submission requirements rule.\"\"\"\n",
    "        # Core required fields for any valid invoice\n",
    "        required = [\"invoice_number\", \"invoice_date\", \"total_amount\", \"vendor_name\"]\n",
    "\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"submission\":\n",
    "                description = rule.get(\"description\", \"\").lower()\n",
    "                if \"po\" in description or \"purchase order\" in description:\n",
    "                    required.append(\"po_number\")\n",
    "\n",
    "        return required\n",
    "\n",
    "    def _get_penalty_rule(self) -> Optional[str]:\n",
    "        \"\"\"Get late payment penalty description.\"\"\"\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"penalty\":\n",
    "                return rule.get(\"description\")\n",
    "        return None\n",
    "\n",
    "    def process_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete invoice processing pipeline.\n",
    "            invoice_path: Path to invoice file\n",
    "        Args:\n",
    "            invoice_path: Path to invoice file\n",
    "\n",
    "        Returns:\n",
    "            Processing result with validation and decision\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse invoice\n",
    "            invoice_data = self.parse_invoice(invoice_path)\n",
    "\n",
    "            # Validate against rules\n",
    "            result = self.validate_invoice(invoice_data)\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing invoice: {e}\")\n",
    "            return {\n",
    "                \"invoice_file\": str(invoice_path),\n",
    "                \"status\": \"ERROR\",\n",
    "                \"action\": \"System error - manual review required\",\n",
    "                \"issues\": [str(e)],\n",
    "                \"warnings\": [],\n",
    "                \"validation_timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "    def batch_process(self, invoice_folder: str):\n",
    "        \"\"\"\n",
    "        Process multiple invoices from a folder.\n",
    "            invoice_folder: Path to folder containing invoices\n",
    "        Args:\n",
    "            invoice_folder: Path to folder containing invoices\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (results list, summary dict)\n",
    "        \"\"\"\n",
    "        folder = Path(invoice_folder)\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Folder not found: {invoice_folder}\")\n",
    "\n",
    "        results = []\n",
    "        invoice_files = (\n",
    "            list(folder.glob(\"*.pdf\"))\n",
    "            + list(folder.glob(\"*.png\"))\n",
    "            + list(folder.glob(\"*.jpg\"))\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Processing {len(invoice_files)} invoices from {invoice_folder}\")\n",
    "\n",
    "        for invoice_file in invoice_files:\n",
    "            result = self.process_invoice(str(invoice_file))\n",
    "            results.append(result)\n",
    "\n",
    "        # Generate summary\n",
    "        summary = {\n",
    "            \"total\": len(results),\n",
    "            \"approved\": sum(1 for r in results if r[\"status\"] == \"APPROVED\"),\n",
    "            \"flagged\": sum(1 for r in results if r[\"status\"] == \"FLAGGED\"),\n",
    "            \"rejected\": sum(1 for r in results if r[\"status\"] == \"REJECTED\"),\n",
    "            \"errors\": sum(1 for r in results if r[\"status\"] == \"ERROR\"),\n",
    "        }\n",
    "        return results, summary\n",
    "\n",
    "\n",
    "print(\"[OK] InvoiceProcessor class defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b57cf",
   "metadata": {},
   "source": [
    "## Usage: Process Invoices with Extracted Rules\n",
    "\n",
    "After extracting rules from contracts (Part 1), use these cells to process invoices:\n",
    "\n",
    "- **Cell 21:** Initialize Invoice Processor (loads rules from `extracted_rules.json`)\n",
    "- **Cell 22:** Process a single invoice file (optional - for testing/debugging)\n",
    "  - Useful for: Testing specific invoices, debugging issues, learning how validation works\n",
    "  - Shows detailed output for one invoice\n",
    "- **Cell 23:** Batch process all invoices (recommended for production)\n",
    "  - Processes all invoices in `docs/invoices/` directory\n",
    "  - Generates summary statistics and saves results to JSON\n",
    "  - Use this for normal workflow\n",
    "- **Cell 24:** Generate a summary report of all processed invoices\n",
    "\n",
    "### Recommendation:\n",
    "- **For production:** Use Cell 23 (batch processing) - it's more efficient and provides summary statistics\n",
    "- **For testing/debugging:** Use Cell 22 (single invoice) - easier to see detailed output for one file\n",
    "\n",
    "### Validation Status:\n",
    "- **APPROVED** - Invoice meets all requirements\n",
    "- **FLAGGED** - Invoice has warnings but may be acceptable\n",
    "- **REJECTED** - Invoice fails critical requirements (e.g., missing PO number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ebb48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:02,639 - INFO - Loaded 4 rules from extracted_rules.json\n",
      "2025-11-06 18:05:02,639 - INFO - Invoice Processor initialized with 4 rules\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Loaded Contract Rules:\n",
      "============================================================\n",
      "\n",
      "[PAYMENT_TERM] - Priority: high\n",
      "Description: The payment terms are Net 30 days from invoice date and in monthly installments....\n",
      "\n",
      "[APPROVAL] - Priority: medium\n",
      "Description: The invoice approval process is to approve invoices by the Project Manager....\n",
      "\n",
      "[PENALTY] - Priority: high\n",
      "Description: The late payment penalty is 1.5% per month on overdue balance....\n",
      "\n",
      "[SUBMISSION] - Priority: medium\n",
      "Description: The invoice processing rules are:\n",
      "\n",
      "*   All invoices must include:\n",
      "    *   Valid PO number (format: P...\n",
      "\n",
      "[OK] Payment Terms: Net 30 days\n",
      "\n",
      "[OK] Invoice Processor ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Initialize Invoice Processor (with robust error handling)\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if rules file exists and is valid\n",
    "rules_file = \"extracted_rules.json\"\n",
    "\n",
    "if not os.path.exists(rules_file):\n",
    "    print(f\"[WARN] Rules file not found: {rules_file}\")\n",
    "    print(\"\\nCreating default rules file...\")\n",
    "\n",
    "    # Create default rules\n",
    "    default_rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    with open(rules_file, \"w\") as f:\n",
    "        json.dump(default_rules, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Created {rules_file} with {len(default_rules)} default rules\")\n",
    "\n",
    "else:\n",
    "    # Check if file is empty or invalid\n",
    "    try:\n",
    "        with open(rules_file, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:\n",
    "                raise ValueError(\"File is empty\")\n",
    "            # Try to parse JSON\n",
    "            json.loads(content)\n",
    "    except (ValueError, json.JSONDecodeError) as e:\n",
    "        print(f\"[WARN] Invalid JSON in {rules_file}: {e}\")\n",
    "        print(\"\\nCreating default rules file...\")\n",
    "\n",
    "        default_rules = [\n",
    "            {\n",
    "                \"rule_id\": \"payment_terms\",\n",
    "                \"type\": \"payment_term\",\n",
    "                \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "                \"priority\": \"high\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "            {\n",
    "                \"rule_id\": \"submission_requirements\",\n",
    "                \"type\": \"submission\",\n",
    "                \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "                \"priority\": \"medium\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "            {\n",
    "                \"rule_id\": \"late_penalties\",\n",
    "                \"type\": \"penalty\",\n",
    "                \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "                \"priority\": \"high\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        with open(rules_file, \"w\") as f:\n",
    "            json.dump(default_rules, f, indent=2)\n",
    "\n",
    "        print(f\"[OK] Created {rules_file} with {len(default_rules)} default rules\")\n",
    "\n",
    "# Now initialize processor\n",
    "try:\n",
    "    processor = InvoiceProcessor(rules_file=rules_file)\n",
    "\n",
    "    # Display loaded rules\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Loaded Contract Rules:\")\n",
    "    print(\"=\" * 60)\n",
    "    for rule in processor.rules:\n",
    "        print(f\"\\n[{rule['type'].upper()}] - Priority: {rule['priority']}\")\n",
    "        print(f\"Description: {rule['description'][:100]}...\")\n",
    "\n",
    "    if processor.payment_terms:\n",
    "        print(f\"\\n[OK] Payment Terms: Net {processor.payment_terms} days\")\n",
    "    else:\n",
    "        print(\"\\n[WARN] No payment terms found in rules\")\n",
    "\n",
    "    print(\"\\n[OK] Invoice Processor ready\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error initializing processor: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Run Cell 15 to extract rules from contract\")\n",
    "    print(\"  2. Or run Generate_Sample_Documents.ipynb to create sample documents first\")\n",
    "    print(\"  3. Or run Cell 28 for complete pipeline test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27bbf0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:02,645 - INFO - Parsing invoice: docs/invoices/invoice_005_ocr_valid.png\n",
      "2025-11-06 18:05:02,874 - INFO - Using pytesseract for image file: invoice_005_ocr_valid.png\n",
      "2025-11-06 18:05:03,493 - INFO - pytesseract extracted 428 characters\n",
      "2025-11-06 18:05:03,495 - INFO - Validating invoice: invoice_005_ocr_valid.png\n",
      "2025-11-06 18:05:03,495 - INFO - Validation complete: APPROVED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INVOICE VALIDATION RESULT\n",
      "======================================================================\n",
      "\n",
      "Invoice File: invoice_005_ocr_valid.png\n",
      "Invoice Number: INV-2025-005\n",
      "\n",
      "Status: APPROVED\n",
      "Action: Auto-approved for payment\n",
      "\n",
      "[OK] Invoice approved for payment\n",
      "\n",
      "Validation Timestamp: 2025-11-06T18:05:03.495302\n",
      "======================================================================\n",
      "\n",
      "Extracted Invoice Data:\n",
      "  Invoice Date: 2025-10-29 00:00:00\n",
      "  Due Date: 2025-11-28 00:00:00\n",
      "  Total Amount: $6000.00\n",
      "  PO Number: PO-2025-1237\n",
      "  Vendor: XYZ Services Inc.\n"
     ]
    }
   ],
   "source": [
    "# Cell 22: Process a Single Invoice\n",
    "\n",
    "# NOTE: This cell is OPTIONAL - for testing/debugging individual invoices\n",
    "# For production use, skip to Cell 23 (Batch Processing) which processes all invoices\n",
    "# Use this cell when you need to:\n",
    "#   - Test a specific invoice\n",
    "#   - Debug validation issues\n",
    "#   - See detailed output for one invoice\n",
    "\n",
    "\n",
    "# Process a single invoice file\n",
    "invoice_file = \"docs/invoices/invoice_005_ocr_valid.png\"  # Change to your invoice file\n",
    "\n",
    "try:\n",
    "    result = processor.process_invoice(invoice_file)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=\" * 70)\n",
    "    print(\"INVOICE VALIDATION RESULT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nInvoice File: {result['invoice_file']}\")\n",
    "    print(f\"Invoice Number: {result.get('invoice_number', 'N/A')}\")\n",
    "    print(f\"\\nStatus: {result['status']}\")\n",
    "    print(f\"Action: {result['action']}\")\n",
    "\n",
    "    if result[\"issues\"]:\n",
    "        print(f\"\\n[FAIL] ISSUES ({len(result['issues'])}):\")\n",
    "        for i, issue in enumerate(result[\"issues\"], 1):\n",
    "            print(f\"  {i}. {issue}\")\n",
    "\n",
    "    if result[\"warnings\"]:\n",
    "        print(f\"\\n[WARN] WARNINGS ({len(result['warnings'])}):\")\n",
    "        for i, warning in enumerate(result[\"warnings\"], 1):\n",
    "            print(f\"  {i}. {warning}\")\n",
    "\n",
    "    if result[\"status\"] == \"APPROVED\":\n",
    "        print(\"\\n[OK] Invoice approved for payment\")\n",
    "\n",
    "    print(f\"\\nValidation Timestamp: {result['validation_timestamp']}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Display invoice data\n",
    "    if \"invoice_data\" in result:\n",
    "        print(\"\\nExtracted Invoice Data:\")\n",
    "        inv_data = result[\"invoice_data\"]\n",
    "        print(f\"  Invoice Date: {inv_data.get('invoice_date', 'N/A')}\")\n",
    "        print(f\"  Due Date: {inv_data.get('due_date', 'N/A')}\")\n",
    "        print(\n",
    "            f\"  Total Amount: ${inv_data.get('total_amount', 0):.2f}\"\n",
    "            if inv_data.get(\"total_amount\")\n",
    "            else \"  Total Amount: N/A\"\n",
    "        )\n",
    "        print(f\"  PO Number: {inv_data.get('po_number', 'N/A')}\")\n",
    "        print(f\"  Vendor: {inv_data.get('vendor_name', 'N/A')}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] Invoice file not found: {invoice_file}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error processing invoice: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db5ba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:03,503 - INFO - Processing 6 invoices from docs/invoices\n",
      "2025-11-06 18:05:03,503 - INFO - Parsing invoice: docs/invoices/invoice_001_valid.pdf\n",
      "2025-11-06 18:05:03,512 - INFO - Validating invoice: invoice_001_valid.pdf\n",
      "2025-11-06 18:05:03,512 - INFO - Validation complete: APPROVED\n",
      "2025-11-06 18:05:03,512 - INFO - Parsing invoice: docs/invoices/invoice_002_no_po.pdf\n",
      "2025-11-06 18:05:03,519 - WARNING - PO Number not found in invoice\n",
      "2025-11-06 18:05:03,520 - INFO - Validating invoice: invoice_002_no_po.pdf\n",
      "2025-11-06 18:05:03,520 - INFO - Validation complete: REJECTED\n",
      "2025-11-06 18:05:03,520 - INFO - Parsing invoice: docs/invoices/invoice_003_overdue.pdf\n",
      "2025-11-06 18:05:03,527 - INFO - Validating invoice: invoice_003_overdue.pdf\n",
      "2025-11-06 18:05:03,527 - INFO - Validation complete: FLAGGED\n",
      "2025-11-06 18:05:03,528 - INFO - Parsing invoice: docs/invoices/invoice_004_recent.pdf\n",
      "2025-11-06 18:05:03,535 - INFO - Validating invoice: invoice_004_recent.pdf\n",
      "2025-11-06 18:05:03,535 - INFO - Validation complete: APPROVED\n",
      "2025-11-06 18:05:03,535 - INFO - Parsing invoice: docs/invoices/invoice_005_ocr_valid.png\n",
      "2025-11-06 18:05:03,535 - INFO - Using pytesseract for image file: invoice_005_ocr_valid.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] VALIDATION ISSUE: invoice_002_no_po.pdf - Missing required field: po_number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:05:04,111 - INFO - pytesseract extracted 428 characters\n",
      "2025-11-06 18:05:04,112 - INFO - Validating invoice: invoice_005_ocr_valid.png\n",
      "2025-11-06 18:05:04,112 - INFO - Validation complete: APPROVED\n",
      "2025-11-06 18:05:04,112 - INFO - Parsing invoice: docs/invoices/invoice_006_ocr_no_po.png\n",
      "2025-11-06 18:05:04,113 - INFO - Using pytesseract for image file: invoice_006_ocr_no_po.png\n",
      "2025-11-06 18:05:04,697 - INFO - pytesseract extracted 404 characters\n",
      "2025-11-06 18:05:04,698 - WARNING - PO Number not found in invoice\n",
      "2025-11-06 18:05:04,698 - INFO - Validating invoice: invoice_006_ocr_no_po.png\n",
      "2025-11-06 18:05:04,699 - INFO - Validation complete: REJECTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] VALIDATION ISSUE: invoice_006_ocr_no_po.png - Missing required field: po_number\n",
      "======================================================================\n",
      "BATCH PROCESSING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Total Invoices Processed: 6\n",
      "\n",
      "[OK] Approved: 3\n",
      "[WARN] Flagged for Review: 1\n",
      "[FAIL] Rejected: 2\n",
      "[ERROR] Errors: 0\n",
      "\n",
      "Approval Rate: 50.0%\n",
      "\n",
      "======================================================================\n",
      "INDIVIDUAL INVOICE RESULTS\n",
      "======================================================================\n",
      "\n",
      "1. [OK] invoice_001_valid.pdf\n",
      "   Status: APPROVED - Auto-approved for payment\n",
      "\n",
      "2. [FAIL] invoice_002_no_po.pdf\n",
      "   Status: REJECTED - Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "\n",
      "3. [WARN] invoice_003_overdue.pdf\n",
      "   Status: FLAGGED - Review recommended\n",
      "   Warnings: Invoice is 15 days overdue, Late penalty may apply: The late payment penalty is 1.5% per month on overdue balance.\n",
      "\n",
      "4. [OK] invoice_004_recent.pdf\n",
      "   Status: APPROVED - Auto-approved for payment\n",
      "\n",
      "5. [OK] invoice_005_ocr_valid.png\n",
      "   Status: APPROVED - Auto-approved for payment\n",
      "\n",
      "6. [FAIL] invoice_006_ocr_no_po.png\n",
      "   Status: REJECTED - Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "\n",
      "[OK] Results saved to invoice_processing_results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 23: Batch Process Multiple Invoices\n",
    "\n",
    "# Process multiple invoices from a folder\n",
    "invoice_folder = \"docs/invoices\"  # Change to your invoices folder\n",
    "\n",
    "try:\n",
    "    results, summary = processor.batch_process(invoice_folder)\n",
    "\n",
    "    # Display summary\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal Invoices Processed: {summary['total']}\")\n",
    "    print(f\"\\n[OK] Approved: {summary['approved']}\")\n",
    "    print(f\"[WARN] Flagged for Review: {summary['flagged']}\")\n",
    "    print(f\"[FAIL] Rejected: {summary['rejected']}\")\n",
    "    print(f\"[ERROR] Errors: {summary['errors']}\")\n",
    "\n",
    "    # Calculate approval rate\n",
    "    if summary[\"total\"] > 0:\n",
    "        approval_rate = (summary[\"approved\"] / summary[\"total\"]) * 100\n",
    "        print(f\"\\nApproval Rate: {approval_rate:.1f}%\")\n",
    "\n",
    "    # Display individual results\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INDIVIDUAL INVOICE RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for i, result in enumerate(results, 1):\n",
    "        status_icon = {\n",
    "            \"APPROVED\": \"[OK]\",\n",
    "            \"FLAGGED\": \"[WARN]\",\n",
    "            \"REJECTED\": \"[FAIL]\",\n",
    "            \"ERROR\": \"[ERROR]\",\n",
    "        }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "        print(f\"\\n{i}. {status_icon} {result['invoice_file']}\")\n",
    "        print(f\"   Status: {result['status']} - {result['action']}\")\n",
    "\n",
    "        if result[\"issues\"]:\n",
    "            print(f\"   Issues: {', '.join(result['issues'][:2])}\")\n",
    "        if result[\"warnings\"]:\n",
    "            print(f\"   Warnings: {', '.join(result['warnings'][:2])}\")\n",
    "\n",
    "    # Save results to JSON\n",
    "    output_file = \"invoice_processing_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"summary\": summary,\n",
    "                \"results\": results,\n",
    "                \"processed_at\": datetime.now().isoformat(),\n",
    "            },\n",
    "            f,\n",
    "            indent=2,\n",
    "            default=str,\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[OK] Results saved to {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] Invoice folder not found: {invoice_folder}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] Error in batch processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bec9cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INVOICE PROCESSING REPORT\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-06T18:05:04.699671\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Invoices: 6\n",
      "Approved: 3 (50.0%)\n",
      "Flagged: 1 (16.7%)\n",
      "Rejected: 2 (33.3%)\n",
      "Errors: 0 (0.0%)\n",
      "\n",
      "MOST COMMON ISSUES\n",
      "--------------------------------------------------------------------------------\n",
      "   Missing required field: po_number: 2 occurrence(s)\n",
      "\n",
      "MOST COMMON WARNINGS\n",
      "--------------------------------------------------------------------------------\n",
      "   Invoice is 15 days overdue: 1 occurrence(s)\n",
      "   Late penalty may apply: The late payment penalty is 1.5% per month on overdue balance.: 1 occurrence(s)\n",
      "\n",
      "RECOMMENDED ACTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Review 2 rejected invoice(s) manually\n",
      "  2. Investigate 1 flagged invoice(s)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 24: Generate Processing Report\n",
    "\n",
    "\n",
    "def generate_processing_report(results_file: str = \"invoice_processing_results.json\"):\n",
    "    \"\"\"Generate a detailed processing report with statistics and insights.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(results_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        summary = data[\"summary\"]\n",
    "        results = data[\"results\"]\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"INVOICE PROCESSING REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nGenerated: {data.get('processed_at', 'N/A')}\")\n",
    "\n",
    "        # Overall Statistics\n",
    "        print(\"\\nOVERALL STATISTICS\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Total Invoices: {summary['total']}\")\n",
    "        print(\n",
    "            f\"Approved: {summary['approved']} ({summary['approved']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Flagged: {summary['flagged']} ({summary['flagged']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Rejected: {summary['rejected']} ({summary['rejected']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Errors: {summary['errors']} ({summary['errors']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # Most Common Issues\n",
    "        print(\"\\nMOST COMMON ISSUES\")\n",
    "        print(\"-\" * 80)\n",
    "        all_issues = []\n",
    "        for result in results:\n",
    "            all_issues.extend(result.get(\"issues\", []))\n",
    "\n",
    "        if all_issues:\n",
    "            from collections import Counter\n",
    "\n",
    "            issue_counts = Counter(all_issues)\n",
    "            for issue, count in issue_counts.most_common(5):\n",
    "                print(f\"   {issue}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No issues found\")\n",
    "\n",
    "        # Most Common Warnings\n",
    "        print(\"\\nMOST COMMON WARNINGS\")\n",
    "        print(\"-\" * 80)\n",
    "        all_warnings = []\n",
    "        for result in results:\n",
    "            all_warnings.extend(result.get(\"warnings\", []))\n",
    "\n",
    "        if all_warnings:\n",
    "            from collections import Counter\n",
    "\n",
    "            warning_counts = Counter(all_warnings)\n",
    "            for warning, count in warning_counts.most_common(5):\n",
    "                print(f\"   {warning}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No warnings found\")\n",
    "\n",
    "        # Recommended Actions\n",
    "        print(\"\\nRECOMMENDED ACTIONS\")\n",
    "        print(\"-\" * 80)\n",
    "        if summary[\"rejected\"] > 0:\n",
    "            print(f\"  1. Review {summary['rejected']} rejected invoice(s) manually\")\n",
    "        if summary[\"flagged\"] > 0:\n",
    "            print(f\"  2. Investigate {summary['flagged']} flagged invoice(s)\")\n",
    "        if summary[\"errors\"] > 0:\n",
    "            print(f\"  3. Fix processing errors for {summary['errors']} invoice(s)\")\n",
    "        if summary[\"approved\"] == summary[\"total\"]:\n",
    "            print(\"  [OK] All invoices approved - ready for payment processing\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] Results file not found: {results_file}\")\n",
    "        print(\"Please run batch processing first (Cell 23)\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] Error generating report: {e}\")\n",
    "\n",
    "\n",
    "# Run the report if results exist\n",
    "generate_processing_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af20a1e",
   "metadata": {},
   "source": [
    "## Summary: Complete AI Agent Pipeline\n",
    "\n",
    "This notebook provides a complete end-to-end invoice processing solution:\n",
    "\n",
    "1. **Rule Extraction** (Cells 14-17) - Extract rules from contracts using RAG\n",
    "2. **Invoice Processing** (Cells 19-24) - Validate invoices against rules\n",
    "3. **Complete Pipeline** (Cell 29) - Run both steps together\n",
    "4. **Reporting** (Cell 30) - Export results to JSON reports\n",
    "\n",
    "### Key Files Generated:\n",
    "- `extracted_rules.json` - Extracted invoice processing rules\n",
    "- `invoice_processing_results.json` - Processing results and validation status\n",
    "- `validation_report.json` - Detailed validation report\n",
    "\n",
    "### Sample Documents:\n",
    "Sample contracts and invoices are automatically generated if the `docs/` directories are empty (see Cell 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d011522",
   "metadata": {},
   "source": [
    "# Cell 26: Sample Document Generation\n",
    "\n",
    "**Note:** Sample document generation has been moved to a separate notebook.\n",
    "\n",
    "**To generate sample documents:**\n",
    "- Run the notebook: **`Generate_Sample_Documents.ipynb`**\n",
    "- Or let the main notebook auto-generate them (check runs at startup)\n",
    "\n",
    "The main notebook automatically checks for sample documents at startup (Cell 8) and will prompt you to generate them if the folders are empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a47a1",
   "metadata": {},
   "source": [
    "## Test the Complete Pipeline\n",
    "\n",
    "**Cell 29** runs the complete pipeline:\n",
    "1. Extracts rules from contract documents\n",
    "2. Processes all invoices in `docs/invoices/`\n",
    "3. Validates invoices against extracted rules\n",
    "4. Generates comprehensive results\n",
    "\n",
    "This is the recommended way to test the entire system end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f86b868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPLETE RAG PIPELINE TEST\n",
      "================================================================================\n",
      "\n",
      "Step 1: Extracting rules from contract using RAG...\n",
      "--------------------------------------------------------------------------------\n",
      "Analyzing contract: docs/contracts/sample_contract_net30.pdf\n",
      "Processing... (this takes ~4-5 seconds)\n",
      "[WARN] Contract not found. Using fallback rules...\n",
      "Created 3 fallback rules\n",
      "  - [payment_term] Payment terms: Net 30 days from invoice date. All invoices m...\n",
      "  - [submission] All invoices must include: Valid PO number (format: PO-YYYY-...\n",
      "  - [penalty] Late payment penalty: 1.5% per month on overdue balance. Mis...\n",
      "\n",
      "Step 2: Processing sample invoices...\n",
      "--------------------------------------------------------------------------------\n",
      "Found 10 invoice file(s) to process\n",
      "Files: ['invoice_001_valid.pdf', 'invoice_002_no_po.pdf', 'invoice_002_no_po.docx', 'invoice_003_overdue.pdf', 'invoice_005_ocr_valid.png', 'invoice_004_recent.pdf', 'invoice_001_valid.docx', 'invoice_004_recent.docx', 'invoice_003_overdue.docx', 'invoice_006_ocr_no_po.png']\n",
      "\n",
      "[OK] invoice_001_valid.pdf:\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.pdf - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_002_no_po.pdf:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.docx - Missing required field: invoice_number\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.docx - Missing required field: invoice_date\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.docx - Missing required field: total_amount\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.docx - Missing required field: vendor_name\n",
      "[!] VALIDATION ISSUE: invoice_002_no_po.docx - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_002_no_po.docx:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number, Missing required field: invoice_date, Missing required field: total_amount, Missing required field: vendor_name, Missing required field: po_number\n",
      "\n",
      "[WARN] invoice_003_overdue.pdf:\n",
      "   Status: FLAGGED\n",
      "   Action: Review recommended\n",
      "   Warnings: Invoice is 15 days overdue, Late penalty may apply: Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\n",
      "\n",
      "[OK] invoice_005_ocr_valid.png:\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "\n",
      "[OK] invoice_004_recent.pdf:\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "[!] VALIDATION ISSUE: invoice_001_valid.docx - Missing required field: invoice_number\n",
      "[!] VALIDATION ISSUE: invoice_001_valid.docx - Missing required field: invoice_date\n",
      "[!] VALIDATION ISSUE: invoice_001_valid.docx - Missing required field: total_amount\n",
      "[!] VALIDATION ISSUE: invoice_001_valid.docx - Missing required field: vendor_name\n",
      "[!] VALIDATION ISSUE: invoice_001_valid.docx - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_001_valid.docx:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number, Missing required field: invoice_date, Missing required field: total_amount, Missing required field: vendor_name, Missing required field: po_number\n",
      "[!] VALIDATION ISSUE: invoice_004_recent.docx - Missing required field: invoice_number\n",
      "[!] VALIDATION ISSUE: invoice_004_recent.docx - Missing required field: invoice_date\n",
      "[!] VALIDATION ISSUE: invoice_004_recent.docx - Missing required field: total_amount\n",
      "[!] VALIDATION ISSUE: invoice_004_recent.docx - Missing required field: vendor_name\n",
      "[!] VALIDATION ISSUE: invoice_004_recent.docx - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_004_recent.docx:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number, Missing required field: invoice_date, Missing required field: total_amount, Missing required field: vendor_name, Missing required field: po_number\n",
      "[!] VALIDATION ISSUE: invoice_003_overdue.docx - Missing required field: invoice_number\n",
      "[!] VALIDATION ISSUE: invoice_003_overdue.docx - Missing required field: invoice_date\n",
      "[!] VALIDATION ISSUE: invoice_003_overdue.docx - Missing required field: total_amount\n",
      "[!] VALIDATION ISSUE: invoice_003_overdue.docx - Missing required field: vendor_name\n",
      "[!] VALIDATION ISSUE: invoice_003_overdue.docx - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_003_overdue.docx:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number, Missing required field: invoice_date, Missing required field: total_amount, Missing required field: vendor_name, Missing required field: po_number\n",
      "[!] VALIDATION ISSUE: invoice_006_ocr_no_po.png - Missing required field: po_number\n",
      "\n",
      "[FAIL] invoice_006_ocr_no_po.png:\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "\n",
      "================================================================================\n",
      "PIPELINE TEST RESULTS\n",
      "================================================================================\n",
      "Total Invoices: 10\n",
      "[OK] Approved: 3\n",
      "[WARN] Flagged: 1\n",
      "[FAIL] Rejected: 6\n",
      "\n",
      "Success Rate: 30.0%\n",
      "\n",
      "================================================================================\n",
      "[OK] Pipeline test complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 28: Complete RAG Pipeline Test - Extract Rules and Process Invoices\n",
    "from datetime import datetime\n",
    "\n",
    "# Temporarily reduce logging noise for cleaner output\n",
    "import logging\n",
    "\n",
    "old_level = logging.getLogger().level\n",
    "logging.getLogger().setLevel(\n",
    "    logging.ERROR\n",
    ")  # Only show errors (suppresses INFO and WARNING)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE RAG PIPELINE TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Extract rules from contract using RAG\n",
    "print(\"\\nStep 1: Extracting rules from contract using RAG...\")\n",
    "print(\"-\" * 80)\n",
    "contract_path = \"docs/contracts/sample_contract_net30.pdf\"\n",
    "\n",
    "try:\n",
    "    # Initialize RAG-powered agent\n",
    "    rag_agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "\n",
    "    # Extract rules using RAG\n",
    "    print(f\"Analyzing contract: {contract_path}\")\n",
    "    print(\"Processing... (this takes ~4-5 seconds)\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        rules = rag_agent.run(contract_path)\n",
    "\n",
    "    # Save rules\n",
    "    # Save rules with metadata\n",
    "    rules_data = {\n",
    "        \"contract_path\": contract_path,\n",
    "        \"extracted_at\": datetime.now().isoformat(),\n",
    "        \"rules\": rules\n",
    "    }\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules_data, f, indent=2)\n",
    "    print(f\"[WARN] Contract not found. Using fallback rules...\")\n",
    "    # Fallback to manual rules if contract not found\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "    # Save fallback rules with metadata\n",
    "    rules_data = {\n",
    "        \"contract_path\": contract_path if \"contract_path\" in locals() else \"Unknown\",\n",
    "        \"extracted_at\": datetime.now().isoformat(),\n",
    "        \"rules\": rules\n",
    "    }\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules_data, f, indent=2)\n",
    "    print(f\"Created {len(rules)} fallback rules\")\n",
    "    for rule in rules:\n",
    "        print(f\"  - [{rule['type']}] {rule['description'][:60]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error extracting rules: {e}\")\n",
    "    print(\"Using fallback rules...\")\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Net 30 payment terms\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"medium\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"PO number required\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"medium\",\n",
    "        },\n",
    "    ]\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "\n",
    "# Step 2: Process sample invoices\n",
    "print(\"\\nStep 2: Processing sample invoices...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    # Initialize invoice processor\n",
    "    processor = InvoiceProcessor(rules_file=\"extracted_rules.json\")\n",
    "\n",
    "    # Process all invoices found in the invoices directory\n",
    "    # Scan invoices directory for all invoice files\n",
    "    invoice_dir = Path(\"docs/invoices\")\n",
    "    invoice_files = [\n",
    "        str(f) for f in invoice_dir.glob(\"*.*\")\n",
    "        if f.suffix.lower() in [\".pdf\", \".docx\", \".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\"]\n",
    "        and f.is_file()\n",
    "    ]\n",
    "\n",
    "    if not invoice_files:\n",
    "        print(\"[WARN] No invoice files found in docs/invoices/\")\n",
    "        print(\"Please add invoice files or run Generate_Sample_Documents.ipynb\")\n",
    "    else:\n",
    "        print(f\"Found {len(invoice_files)} invoice file(s) to process\")\n",
    "        print(f\"Files: {[Path(f).name for f in invoice_files]}\")\n",
    "\n",
    "        results = []\n",
    "        for invoice_file in invoice_files:\n",
    "            try:\n",
    "                result = processor.process_invoice(invoice_file)\n",
    "                results.append(result)\n",
    "\n",
    "                # Display result\n",
    "                status_icon = {\n",
    "                    \"APPROVED\": \"[OK]\",\n",
    "                    \"FLAGGED\": \"[WARN]\",\n",
    "                    \"REJECTED\": \"[FAIL]\",\n",
    "                    \"ERROR\": \"[ERROR]\",\n",
    "                }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "                print(f\"\\n{status_icon} {Path(invoice_file).name}:\")\n",
    "                print(f\"   Status: {result['status']}\")\n",
    "                print(f\"   Action: {result['action']}\")\n",
    "                if result.get(\"issues\"):\n",
    "                    print(f\"   Issues: {', '.join(result['issues'])}\")\n",
    "                if result.get(\"warnings\"):\n",
    "                    print(f\"   Warnings: {', '.join(result['warnings'])}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"\\n[ERROR] {Path(invoice_file).name}: File not found (skipping)\")\n",
    "\n",
    "        if results:\n",
    "            # Summary\n",
    "            approved = sum(1 for r in results if r[\"status\"] == \"APPROVED\")\n",
    "            flagged = sum(1 for r in results if r[\"status\"] == \"FLAGGED\")\n",
    "            rejected = sum(1 for r in results if r[\"status\"] == \"REJECTED\")\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"PIPELINE TEST RESULTS\")\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Total Invoices: {len(results)}\")\n",
    "            print(f\"[OK] Approved: {approved}\")\n",
    "            print(f\"[WARN] Flagged: {flagged}\")\n",
    "            print(f\"[FAIL] Rejected: {rejected}\")\n",
    "            if len(results) > 0:\n",
    "                print(f\"\\nSuccess Rate: {approved/len(results)*100:.1f}%\")\n",
    "        else:\n",
    "            print(\"\\n[WARN] No invoices processed. Create sample documents first (Generate_Sample_Documents.ipynb)\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[OK] Pipeline test complete!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error in invoice processing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Restore original logging level\n",
    "    logging.getLogger().setLevel(old_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb8bd06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Results saved to: invoice_processing_results.json\n",
      "\n",
      "================================================================================\n",
      "DETAILED PROCESSING REPORT\n",
      "================================================================================\n",
      "\n",
      "Generated: 2025-11-06T18:05:07.445025\n",
      "Contract Analyzed: docs/contracts/sample_contract_net30.pdf\n",
      "Rules Extracted: 3\n",
      "\n",
      "OVERALL STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total Invoices: 10\n",
      "[OK] Approved: 3 (30.0%)\n",
      "[WARN] Flagged: 1 (10.0%)\n",
      "[FAIL] Rejected: 6 (60.0%)\n",
      "[ERROR] Errors: 0 (0.0%)\n",
      "\n",
      "INVOICE DETAILS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. [OK] invoice_001_valid.pdf\n",
      "   Invoice #: INV-2025-001\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "\n",
      "2. [FAIL] invoice_002_no_po.pdf\n",
      "   Invoice #: INV-2025-002\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "\n",
      "3. [FAIL] invoice_002_no_po.docx\n",
      "   Invoice #: None\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number; Missing required field: invoice_date; Missing required field: total_amount; Missing required field: vendor_name; Missing required field: po_number\n",
      "\n",
      "4. [WARN] invoice_003_overdue.pdf\n",
      "   Invoice #: INV-2025-003\n",
      "   Status: FLAGGED\n",
      "   Action: Review recommended\n",
      "   Warnings: Invoice is 15 days overdue; Late penalty may apply: Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\n",
      "\n",
      "5. [OK] invoice_005_ocr_valid.png\n",
      "   Invoice #: INV-2025-005\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "\n",
      "6. [OK] invoice_004_recent.pdf\n",
      "   Invoice #: INV-2025-004\n",
      "   Status: APPROVED\n",
      "   Action: Auto-approved for payment\n",
      "\n",
      "7. [FAIL] invoice_001_valid.docx\n",
      "   Invoice #: None\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number; Missing required field: invoice_date; Missing required field: total_amount; Missing required field: vendor_name; Missing required field: po_number\n",
      "\n",
      "8. [FAIL] invoice_004_recent.docx\n",
      "   Invoice #: None\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number; Missing required field: invoice_date; Missing required field: total_amount; Missing required field: vendor_name; Missing required field: po_number\n",
      "\n",
      "9. [FAIL] invoice_003_overdue.docx\n",
      "   Invoice #: None\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: invoice_number; Missing required field: invoice_date; Missing required field: total_amount; Missing required field: vendor_name; Missing required field: po_number\n",
      "\n",
      "10. [FAIL] invoice_006_ocr_no_po.png\n",
      "   Invoice #: INV-2025-006\n",
      "   Status: REJECTED\n",
      "   Action: Manual review required\n",
      "   Issues: Missing required field: po_number\n",
      "\n",
      "MOST COMMON ISSUES\n",
      "--------------------------------------------------------------------------------\n",
      "   Missing required field: po_number: 6 occurrence(s)\n",
      "   Missing required field: invoice_number: 4 occurrence(s)\n",
      "   Missing required field: invoice_date: 4 occurrence(s)\n",
      "   Missing required field: total_amount: 4 occurrence(s)\n",
      "   Missing required field: vendor_name: 4 occurrence(s)\n",
      "\n",
      "MOST COMMON WARNINGS\n",
      "--------------------------------------------------------------------------------\n",
      "   Invoice is 15 days overdue: 1 occurrence(s)\n",
      "   Late penalty may apply: Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.: 1 occurrence(s)\n",
      "\n",
      "EXTRACTED RULES (from RAG)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. PAYMENT_TERM\n",
      "   Priority: high\n",
      "   Description: Payment terms: Net 30 days from invoice date. All invoices must include a valid ...\n",
      "\n",
      "2. SUBMISSION\n",
      "   Priority: medium\n",
      "   Description: All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date ...\n",
      "\n",
      "3. PENALTY\n",
      "   Priority: high\n",
      "   Description: Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Auto...\n",
      "\n",
      "RECOMMENDED ACTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Review 6 rejected invoice(s) manually\n",
      "  2. Investigate 1 flagged invoice(s)\n",
      "\n",
      "================================================================================\n",
      "[OK] Report generated successfully!\n",
      "Full results saved to: invoice_processing_results.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 29: Export Pipeline Results to Report\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Convert datetime objects to strings for JSON serialization\n",
    "def serialize_result(result):\n",
    "    \"\"\"Convert result dict to JSON-serializable format.\"\"\"\n",
    "    serialized = result.copy()\n",
    "    if \"invoice_data\" in serialized:\n",
    "        invoice_data = serialized[\"invoice_data\"].copy()\n",
    "        # Convert datetime objects to ISO format strings\n",
    "        for key in [\"invoice_date\", \"due_date\"]:\n",
    "            if key in invoice_data and invoice_data[key]:\n",
    "                if isinstance(invoice_data[key], datetime):\n",
    "                    invoice_data[key] = invoice_data[key].isoformat()\n",
    "        serialized[\"invoice_data\"] = invoice_data\n",
    "    return serialized\n",
    "\n",
    "\n",
    "# Save results to JSON for reporting\n",
    "# Read contract path from extracted_rules.json\n",
    "try:\n",
    "    with open(\"extracted_rules.json\", \"r\") as f:\n",
    "        rules_data = json.load(f)\n",
    "        # Handle both old format (list) and new format (dict with metadata)\n",
    "        if isinstance(rules_data, dict) and \"contract_path\" in rules_data:\n",
    "            contract_path = rules_data[\"contract_path\"]\n",
    "        else:\n",
    "            contract_path = \"Unknown\"\n",
    "except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "    contract_path = \"Unknown\"\n",
    "\n",
    "results_data = {\n",
    "    \"processed_at\": datetime.now().isoformat(),\n",
    "    \"contract_analyzed\": contract_path,\n",
    "    \"rules_extracted\": len(rules),\n",
    "    \"summary\": {\n",
    "        \"total\": len(results),\n",
    "        \"approved\": sum(1 for r in results if r[\"status\"] == \"APPROVED\"),\n",
    "        \"flagged\": sum(1 for r in results if r[\"status\"] == \"FLAGGED\"),\n",
    "        \"rejected\": sum(1 for r in results if r[\"status\"] == \"REJECTED\"),\n",
    "        \"errors\": sum(1 for r in results if r[\"status\"] == \"ERROR\"),\n",
    "    },\n",
    "    \"results\": [serialize_result(r) for r in results],\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open(\"invoice_processing_results.json\", \"w\") as f:\n",
    "    json.dump(results_data, indent=2, fp=f)\n",
    "\n",
    "print(\"[OK] Results saved to: invoice_processing_results.json\")\n",
    "\n",
    "# Generate detailed report\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED PROCESSING REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {results_data['processed_at']}\")\n",
    "print(f\"Contract Analyzed: {results_data['contract_analyzed']}\")\n",
    "print(f\"Rules Extracted: {results_data['rules_extracted']}\")\n",
    "\n",
    "# Overall Statistics\n",
    "print(\"\\nOVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "summary = results_data[\"summary\"]\n",
    "print(f\"Total Invoices: {summary['total']}\")\n",
    "print(\n",
    "    f\"[OK] Approved: {summary['approved']} ({summary['approved']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[WARN] Flagged: {summary['flagged']} ({summary['flagged']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[FAIL] Rejected: {summary['rejected']} ({summary['rejected']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[ERROR] Errors: {summary['errors']} ({summary['errors']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Invoice-by-Invoice Details\n",
    "print(\"\\nINVOICE DETAILS\")\n",
    "print(\"-\" * 80)\n",
    "for i, result in enumerate(results, 1):\n",
    "    status_icon = {\n",
    "        \"APPROVED\": \"[OK]\",\n",
    "        \"FLAGGED\": \"[WARN]\",\n",
    "        \"REJECTED\": \"[FAIL]\",\n",
    "        \"ERROR\": \"[ERROR]\",\n",
    "    }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "    print(f\"\\n{i}. {status_icon} {result['invoice_file'].split('/')[-1]}\")\n",
    "    print(f\"   Invoice #: {result.get('invoice_number', 'N/A')}\")\n",
    "    print(f\"   Status: {result['status']}\")\n",
    "    print(f\"   Action: {result['action']}\")\n",
    "\n",
    "    if result.get(\"issues\"):\n",
    "        print(f\"   Issues: {'; '.join(result['issues'])}\")\n",
    "    if result.get(\"warnings\"):\n",
    "        print(f\"   Warnings: {'; '.join(result['warnings'])}\")\n",
    "\n",
    "# Most Common Issues\n",
    "print(\"\\nMOST COMMON ISSUES\")\n",
    "print(\"-\" * 80)\n",
    "all_issues = []\n",
    "for result in results:\n",
    "    all_issues.extend(result.get(\"issues\", []))\n",
    "\n",
    "if all_issues:\n",
    "    issue_counts = Counter(all_issues)\n",
    "    for issue, count in issue_counts.most_common(5):\n",
    "        print(f\"   {issue}: {count} occurrence(s)\")\n",
    "else:\n",
    "    print(\"  [OK] No issues found\")\n",
    "\n",
    "# Most Common Warnings\n",
    "print(\"\\nMOST COMMON WARNINGS\")\n",
    "print(\"-\" * 80)\n",
    "all_warnings = []\n",
    "for result in results:\n",
    "    all_warnings.extend(result.get(\"warnings\", []))\n",
    "\n",
    "if all_warnings:\n",
    "    warning_counts = Counter(all_warnings)\n",
    "    for warning, count in warning_counts.most_common(5):\n",
    "        print(f\"   {warning}: {count} occurrence(s)\")\n",
    "else:\n",
    "    print(\"  [OK] No warnings found\")\n",
    "\n",
    "# Extracted Rules Summary\n",
    "print(\"\\nEXTRACTED RULES (from RAG)\")\n",
    "print(\"-\" * 80)\n",
    "for i, rule in enumerate(rules, 1):\n",
    "    print(f\"\\n{i}. {rule['type'].upper()}\")\n",
    "    print(f\"   Priority: {rule['priority']}\")\n",
    "    print(f\"   Description: {rule['description'][:80]}...\")\n",
    "\n",
    "# Recommended Actions\n",
    "print(\"\\nRECOMMENDED ACTIONS\")\n",
    "print(\"-\" * 80)\n",
    "actions_listed = False\n",
    "if summary[\"rejected\"] > 0:\n",
    "    print(f\"  1. Review {summary['rejected']} rejected invoice(s) manually\")\n",
    "    actions_listed = True\n",
    "if summary[\"flagged\"] > 0:\n",
    "    print(f\"  2. Investigate {summary['flagged']} flagged invoice(s)\")\n",
    "    actions_listed = True\n",
    "if summary[\"errors\"] > 0:\n",
    "    print(f\"  3. Fix processing errors for {summary['errors']} invoice(s)\")\n",
    "    actions_listed = True\n",
    "if summary[\"approved\"] == summary[\"total\"]:\n",
    "    print(\"  [OK] All invoices approved - ready for payment processing\")\n",
    "    actions_listed = True\n",
    "\n",
    "if not actions_listed:\n",
    "    print(\"  [OK] No action required at this time\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[OK] Report generated successfully!\")\n",
    "print(f\"Full results saved to: invoice_processing_results.json\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479665e",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "\n",
    "1. **No API Keys Required** - Uses local Ollama models\n",
    "2. **Fast Processing** - FAISS vector store for efficient semantic search\n",
    "3. **Comprehensive Validation** - Checks multiple rule types (payment terms, PO requirements, penalties, etc.)\n",
    "4. **Detailed Reporting** - JSON output with validation status and issues\n",
    "5. **Cross-Platform** - Works on Windows, Mac, and Linux\n",
    "6. **OCR Support** - Handles scanned documents and images\n",
    "7. **Automatic Setup** - Auto-generates sample documents if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820502",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "### Step-by-Step Execution:\n",
    "\n",
    "1. **Setup** (run once):\n",
    "   - Cells 5-6: Install packages\n",
    "   - Cell 7: Import libraries\n",
    "   - Cell 8: Generate sample documents (if needed)\n",
    "   - Cell 9: Test Ollama connection\n",
    "\n",
    "2. **Extract Rules**:\n",
    "   - Cell 14: Initialize RAG agent\n",
    "   - Cell 15: Process contract and extract rules\n",
    "   - Cell 16: Save rules to JSON\n",
    "\n",
    "3. **Process Invoices** (choose one):\n",
    "   - **Option A (Recommended):** Cell 23 - Batch process all invoices\n",
    "   - **Option B (Testing):** Cell 21  Cell 22 - Process single invoice for debugging\n",
    "\n",
    "4. **Complete Pipeline**:\n",
    "   - Cell 29: Run complete pipeline (extract rules + process invoices)\n",
    "   - Cell 30: Export results to report\n",
    "\n",
    "### Quick Start (Production):\n",
    "Run Cells 5-9, then Cell 29 (complete pipeline) for end-to-end processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d1ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CURRENT PROCESSOR STATE\n",
      "======================================================================\n",
      "\n",
      "[OK] Processor Status: Initialized\n",
      "Total Rules Loaded: 3\n",
      "Payment Terms: Net 30 days\n",
      "\n",
      "Currently Loaded Rules:\n",
      "\n",
      "  1. [PAYMENT_TERM]\n",
      "     ID: payment_terms\n",
      "     Priority: high\n",
      "     Source: Default\n",
      "     Description: Payment terms: Net 30 days from invoice date. All invoices must includ...\n",
      "\n",
      "  2. [SUBMISSION]\n",
      "     ID: submission_requirements\n",
      "     Priority: medium\n",
      "     Source: Default\n",
      "     Description: All invoices must include: Valid PO number (format: PO-YYYY-####), Inv...\n",
      "\n",
      "  3. [PENALTY]\n",
      "     ID: late_penalties\n",
      "     Priority: high\n",
      "     Source: Default\n",
      "     Description: Late payment penalty: 1.5% per month on overdue balance. Missing PO nu...\n",
      "\n",
      "======================================================================\n",
      "[OK] Ready to process invoices!\n",
      "\n",
      "Next steps:\n",
      "  1. Run Cell 22 to process a single invoice\n",
      "  2. Run Cell 23 to batch process all invoices\n",
      "  3. Run Cell 28 for complete pipeline with RAG extraction\n"
     ]
    }
   ],
   "source": [
    "# Cell 32: Verification Cell - Check Current Rules\n",
    "print(\"=\" * 70)\n",
    "print(\"CURRENT PROCESSOR STATE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if processor exists\n",
    "try:\n",
    "    print(f\"\\n[OK] Processor Status: Initialized\")\n",
    "    print(f\"Total Rules Loaded: {len(processor.rules)}\")\n",
    "    print(\n",
    "        f\"Payment Terms: Net {processor.payment_terms} days\"\n",
    "        if processor.payment_terms\n",
    "        else \"Payment Terms: Not specified\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nCurrently Loaded Rules:\")\n",
    "    for i, rule in enumerate(processor.rules, 1):\n",
    "        print(f\"\\n  {i}. [{rule['type'].upper()}]\")\n",
    "        print(f\"     ID: {rule['rule_id']}\")\n",
    "        print(f\"     Priority: {rule['priority']}\")\n",
    "        print(\n",
    "            f\"     Source: {'RAG-extracted' if rule.get('confidence') == 'medium' else 'Default'}\"\n",
    "        )\n",
    "        print(f\"     Description: {rule['description'][:70]}...\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"[OK] Ready to process invoices!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Run Cell 22 to process a single invoice\")\n",
    "    print(\"  2. Run Cell 23 to batch process all invoices\")\n",
    "    print(\"  3. Run Cell 28 for complete pipeline with RAG extraction\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"[FAIL] Processor not initialized. Run Cell 21 first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
