{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35da08",
   "metadata": {},
   "source": [
    "# AI Agent for Invoice Processing with RAG + Local LLM (Ollama)\n",
    "\n",
    "This notebook implements an **AI Agent with RAG (Retrieval-Augmented Generation)** for:\n",
    "1. **Extracting invoice processing rules** from contract documents using RAG\n",
    "2. **Processing invoices** against extracted rules with intelligent validation\n",
    "3. **Using local Ollama models** (gemma3:270m + nomic-embed-text)\n",
    "\n",
    "**Version:** 2.0 - RAG Edition  \n",
    "**Author:** r4 Technologies, Inc 2025\n",
    "\n",
    "## Key Features:\n",
    "- **RAG Architecture** - Retrieval-Augmented Generation for context-aware processing\n",
    "- **Local LLM** - Ollama gemma3:270m (no API keys needed)\n",
    "- **Vector Store** - ChromaDB for semantic search\n",
    "- **Semantic Chunking** - Context-aware document splitting\n",
    "- **Parallel OCR** - Multiprocessing for scanned documents\n",
    "- **Invoice Validation** - Rule-based compliance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f304d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Extract and display the block diagram from agent_iz.pdf\n",
    "# Delete this cell if you don't want to analyze agent_iz.pdf\n",
    "\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf_path = \"agent_Igor_Zhuk.pdf\"\n",
    "\n",
    "try:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        print(f\"PDF {pdf_path} has {len(pdf.pages)} page(s)\")\n",
    "\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            print(f\"\\n=== Page {i} ===\")\n",
    "\n",
    "            # Convert page to image\n",
    "            img = page.to_image(resolution=150)\n",
    "            pil_img = img.original\n",
    "\n",
    "            # Display the image\n",
    "            plt.figure(figsize=(12, 16))\n",
    "            plt.imshow(pil_img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(f\"agent_Igor_Zhuk.pdf - Page {i} (Block Diagram)\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Save as PNG for reference\n",
    "            output_file = f\"original_agent_Igor_Zhuk.png\"\n",
    "            pil_img.save(output_file)\n",
    "            print(f\"Saved diagram to: {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  File not found: {pdf_path}\")\n",
    "    print(\"Skipping diagram display (optional step)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2ae9",
   "metadata": {},
   "source": [
    "# AI Agent for Extracting Invoice Processing Rules from Contract Documents\n",
    "\n",
    "This notebook implements a modular AI agent that:\n",
    "1. Parses PDF or Word or Scanned contract documents into text.\n",
    "2. Uses an LLM (via Hugging Face Transformers) to extract rules related to invoice processing (e.g., payment terms, approvals, penalties).\n",
    "3. Refines and structures the rules into a JSON-like format.\n",
    "4. Outputs the rules for use in invoice processing systems.\n",
    "\n",
    "**Version:** 1.2  \n",
    "**Author:** r4 Technologies, Inc 2025\n",
    "\n",
    "## Features:\n",
    "- Parallel OCR processing using multiprocessing for scanned PDFs\n",
    "- Handling for low quality OCR with manual review\n",
    "- Validation of extracted text against Invoice related terms prior to LLM processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc30410",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "### Python Dependencies\n",
    "```bash\n",
    "pip install pdfplumber python-docx pytesseract Pillow nbformat\n",
    "```\n",
    "\n",
    "### Tesseract OCR Setup\n",
    "- **Linux:** `sudo apt-get install tesseract-ocr`\n",
    "- **Windows:** Download installer from [Tesseract GitHub](https://github.com/tesseract-ocr/tesseract)\n",
    "- **Mac:** `brew install tesseract`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6392028",
   "metadata": {},
   "source": [
    "## RAG Setup Requirements\n",
    "\n",
    "### Required Packages\n",
    "This notebook uses RAG with Ollama for local LLM processing.\n",
    "Install the following packages for RAG with Ollama:\n",
    "```bash\n",
    "pip install langchain-core langchain-community langchain langchain-ollama chromadb beautifulsoup4\n",
    "```\n",
    "\n",
    "### Ollama Models\n",
    "Make sure you have Ollama running with the required models:\n",
    "```bash\n",
    "ollama pull gemma3:270m\n",
    "ollama pull nomic-embed-text\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install document processing packages\n",
    "%pip install -q pdfplumber python-docx pytesseract Pillow reportlab matplotlib\n",
    "\n",
    "print(\"‚úì Document processing packages installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install RAG packages\n",
    "%pip install -q langchain-core==0.3.6 langchain-community==0.3.1 langchain==0.3.1 langchain-ollama==0.2.0 chromadb==0.5.23 beautifulsoup4==4.12.3 ipywidgets pydantic==2.9.2\n",
    "\n",
    "print(\" ‚úì RAG packages installed!\")\n",
    "print(\"\\nNote: Make sure Ollama is running with models:\")\n",
    "print(\"  ollama pull gemma3:270m\")\n",
    "print(\"  ollama pull nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3027e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configure environment variables (disable telemetry + warnings)\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"USER_AGENT\"] = \"InvoiceProcessingRAGAgent\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "os.environ[\"CHROMA_TELEMETRY\"] = \"False\"\n",
    "\n",
    "# Suppress IProgress warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress.*\")\n",
    "\n",
    "print(\"‚úì Environment configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Disable ChromaDB telemetry (COMPLETE FIX)\n",
    "import chromadb\n",
    "from unittest.mock import Mock, MagicMock\n",
    "import logging\n",
    "\n",
    "# Method 1: Mock the telemetry module completely\n",
    "if hasattr(chromadb, \"telemetry\"):\n",
    "    # Create a mock that accepts any arguments\n",
    "    chromadb.telemetry.capture = MagicMock(return_value=None)\n",
    "    chromadb.telemetry.Telemetry = MagicMock\n",
    "\n",
    "# Method 2: Set environment variables BEFORE ChromaDB initialization\n",
    "import os\n",
    "\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "os.environ[\"CHROMA_TELEMETRY\"] = \"False\"\n",
    "\n",
    "# Method 3: Suppress ChromaDB telemetry error logs\n",
    "logging.getLogger(\"chromadb.telemetry\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"chromadb\").setLevel(logging.WARNING)\n",
    "\n",
    "print(\"‚úì ChromaDB telemetry completely disabled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Import necessary libraries (Standard + RAG)\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from multiprocessing import Manager\n",
    "from datetime import datetime, timedelta\n",
    "from contextlib import redirect_stderr\n",
    "\n",
    "import pdfplumber  # For PDF parsing\n",
    "from docx import Document  # For Word (.docx) parsing\n",
    "from PIL import ImageEnhance\n",
    "import pytesseract  # For OCR\n",
    "\n",
    "# RAG imports\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document as LangchainDocument\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully (Standard + RAG components)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09062cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test Ollama connection and initialize models\n",
    "\n",
    "try:\n",
    "    # Test embeddings\n",
    "    test_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    test_embedding.embed_query(\"test\")\n",
    "    print(\"‚úì Ollama embeddings working (nomic-embed-text)\")\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm = ChatOllama(model=\"gemma3:270m\", temperature=0)\n",
    "    test_response = llm.invoke(\"Hello\")\n",
    "    print(\"‚úì Ollama LLM working (gemma3:270m)\")\n",
    "\n",
    "    # Initialize embeddings for later use\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "    print(\"\\n‚úì All Ollama models ready!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ollama error: {e}\")\n",
    "    print(\"\\nMake sure:\")\n",
    "    print(\"  1. Ollama is running\")\n",
    "    print(\"  2. Models are pulled:\")\n",
    "    print(\"     ollama pull gemma3:270m\")\n",
    "    print(\"     ollama pull nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Helper function to detect garbled text\n",
    "\n",
    "\n",
    "def is_garbled_text(\n",
    "    text: str, non_alpha_threshold: float = 0.4, min_word_length: int = 3\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Detect if text is likely garbled (low-confidence OCR output).\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to check.\n",
    "        non_alpha_threshold (float): Max proportion of non-alphanumeric characters.\n",
    "        min_word_length (int): Minimum average word length to consider valid.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if text is likely garbled, False otherwise.\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return True\n",
    "\n",
    "    # Check proportion of non-alphanumeric characters\n",
    "    non_alpha_count = len(re.findall(r\"[^a-zA-Z0-9\\s]\", text))\n",
    "    if non_alpha_count / max(len(text), 1) > non_alpha_threshold:\n",
    "        return True\n",
    "\n",
    "    # Check average word length\n",
    "    words = [w for w in text.split() if w.strip()]\n",
    "    if not words:\n",
    "        return True\n",
    "    avg_word_length = sum(len(w) for w in words) / len(words)\n",
    "    if avg_word_length < min_word_length:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "print(\"‚úì Garbled text detection function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Helper function to validate invoice-related terms\n",
    "\n",
    "\n",
    "def validate_invoice_terms(text: str, min_terms: int = 2) -> bool:\n",
    "    \"\"\"\n",
    "    Validate if text contains enough invoice-related terms.\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to validate.\n",
    "        min_terms (int): Minimum number of invoice-related terms required.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if sufficient invoice-related terms are found, False otherwise.\n",
    "    \"\"\"\n",
    "    invoice_keywords = [\n",
    "        r\"\\bpayment\\b\",\n",
    "        r\"\\binvoice\\b\",\n",
    "        r\"\\bdue\\b\",\n",
    "        r\"\\bnet\\s*\\d+\\b\",\n",
    "        r\"\\bterms\\b\",\n",
    "        r\"\\bapproval\\b\",\n",
    "        r\"\\bpenalty\\b\",\n",
    "        r\"\\bPO\\s*number\\b\",\n",
    "        r\"\\btax\\b\",\n",
    "        r\"\\bbilling\\b\",\n",
    "    ]\n",
    "    found_terms = sum(\n",
    "        1 for keyword in invoice_keywords if re.search(keyword, text, re.IGNORECASE)\n",
    "    )\n",
    "    return found_terms >= min_terms\n",
    "\n",
    "\n",
    "print(\"‚úì Invoice terms validation function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: InvoiceRuleExtractorAgent class definition (RAG-powered)\n",
    "\n",
    "\n",
    "class InvoiceRuleExtractorAgent:\n",
    "    \"\"\"\n",
    "    AI Agent for extracting invoice processing rules from contract documents using RAG.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm=None, embeddings=None):\n",
    "        \"\"\"\n",
    "        Initialize the agent with RAG components.\n",
    "\n",
    "        Args:\n",
    "            llm: ChatOllama instance (defaults to gemma3:270m)\n",
    "            embeddings: OllamaEmbeddings instance (defaults to nomic-embed-text)\n",
    "        \"\"\"\n",
    "        logger.info(\"Initializing RAG-powered Invoice Rule Extractor Agent\")\n",
    "\n",
    "        # Use provided models or create defaults\n",
    "        self.llm = llm if llm else ChatOllama(model=\"gemma3:270m\", temperature=0)\n",
    "        self.embeddings = (\n",
    "            embeddings if embeddings else OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        )\n",
    "\n",
    "        # Expanded keyword patterns for better matching\n",
    "        self.rule_keywords = [\n",
    "            \"payment\",\n",
    "            \"terms\",\n",
    "            \"due\",\n",
    "            \"net\",\n",
    "            \"days\",\n",
    "            \"invoice\",\n",
    "            \"approval\",\n",
    "            \"submission\",\n",
    "            \"requirement\",\n",
    "            \"late\",\n",
    "            \"fee\",\n",
    "            \"penalty\",\n",
    "            \"penalties\",\n",
    "            \"PO\",\n",
    "            \"purchase order\",\n",
    "            \"tax\",\n",
    "            \"dispute\",\n",
    "            \"month\",\n",
    "            \"overdue\",\n",
    "            \"rejection\",\n",
    "        ]\n",
    "\n",
    "        # RAG chain will be created after document parsing\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "        self.num_chunks = 0  # Track number of chunks\n",
    "\n",
    "    def parse_document(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Parse the contract document (PDF or Word), extract text, and create vector store for RAG.\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Extract text from document\n",
    "            if file_path.suffix.lower() == \".pdf\":\n",
    "                logger.info(f\"Parsing PDF: {file_path}\")\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text + \"\\n\"\n",
    "                        else:\n",
    "                            # Use OCR for scanned pages\n",
    "                            img = page.to_image().original\n",
    "                            img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                            text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "\n",
    "            elif file_path.suffix.lower() == \".docx\":\n",
    "                logger.info(f\"Parsing Word doc: {file_path}\")\n",
    "                doc = Document(file_path)\n",
    "                for para in doc.paragraphs:\n",
    "                    if para.text.strip():\n",
    "                        text += para.text + \"\\n\"\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unsupported file format: {file_path.suffix}. Use PDF or DOCX.\"\n",
    "                )\n",
    "\n",
    "            if not text.strip():\n",
    "                raise ValueError(\n",
    "                    \"No text extracted from document. Check scan quality or OCR setup.\"\n",
    "                )\n",
    "\n",
    "            logger.info(f\"Successfully parsed {len(text)} characters.\")\n",
    "\n",
    "            # Create document chunks for RAG\n",
    "            logger.info(\"Creating vector store for RAG...\")\n",
    "            self._create_vectorstore(text)\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing document: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _create_vectorstore(self, text: str):\n",
    "        \"\"\"Create vector store from document text for RAG retrieval.\"\"\"\n",
    "        # Create a document object\n",
    "        doc = LangchainDocument(page_content=text, metadata={\"source\": \"contract\"})\n",
    "\n",
    "        # Split document into chunks using RecursiveCharacterTextSplitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        self.num_chunks = len(splits)\n",
    "        logger.info(f\"Created {self.num_chunks} document chunks\")\n",
    "\n",
    "        # Create vector store (suppress telemetry warnings)\n",
    "        with redirect_stderr(io.StringIO()):\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=splits, embedding=self.embeddings\n",
    "            )\n",
    "\n",
    "        # Adaptive k: use min(3, num_chunks) to avoid warning\n",
    "        k_value = min(3, self.num_chunks)\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": k_value})\n",
    "        logger.info(\n",
    "            f\"Vector store created successfully (retrieving top {k_value} chunks)\"\n",
    "        )\n",
    "\n",
    "    def extract_rules(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Use RAG to extract invoice-related rules from the document.\n",
    "        \"\"\"\n",
    "        logger.info(\"Extracting rules using RAG...\")\n",
    "\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\n",
    "                \"Vector store not initialized. Call parse_document() first.\"\n",
    "            )\n",
    "\n",
    "        # Create RAG chain\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_template(\n",
    "            \"\"\"You are an expert at extracting invoice processing rules from contracts.\n",
    "Based on the following contract context, extract the requested information.\n",
    "Be specific and concise. If the information is not found, say \"Not specified in contract\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        )\n",
    "\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Extract different types of rules using RAG\n",
    "        questions = {\n",
    "            \"payment_terms\": \"What are the payment terms for invoices? Include net days, due dates, and any specific payment requirements.\",\n",
    "            \"approval_process\": \"What is the invoice approval process? Who needs to approve invoices and what are the approval requirements?\",\n",
    "            \"late_penalties\": \"What are the late payment penalties or fees? Include percentage rates and conditions.\",\n",
    "            \"submission_requirements\": \"What are the invoice submission requirements? What information must be included (e.g., PO number, tax ID, documentation)?\",\n",
    "        }\n",
    "\n",
    "        raw_rules = {}\n",
    "        for key, question in questions.items():\n",
    "            try:\n",
    "                with redirect_stderr(io.StringIO()):\n",
    "                    answer = rag_chain.invoke(question)\n",
    "\n",
    "                if (\n",
    "                    answer\n",
    "                    and len(answer) > 10\n",
    "                    and \"not specified\" not in answer.lower()\n",
    "                ):\n",
    "                    raw_rules[key] = answer.strip()\n",
    "                    logger.info(f\"Extracted {key}: {answer[:80]}...\")\n",
    "                else:\n",
    "                    raw_rules[key] = \"Not found\"\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error extracting {key}: {e}\")\n",
    "                raw_rules[key] = \"Not found\"\n",
    "\n",
    "        return raw_rules\n",
    "\n",
    "    def refine_rules(self, raw_rules: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Refine and structure the raw rules into a standardized format.\n",
    "        IMPROVED: Better keyword matching with case-insensitive search.\n",
    "        \"\"\"\n",
    "        logger.info(\"Refining rules...\")\n",
    "        structured_rules = []\n",
    "        rule_mapping = {\n",
    "            \"payment_terms\": {\"type\": \"payment_term\", \"priority\": \"high\"},\n",
    "            \"approval_process\": {\"type\": \"approval\", \"priority\": \"medium\"},\n",
    "            \"late_penalties\": {\"type\": \"penalty\", \"priority\": \"high\"},\n",
    "            \"submission_requirements\": {\"type\": \"submission\", \"priority\": \"medium\"},\n",
    "        }\n",
    "\n",
    "        for key, description in raw_rules.items():\n",
    "            if key in rule_mapping and description != \"Not found\":\n",
    "                # Convert to lowercase for matching\n",
    "                description_lower = description.lower()\n",
    "\n",
    "                # Check if ANY keyword is present (more lenient)\n",
    "                has_keyword = any(\n",
    "                    keyword.lower() in description_lower\n",
    "                    for keyword in self.rule_keywords\n",
    "                )\n",
    "\n",
    "                if (\n",
    "                    has_keyword or len(description) > 20\n",
    "                ):  # Accept if has keywords OR is substantial\n",
    "                    rule = {\n",
    "                        \"rule_id\": key,\n",
    "                        \"type\": rule_mapping[key][\"type\"],\n",
    "                        \"description\": description.strip(),\n",
    "                        \"priority\": rule_mapping[key][\"priority\"],\n",
    "                        \"confidence\": \"medium\",\n",
    "                    }\n",
    "                    structured_rules.append(rule)\n",
    "                    logger.info(\n",
    "                        f\"‚úì Structured rule: {rule['type']} - {rule['description'][:50]}...\"\n",
    "                    )\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        f\"Rule {key} discarded: No relevant keywords found. \"\n",
    "                        f\"Content: '{description[:60]}...'\"\n",
    "                    )\n",
    "\n",
    "        return structured_rules\n",
    "\n",
    "    def run(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Main execution method for the agent.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = self.parse_document(file_path)\n",
    "            raw_rules = self.extract_rules(text)\n",
    "            refined_rules = self.refine_rules(raw_rules)\n",
    "            logger.info(f\"Extraction complete. Found {len(refined_rules)} rules.\")\n",
    "            return refined_rules\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Agent run failed: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "print(\"‚úì InvoiceRuleExtractorAgent class defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42712e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Rule Extraction with RAG\n",
    "\n",
    "### RAG Workflow for Contract Analysis:\n",
    "\n",
    "1. **Document Loading** - Parse PDF/DOCX contract\n",
    "2. **Text Chunking** - Split document into semantic chunks (800 chars)\n",
    "3. **Indexing** - Create vector embeddings with ChromaDB\n",
    "4. **Retrieval** - Find relevant contract sections for each query\n",
    "5. **Generation** - LLM generates structured rules from retrieved context\n",
    "\n",
    "This approach ensures the LLM has access to the most relevant contract sections when extracting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Initialize the RAG-powered agent\n",
    "\n",
    "# Use the global llm and embeddings initialized earlier\n",
    "agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "print(\"‚úì RAG-powered Agent initialized successfully\")\n",
    "print(f\"  - LLM: gemma3:270m\")\n",
    "print(f\"  - Embeddings: nomic-embed-text\")\n",
    "print(f\"  - Vector Store: ChromaDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Process a contract document with RAG\n",
    "\n",
    "# Use sample contract or specify your own path\n",
    "file_path = \"data/contracts/sample_contract_net30.pdf\"  # Change this to your file path\n",
    "\n",
    "try:\n",
    "    print(f\"Processing contract: {file_path}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    rules = agent.run(file_path)\n",
    "\n",
    "    print(f\"\\n‚úì Extracted {len(rules)} rules using RAG:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(rules, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  File not found: {file_path}\")\n",
    "    print(\"Please create sample documents first (run Cell 18)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save extracted rules to JSON file\n",
    "\n",
    "output_file = \"extracted_rules.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "    print(f\"‚úì Rules saved to {output_file}\")\n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è  No rules to save. Run Cell 11 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a29ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Display extracted rules in a formatted way\n",
    "\n",
    "try:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXTRACTED INVOICE PROCESSING RULES\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        print(f\"\\n[Rule {i}]\")\n",
    "        print(f\"Type: {rule['type']}\")\n",
    "        print(f\"Priority: {rule['priority']}\")\n",
    "        print(f\"Description: {rule['description']}\")\n",
    "        print(f\"Confidence: {rule['confidence']}\")\n",
    "        print(\"-\" * 60)\n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è  No rules to display. Run Cell 11 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b95f48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Invoice Processor - Apply Extracted Rules\n",
    "\n",
    "Now we'll implement the Invoice Processor that uses the extracted rules to validate and process incoming invoices.\n",
    "\n",
    "### Goals:\n",
    "1. **Load extracted rules** from the AI Agent output\n",
    "2. **Parse incoming invoices** (various formats)\n",
    "3. **Validate invoices** against contract rules\n",
    "4. **Check compliance:** payment terms, PO numbers, amounts, dates\n",
    "5. **Flag violations** and generate alerts\n",
    "6. **Auto-approve or route** for manual review\n",
    "7. **Generate audit trail** and processing reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Invoice Processor Class Definition\n",
    "\n",
    "\n",
    "class InvoiceProcessor:\n",
    "    \"\"\"\n",
    "    AI-powered Invoice Processor that applies extracted rules to validate invoices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules_file: str = \"extracted_rules.json\"):\n",
    "        \"\"\"\n",
    "        Initialize the processor with extracted rules.\n",
    "\n",
    "        Args:\n",
    "            rules_file: Path to JSON file with extracted rules\n",
    "        \"\"\"\n",
    "        self.rules = self._load_rules(rules_file)\n",
    "        self.payment_terms = self._extract_payment_terms()\n",
    "        logger.info(f\"Invoice Processor initialized with {len(self.rules)} rules\")\n",
    "\n",
    "    def _load_rules(self, rules_file: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Load extracted rules from JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(rules_file, \"r\") as f:\n",
    "                rules = json.load(f)\n",
    "            logger.info(f\"Loaded {len(rules)} rules from {rules_file}\")\n",
    "            return rules\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(f\"Rules file not found: {rules_file}. Using empty rules.\")\n",
    "            return []\n",
    "\n",
    "    def _extract_payment_terms(self) -> Optional[int]:\n",
    "        \"\"\"Extract net days from payment terms rule.\"\"\"\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"payment_term\":\n",
    "                description = rule.get(\"description\", \"\")\n",
    "                # Look for \"net 30\", \"net 60\", etc.\n",
    "                match = re.search(r\"net\\s*(\\d+)\", description, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    def parse_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse invoice document and extract key fields.\n",
    "\n",
    "        Args:\n",
    "            invoice_path: Path to invoice PDF/image\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with invoice data\n",
    "        \"\"\"\n",
    "        logger.info(f\"Parsing invoice: {invoice_path}\")\n",
    "        invoice_path = Path(invoice_path)\n",
    "\n",
    "        if not invoice_path.exists():\n",
    "            raise FileNotFoundError(f\"Invoice not found: {invoice_path}\")\n",
    "\n",
    "        # Extract text from invoice\n",
    "        text = \"\"\n",
    "        if invoice_path.suffix.lower() == \".pdf\":\n",
    "            with pdfplumber.open(invoice_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "                    else:\n",
    "                        # Use OCR for scanned invoices\n",
    "                        img = page.to_image().original\n",
    "                        img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                        text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "\n",
    "        # Extract key invoice fields using regex patterns\n",
    "        invoice_data = {\n",
    "            \"file\": invoice_path.name,\n",
    "            \"invoice_number\": self._extract_field(\n",
    "                text, r\"invoice\\s*#?:?\\s*(\\S+)\", \"Invoice Number\"\n",
    "            ),\n",
    "            \"po_number\": self._extract_field(\n",
    "                text, r\"po\\s*(?:number|#)?:?\\s*(PO-[\\w-]+)\", \"PO Number\"\n",
    "            ),\n",
    "            \"invoice_date\": self._extract_date(\n",
    "                text, r\"invoice\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"due_date\": self._extract_date(\n",
    "                text, r\"due\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"total_amount\": self._extract_amount(text),\n",
    "            \"vendor_name\": self._extract_field(text, r\"from:?\\s*([^\\n]+)\", \"Vendor\"),\n",
    "            \"raw_text\": text[:500],  # First 500 chars for reference\n",
    "        }\n",
    "\n",
    "        return invoice_data\n",
    "\n",
    "    def _extract_field(self, text: str, pattern: str, field_name: str) -> Optional[str]:\n",
    "        \"\"\"Extract a field using regex pattern.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        logger.warning(f\"{field_name} not found in invoice\")\n",
    "        return None\n",
    "\n",
    "    def _extract_date(self, text: str, pattern: str) -> Optional[datetime]:\n",
    "        \"\"\"Extract and parse a date field.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            date_str = match.group(1)\n",
    "            # Try common date formats\n",
    "            for fmt in [\n",
    "                \"%m/%d/%Y\",\n",
    "                \"%d/%m/%Y\",\n",
    "                \"%m-%d-%Y\",\n",
    "                \"%d-%m-%Y\",\n",
    "                \"%m/%d/%y\",\n",
    "                \"%d/%m/%y\",\n",
    "            ]:\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, fmt)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def _extract_amount(self, text: str) -> Optional[float]:\n",
    "        \"\"\"Extract total amount from invoice.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:total\\s*amount\\s*due|total|amount\\s*due|balance\\s*due)[:\\s]*\\$\\s*([\\d,]+\\.?\\d*)\",\n",
    "            r\"\\$\\s*([\\d,]+\\.\\d{2})\\s*$\",  # Last dollar amount in text\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                amount_str = match.group(1).replace(\",\", \"\")\n",
    "                try:\n",
    "                    return float(amount_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def validate_invoice(self, invoice_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate invoice against extracted rules.\n",
    "\n",
    "        Args:\n",
    "            invoice_data: Parsed invoice data\n",
    "\n",
    "        Returns:\n",
    "            Validation result with status and issues\n",
    "        \"\"\"\n",
    "        logger.info(f\"Validating invoice: {invoice_data['file']}\")\n",
    "\n",
    "        issues = []\n",
    "        warnings = []\n",
    "\n",
    "        # Check for required fields based on submission requirements rule\n",
    "        required_fields = self._get_required_fields()\n",
    "        for field in required_fields:\n",
    "            if not invoice_data.get(field):\n",
    "                issues.append(f\"Missing required field: {field}\")\n",
    "\n",
    "        # Validate payment terms\n",
    "        if (\n",
    "            self.payment_terms\n",
    "            and invoice_data.get(\"invoice_date\")\n",
    "            and invoice_data.get(\"due_date\")\n",
    "        ):\n",
    "            expected_due = invoice_data[\"invoice_date\"] + timedelta(\n",
    "                days=self.payment_terms\n",
    "            )\n",
    "            actual_due = invoice_data[\"due_date\"]\n",
    "\n",
    "            if abs((actual_due - expected_due).days) > 2:  # Allow 2-day tolerance\n",
    "                issues.append(\n",
    "                    f\"Due date mismatch: Expected {expected_due.strftime('%m/%d/%Y')}, \"\n",
    "                    f\"got {actual_due.strftime('%m/%d/%Y')} (Net {self.payment_terms} terms)\"\n",
    "                )\n",
    "\n",
    "        # Check if invoice is overdue\n",
    "        if invoice_data.get(\"due_date\"):\n",
    "            if invoice_data[\"due_date\"] < datetime.now():\n",
    "                days_overdue = (datetime.now() - invoice_data[\"due_date\"]).days\n",
    "                warnings.append(f\"Invoice is {days_overdue} days overdue\")\n",
    "\n",
    "                # Check for late penalties\n",
    "                penalty_rule = self._get_penalty_rule()\n",
    "                if penalty_rule:\n",
    "                    warnings.append(f\"Late penalty may apply: {penalty_rule}\")\n",
    "\n",
    "        # Determine approval status\n",
    "        if issues:\n",
    "            status = \"REJECTED\"\n",
    "            action = \"Manual review required\"\n",
    "        elif warnings:\n",
    "            status = \"FLAGGED\"\n",
    "            action = \"Review recommended\"\n",
    "        else:\n",
    "            status = \"APPROVED\"\n",
    "            action = \"Auto-approved for payment\"\n",
    "\n",
    "        result = {\n",
    "            \"invoice_file\": invoice_data[\"file\"],\n",
    "            \"invoice_number\": invoice_data.get(\"invoice_number\"),\n",
    "            \"status\": status,\n",
    "            \"action\": action,\n",
    "            \"issues\": issues,\n",
    "            \"warnings\": warnings,\n",
    "            \"invoice_data\": invoice_data,\n",
    "            \"validation_timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Validation complete: {status}\")\n",
    "        return result\n",
    "\n",
    "    def _get_required_fields(self) -> List[str]:\n",
    "        \"\"\"Extract required fields from submission requirements rule.\"\"\"\n",
    "        required = [\"invoice_number\", \"invoice_date\", \"total_amount\"]\n",
    "\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"submission\":\n",
    "                description = rule.get(\"description\", \"\").lower()\n",
    "                if \"po\" in description or \"purchase order\" in description:\n",
    "                    required.append(\"po_number\")\n",
    "\n",
    "        return required\n",
    "\n",
    "    def _get_penalty_rule(self) -> Optional[str]:\n",
    "        \"\"\"Get late payment penalty description.\"\"\"\n",
    "        for rule in self.rules:\n",
    "            if rule.get(\"type\") == \"penalty\":\n",
    "                return rule.get(\"description\")\n",
    "        return None\n",
    "\n",
    "    def process_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete invoice processing pipeline.\n",
    "\n",
    "        Args:\n",
    "            invoice_path: Path to invoice file\n",
    "\n",
    "        Returns:\n",
    "            Processing result with validation and decision\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse invoice\n",
    "            invoice_data = self.parse_invoice(invoice_path)\n",
    "\n",
    "            # Validate against rules\n",
    "            result = self.validate_invoice(invoice_data)\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing invoice: {e}\")\n",
    "            return {\n",
    "                \"invoice_file\": str(invoice_path),\n",
    "                \"status\": \"ERROR\",\n",
    "                \"action\": \"System error - manual review required\",\n",
    "                \"issues\": [str(e)],\n",
    "                \"warnings\": [],\n",
    "                \"validation_timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "    def batch_process(self, invoice_folder: str):\n",
    "        \"\"\"\n",
    "        Process multiple invoices from a folder.\n",
    "\n",
    "        Args:\n",
    "            invoice_folder: Path to folder containing invoices\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (results list, summary dict)\n",
    "        \"\"\"\n",
    "        folder = Path(invoice_folder)\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Folder not found: {invoice_folder}\")\n",
    "\n",
    "        results = []\n",
    "        invoice_files = (\n",
    "            list(folder.glob(\"*.pdf\"))\n",
    "            + list(folder.glob(\"*.png\"))\n",
    "            + list(folder.glob(\"*.jpg\"))\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Processing {len(invoice_files)} invoices from {invoice_folder}\")\n",
    "\n",
    "        for invoice_file in invoice_files:\n",
    "            result = self.process_invoice(str(invoice_file))\n",
    "            results.append(result)\n",
    "\n",
    "        # Generate summary\n",
    "        summary = {\n",
    "            \"total\": len(results),\n",
    "            \"approved\": sum(1 for r in results if r[\"status\"] == \"APPROVED\"),\n",
    "            \"flagged\": sum(1 for r in results if r[\"status\"] == \"FLAGGED\"),\n",
    "            \"rejected\": sum(1 for r in results if r[\"status\"] == \"REJECTED\"),\n",
    "            \"errors\": sum(1 for r in results if r[\"status\"] == \"ERROR\"),\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Batch processing complete: {summary}\")\n",
    "        return results, summary\n",
    "\n",
    "\n",
    "print(\"‚úì InvoiceProcessor class defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b57cf",
   "metadata": {},
   "source": [
    "## Usage: Process Invoices with Extracted Rules\n",
    "\n",
    "Now let's use the Invoice Processor to validate incoming invoices against the extracted contract rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Initialize Invoice Processor\n",
    "\n",
    "# Initialize processor with extracted rules\n",
    "processor = InvoiceProcessor(rules_file=\"extracted_rules.json\")\n",
    "\n",
    "# Display loaded rules\n",
    "print(\"Loaded Contract Rules:\")\n",
    "print(\"=\" * 60)\n",
    "for rule in processor.rules:\n",
    "    print(f\"\\n[{rule['type'].upper()}] - Priority: {rule['priority']}\")\n",
    "    print(f\"Description: {rule['description'][:100]}...\")\n",
    "\n",
    "if processor.payment_terms:\n",
    "    print(f\"\\n‚úì Payment Terms: Net {processor.payment_terms} days\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No payment terms found in rules\")\n",
    "\n",
    "print(\"\\n‚úì Invoice Processor ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Process a Single Invoice\n",
    "\n",
    "# Process a single invoice file\n",
    "invoice_file = \"data/invoices/invoice_001_valid.pdf\"  # Change to your invoice file\n",
    "\n",
    "try:\n",
    "    result = processor.process_invoice(invoice_file)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=\" * 70)\n",
    "    print(\"INVOICE VALIDATION RESULT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nInvoice File: {result['invoice_file']}\")\n",
    "    print(f\"Invoice Number: {result.get('invoice_number', 'N/A')}\")\n",
    "    print(f\"\\nStatus: {result['status']}\")\n",
    "    print(f\"Action: {result['action']}\")\n",
    "\n",
    "    if result[\"issues\"]:\n",
    "        print(f\"\\n‚ùå ISSUES ({len(result['issues'])}):\")\n",
    "        for i, issue in enumerate(result[\"issues\"], 1):\n",
    "            print(f\"  {i}. {issue}\")\n",
    "\n",
    "    if result[\"warnings\"]:\n",
    "        print(f\"\\n‚ö†Ô∏è  WARNINGS ({len(result['warnings'])}):\")\n",
    "        for i, warning in enumerate(result[\"warnings\"], 1):\n",
    "            print(f\"  {i}. {warning}\")\n",
    "\n",
    "    if result[\"status\"] == \"APPROVED\":\n",
    "        print(\"\\n‚úÖ Invoice approved for payment\")\n",
    "\n",
    "    print(f\"\\nValidation Timestamp: {result['validation_timestamp']}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Display invoice data\n",
    "    if \"invoice_data\" in result:\n",
    "        print(\"\\nExtracted Invoice Data:\")\n",
    "        inv_data = result[\"invoice_data\"]\n",
    "        print(f\"  Invoice Date: {inv_data.get('invoice_date', 'N/A')}\")\n",
    "        print(f\"  Due Date: {inv_data.get('due_date', 'N/A')}\")\n",
    "        print(\n",
    "            f\"  Total Amount: ${inv_data.get('total_amount', 0):.2f}\"\n",
    "            if inv_data.get(\"total_amount\")\n",
    "            else \"  Total Amount: N/A\"\n",
    "        )\n",
    "        print(f\"  PO Number: {inv_data.get('po_number', 'N/A')}\")\n",
    "        print(f\"  Vendor: {inv_data.get('vendor_name', 'N/A')}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  Invoice file not found: {invoice_file}\")\n",
    "    print(\"Please create sample documents first (run Cell 18)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing invoice: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Batch Process Multiple Invoices\n",
    "\n",
    "# Process multiple invoices from a folder\n",
    "invoice_folder = \"data/invoices\"  # Change to your invoices folder\n",
    "\n",
    "try:\n",
    "    results, summary = processor.batch_process(invoice_folder)\n",
    "\n",
    "    # Display summary\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal Invoices Processed: {summary['total']}\")\n",
    "    print(f\"\\n‚úÖ Approved: {summary['approved']}\")\n",
    "    print(f\"‚ö†Ô∏è  Flagged for Review: {summary['flagged']}\")\n",
    "    print(f\"‚ùå Rejected: {summary['rejected']}\")\n",
    "    print(f\"üî¥ Errors: {summary['errors']}\")\n",
    "\n",
    "    # Calculate approval rate\n",
    "    if summary[\"total\"] > 0:\n",
    "        approval_rate = (summary[\"approved\"] / summary[\"total\"]) * 100\n",
    "        print(f\"\\nApproval Rate: {approval_rate:.1f}%\")\n",
    "\n",
    "    # Display individual results\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INDIVIDUAL INVOICE RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for i, result in enumerate(results, 1):\n",
    "        status_icon = {\n",
    "            \"APPROVED\": \"‚úÖ\",\n",
    "            \"FLAGGED\": \"‚ö†Ô∏è\",\n",
    "            \"REJECTED\": \"‚ùå\",\n",
    "            \"ERROR\": \"üî¥\",\n",
    "        }.get(result[\"status\"], \"‚ùì\")\n",
    "\n",
    "        print(f\"\\n{i}. {status_icon} {result['invoice_file']}\")\n",
    "        print(f\"   Status: {result['status']} - {result['action']}\")\n",
    "\n",
    "        if result[\"issues\"]:\n",
    "            print(f\"   Issues: {', '.join(result['issues'][:2])}\")\n",
    "        if result[\"warnings\"]:\n",
    "            print(f\"   Warnings: {', '.join(result['warnings'][:2])}\")\n",
    "\n",
    "    # Save results to JSON\n",
    "    output_file = \"invoice_processing_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"summary\": summary,\n",
    "                \"results\": results,\n",
    "                \"processed_at\": datetime.now().isoformat(),\n",
    "            },\n",
    "            f,\n",
    "            indent=2,\n",
    "            default=str,\n",
    "        )\n",
    "\n",
    "    print(f\"\\n‚úì Results saved to {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  Invoice folder not found: {invoice_folder}\")\n",
    "    print(\"Please create sample documents first (run Cell 18)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in batch processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Generate Processing Report\n",
    "\n",
    "\n",
    "def generate_processing_report(results_file: str = \"invoice_processing_results.json\"):\n",
    "    \"\"\"Generate a detailed processing report with statistics and insights.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(results_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        summary = data[\"summary\"]\n",
    "        results = data[\"results\"]\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"INVOICE PROCESSING REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nGenerated: {data.get('processed_at', 'N/A')}\")\n",
    "\n",
    "        # Overall Statistics\n",
    "        print(\"\\nüìä OVERALL STATISTICS\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Total Invoices: {summary['total']}\")\n",
    "        print(\n",
    "            f\"Approved: {summary['approved']} ({summary['approved']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Flagged: {summary['flagged']} ({summary['flagged']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Rejected: {summary['rejected']} ({summary['rejected']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Errors: {summary['errors']} ({summary['errors']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # Most Common Issues\n",
    "        print(\"\\n‚ö†Ô∏è  MOST COMMON ISSUES\")\n",
    "        print(\"-\" * 80)\n",
    "        all_issues = []\n",
    "        for result in results:\n",
    "            all_issues.extend(result.get(\"issues\", []))\n",
    "\n",
    "        if all_issues:\n",
    "            from collections import Counter\n",
    "\n",
    "            issue_counts = Counter(all_issues)\n",
    "            for issue, count in issue_counts.most_common(5):\n",
    "                print(f\"  ‚Ä¢ {issue}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No issues found\")\n",
    "\n",
    "        # Most Common Warnings\n",
    "        print(\"\\n‚ö†Ô∏è  MOST COMMON WARNINGS\")\n",
    "        print(\"-\" * 80)\n",
    "        all_warnings = []\n",
    "        for result in results:\n",
    "            all_warnings.extend(result.get(\"warnings\", []))\n",
    "\n",
    "        if all_warnings:\n",
    "            from collections import Counter\n",
    "\n",
    "            warning_counts = Counter(all_warnings)\n",
    "            for warning, count in warning_counts.most_common(5):\n",
    "                print(f\"  ‚Ä¢ {warning}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No warnings found\")\n",
    "\n",
    "        # Recommended Actions\n",
    "        print(\"\\nüí° RECOMMENDED ACTIONS\")\n",
    "        print(\"-\" * 80)\n",
    "        if summary[\"rejected\"] > 0:\n",
    "            print(f\"  1. Review {summary['rejected']} rejected invoice(s) manually\")\n",
    "        if summary[\"flagged\"] > 0:\n",
    "            print(f\"  2. Investigate {summary['flagged']} flagged invoice(s)\")\n",
    "        if summary[\"errors\"] > 0:\n",
    "            print(f\"  3. Fix processing errors for {summary['errors']} invoice(s)\")\n",
    "        if summary[\"approved\"] == summary[\"total\"]:\n",
    "            print(\"  ‚úÖ All invoices approved - ready for payment processing\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  Results file not found: {results_file}\")\n",
    "        print(\"Please run batch processing first (Cell 17)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating report: {e}\")\n",
    "\n",
    "\n",
    "# Run the report if results exist\n",
    "generate_processing_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af20a1e",
   "metadata": {},
   "source": [
    "## Summary: Complete AI Agent Pipeline\n",
    "\n",
    "You now have a **complete end-to-end AI Agent system** for invoice processing:\n",
    "\n",
    "### ü§ñ **Part 1: Rule Extraction Agent (RAG)**\n",
    "- **Input:** Contract documents (PDF/DOCX)\n",
    "- **Process:** Parse ‚Üí Chunk ‚Üí Index ‚Üí Retrieve ‚Üí Generate\n",
    "- **Output:** JSON rules file with payment terms, submission requirements, penalties\n",
    "- **Technology:** Ollama gemma3:270m + nomic-embed-text + ChromaDB\n",
    "\n",
    "### üìã **Part 2: Invoice Processing Agent**\n",
    "- **Input:** Invoice documents + Extracted rules\n",
    "- **Process:** Parse ‚Üí Extract fields ‚Üí Validate ‚Üí Decide\n",
    "- **Output:** Approval/rejection decisions + audit trail\n",
    "- **Goals:** Auto-approve compliant invoices, flag issues, generate reports\n",
    "\n",
    "### üìä **Business Value:**\n",
    "- **Reduce manual review time** by 70-80%\n",
    "- **Improve accuracy** through rule-based validation\n",
    "- **Faster payment processing** with auto-approval\n",
    "- **Better compliance** with contract terms\n",
    "- **Complete audit trail** for financial controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d011522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Create Sample Contracts and Invoices\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "\n",
    "# Create directories\n",
    "data_dir = Path(\"data\")\n",
    "contracts_dir = data_dir / \"contracts\"\n",
    "invoices_dir = data_dir / \"invoices\"\n",
    "\n",
    "contracts_dir.mkdir(parents=True, exist_ok=True)\n",
    "invoices_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Creating sample contracts and invoices...\\n\")\n",
    "\n",
    "\n",
    "# ========== CREATE SAMPLE CONTRACT ==========\n",
    "def create_sample_contract(filename, net_days=30):\n",
    "    \"\"\"Create a sample service contract PDF.\"\"\"\n",
    "    filepath = contracts_dir / filename\n",
    "    c = canvas.Canvas(str(filepath), pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawCentredString(width / 2, height - 50, \"SERVICE AGREEMENT\")\n",
    "\n",
    "    # Contract details\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    y = height - 100\n",
    "\n",
    "    lines = [\n",
    "        f\"This Service Agreement is entered into as of {datetime.now().strftime('%B %d, %Y')}\",\n",
    "        \"\",\n",
    "        \"BETWEEN:\",\n",
    "        \"ABC Corporation (Client)\",\n",
    "        \"123 Business Street, New York, NY 10001\",\n",
    "        \"\",\n",
    "        \"AND:\",\n",
    "        \"XYZ Services Inc. (Vendor)\",\n",
    "        \"456 Service Avenue, Los Angeles, CA 90001\",\n",
    "        \"\",\n",
    "        \"1. SERVICES\",\n",
    "        \"Vendor agrees to provide software development and consulting services.\",\n",
    "        \"\",\n",
    "        \"2. PAYMENT TERMS\",\n",
    "        f\"- Payment terms: Net {net_days} days from invoice date\",\n",
    "        \"- Invoices shall be submitted monthly\",\n",
    "        \"- All invoices must include a valid Purchase Order (PO) number\",\n",
    "        \"- Late payments will incur a penalty of 1.5% per month\",\n",
    "        \"\",\n",
    "        \"3. INVOICE SUBMISSION REQUIREMENTS\",\n",
    "        \"All invoices must include:\",\n",
    "        \"- Valid PO number (format: PO-YYYY-####)\",\n",
    "        \"- Detailed description of services\",\n",
    "        \"- Invoice date and due date\",\n",
    "        \"- Vendor tax identification number\",\n",
    "        \"\",\n",
    "        \"4. INVOICE APPROVAL PROCESS\",\n",
    "        \"- All invoices must be approved by the Project Manager\",\n",
    "        \"- Approval required within 5 business days\",\n",
    "        \"- Finance department will process payment after approval\",\n",
    "        \"\",\n",
    "        \"5. PENALTIES AND FEES\",\n",
    "        \"- Late payment penalty: 1.5% per month on overdue balance\",\n",
    "        \"- Missing PO number: Automatic rejection\",\n",
    "        \"\",\n",
    "        \"\",\n",
    "        \"___________________________        ___________________________\",\n",
    "        \"Client Representative              Vendor Representative\",\n",
    "        f\"Date: {datetime.now().strftime('%m/%d/%Y')}                    Date: {datetime.now().strftime('%m/%d/%Y')}\",\n",
    "    ]\n",
    "\n",
    "    text_obj = c.beginText(50, y)\n",
    "    text_obj.setFont(\"Helvetica\", 9)\n",
    "    for line in lines:\n",
    "        text_obj.textLine(line)\n",
    "    c.drawText(text_obj)\n",
    "    c.save()\n",
    "    print(f\"  Created: {filename} (Net {net_days} terms)\")\n",
    "\n",
    "\n",
    "# ========== CREATE SAMPLE INVOICES ==========\n",
    "def create_sample_invoice(filename, invoice_num, po_num, days_offset=0, amount=5000.00):\n",
    "    \"\"\"Create a sample invoice PDF.\"\"\"\n",
    "    filepath = invoices_dir / filename\n",
    "    c = canvas.Canvas(str(filepath), pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    invoice_date = datetime.now() + timedelta(days=days_offset)\n",
    "    due_date = invoice_date + timedelta(days=30)\n",
    "\n",
    "    # Header\n",
    "    c.setFont(\"Helvetica-Bold\", 20)\n",
    "    c.drawString(50, height - 50, \"INVOICE\")\n",
    "\n",
    "    # Vendor info\n",
    "    c.setFont(\"Helvetica-Bold\", 12)\n",
    "    c.drawString(50, height - 100, \"XYZ Services Inc.\")\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    c.drawString(50, height - 115, \"456 Service Avenue\")\n",
    "    c.drawString(50, height - 130, \"Los Angeles, CA 90001\")\n",
    "    c.drawString(50, height - 145, \"Tax ID: 12-3456789\")\n",
    "\n",
    "    # Invoice details\n",
    "    c.setFont(\"Helvetica-Bold\", 10)\n",
    "    c.drawString(400, height - 100, f\"Invoice #: {invoice_num}\")\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    c.drawString(\n",
    "        400, height - 115, f\"Invoice Date: {invoice_date.strftime('%m/%d/%Y')}\"\n",
    "    )\n",
    "    c.drawString(400, height - 130, f\"Due Date: {due_date.strftime('%m/%d/%Y')}\")\n",
    "    if po_num:\n",
    "        c.drawString(400, height - 145, f\"PO Number: {po_num}\")\n",
    "\n",
    "    # Bill To\n",
    "    c.setFont(\"Helvetica-Bold\", 10)\n",
    "    c.drawString(50, height - 180, \"Bill To:\")\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    c.drawString(50, height - 195, \"ABC Corporation\")\n",
    "    c.drawString(50, height - 210, \"123 Business Street\")\n",
    "    c.drawString(50, height - 225, \"New York, NY 10001\")\n",
    "\n",
    "    # Line items header\n",
    "    c.setFont(\"Helvetica-Bold\", 10)\n",
    "    y = height - 270\n",
    "    c.drawString(50, y, \"Description\")\n",
    "    c.drawString(350, y, \"Hours\")\n",
    "    c.drawString(420, y, \"Rate\")\n",
    "    c.drawString(500, y, \"Amount\")\n",
    "    c.line(50, y - 5, 550, y - 5)\n",
    "\n",
    "    # Item\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    y -= 25\n",
    "    c.drawString(50, y, \"Software Development Services\")\n",
    "    c.drawString(350, y, \"40\")\n",
    "    c.drawString(420, y, \"$125.00\")\n",
    "    c.drawString(500, y, f\"${amount:.2f}\")\n",
    "\n",
    "    # Total\n",
    "    y -= 50\n",
    "    c.setFont(\"Helvetica-Bold\", 11)\n",
    "    c.drawString(420, y, \"Total Amount Due:\")\n",
    "    c.drawString(500, y, f\"${amount:.2f}\")\n",
    "\n",
    "    # Payment terms\n",
    "    y -= 40\n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    c.drawString(50, y, \"Payment Terms: Net 30 days\")\n",
    "    c.drawString(50, y - 15, \"Late payments subject to 1.5% monthly penalty\")\n",
    "\n",
    "    c.save()\n",
    "    print(f\"  Created: {filename} (Invoice #{invoice_num}, ${amount:.2f})\")\n",
    "\n",
    "\n",
    "# ========== GENERATE DOCUMENTS ==========\n",
    "print(\"CONTRACTS:\")\n",
    "print(\"-\" * 70)\n",
    "create_sample_contract(\"sample_contract_net30.pdf\", net_days=30)\n",
    "create_sample_contract(\"sample_contract_net60.pdf\", net_days=60)\n",
    "\n",
    "print(\"\\nINVOICES:\")\n",
    "print(\"-\" * 70)\n",
    "create_sample_invoice(\n",
    "    \"invoice_001_valid.pdf\", \"INV-2025-001\", \"PO-2025-1234\", -10, 5000.00\n",
    ")\n",
    "create_sample_invoice(\"invoice_002_no_po.pdf\", \"INV-2025-002\", \"\", -5, 3500.00)\n",
    "create_sample_invoice(\n",
    "    \"invoice_003_overdue.pdf\", \"INV-2025-003\", \"PO-2025-1235\", -45, 7500.00\n",
    ")\n",
    "create_sample_invoice(\n",
    "    \"invoice_004_recent.pdf\", \"INV-2025-004\", \"PO-2025-1236\", -2, 4200.00\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary:\")\n",
    "print(\"=\" * 70)\n",
    "contracts = list(contracts_dir.glob(\"*.pdf\"))\n",
    "invoices = list(invoices_dir.glob(\"*.pdf\"))\n",
    "\n",
    "print(f\"\\nContracts: {len(contracts)} files in data/contracts/\")\n",
    "for f in sorted(contracts):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(f\"\\nInvoices: {len(invoices)} files in data/invoices/\")\n",
    "for f in sorted(invoices):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nTest scenarios:\")\n",
    "print(\"  1. invoice_001_valid.pdf - Should be APPROVED\")\n",
    "print(\"  2. invoice_002_no_po.pdf - Should be REJECTED (missing PO)\")\n",
    "print(\"  3. invoice_003_overdue.pdf - Should be FLAGGED (overdue)\")\n",
    "print(\"  4. invoice_004_recent.pdf - Should be APPROVED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a47a1",
   "metadata": {},
   "source": [
    "## Test the Complete Pipeline\n",
    "\n",
    "Now let's test the entire AI Agent pipeline:\n",
    "1. Extract rules from sample contracts\n",
    "2. Process sample invoices using extracted rules\n",
    "3. Generate validation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Complete RAG Pipeline Test - Extract Rules and Process Invoices\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE RAG PIPELINE TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Extract rules from contract using RAG\n",
    "print(\"\\nStep 1: Extracting rules from contract using RAG...\")\n",
    "print(\"-\" * 80)\n",
    "contract_path = \"data/contracts/sample_contract_net30.pdf\"\n",
    "\n",
    "try:\n",
    "    # Initialize RAG-powered agent\n",
    "    rag_agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "\n",
    "    # Extract rules using RAG\n",
    "    print(f\"üìÑ Analyzing contract: {contract_path}\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        rules = rag_agent.run(contract_path)\n",
    "\n",
    "    # Save rules\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "\n",
    "    print(f\"\\n‚úì Extracted {len(rules)} rules using RAG\")\n",
    "    for rule in rules:\n",
    "        print(f\"  - [{rule['type']}] {rule['description'][:60]}...\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è  Contract not found. Using fallback rules...\")\n",
    "    # Fallback to manual rules if contract not found\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "    print(f\"Created {len(rules)} fallback rules\")\n",
    "    for rule in rules:\n",
    "        print(f\"  - [{rule['type']}] {rule['description'][:60]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error extracting rules: {e}\")\n",
    "    print(\"Using fallback rules...\")\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Net 30 payment terms\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"medium\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"PO number required\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"medium\",\n",
    "        },\n",
    "    ]\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "\n",
    "# Step 2: Process sample invoices\n",
    "print(\"\\nStep 2: Processing sample invoices...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    # Initialize invoice processor\n",
    "    processor = InvoiceProcessor(rules_file=\"extracted_rules.json\")\n",
    "\n",
    "    # Process each sample invoice\n",
    "    invoice_files = [\n",
    "        \"data/invoices/invoice_001_valid.pdf\",\n",
    "        \"data/invoices/invoice_002_no_po.pdf\",\n",
    "        \"data/invoices/invoice_003_overdue.pdf\",\n",
    "        \"data/invoices/invoice_004_recent.pdf\",\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    for invoice_file in invoice_files:\n",
    "        try:\n",
    "            result = processor.process_invoice(invoice_file)\n",
    "            results.append(result)\n",
    "\n",
    "            # Display result\n",
    "            status_icon = {\n",
    "                \"APPROVED\": \"‚úÖ\",\n",
    "                \"FLAGGED\": \"‚ö†Ô∏è\",\n",
    "                \"REJECTED\": \"‚ùå\",\n",
    "                \"ERROR\": \"üî¥\",\n",
    "            }.get(result[\"status\"], \"‚ùì\")\n",
    "\n",
    "            print(f\"\\n{status_icon} {Path(invoice_file).name}:\")\n",
    "            print(f\"   Status: {result['status']}\")\n",
    "            print(f\"   Action: {result['action']}\")\n",
    "            if result.get(\"issues\"):\n",
    "                print(f\"   Issues: {', '.join(result['issues'])}\")\n",
    "            if result.get(\"warnings\"):\n",
    "                print(f\"   Warnings: {', '.join(result['warnings'])}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\n‚ùå {Path(invoice_file).name}: File not found (skipping)\")\n",
    "\n",
    "    if results:\n",
    "        # Summary\n",
    "        approved = sum(1 for r in results if r[\"status\"] == \"APPROVED\")\n",
    "        flagged = sum(1 for r in results if r[\"status\"] == \"FLAGGED\")\n",
    "        rejected = sum(1 for r in results if r[\"status\"] == \"REJECTED\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"PIPELINE TEST RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total Invoices: {len(results)}\")\n",
    "        print(f\"‚úÖ Approved: {approved}\")\n",
    "        print(f\"‚ö†Ô∏è  Flagged: {flagged}\")\n",
    "        print(f\"‚ùå Rejected: {rejected}\")\n",
    "        if len(results) > 0:\n",
    "            print(f\"\\nSuccess Rate: {approved/len(results)*100:.1f}%\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No invoices processed. Create sample documents first (Cell 19)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in invoice processing: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Pipeline test complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479665e",
   "metadata": {},
   "source": [
    "\n",
    "### Benefits:\n",
    "\n",
    "1. **Better Accuracy** - LLM sees relevant contract sections\n",
    "2. **No Token Limits** - Process large contracts efficiently\n",
    "3. **Semantic Understanding** - Finds related concepts even with different wording\n",
    "4. **Local & Private** - All processing happens on your machine\n",
    "5. **Cost-Free** - No API fees\n",
    "\n",
    "### Execution Order:\n",
    "\n",
    "1. Run Cell 1-6: Install packages and initialize Ollama models\n",
    "2. Run Cell 19: Create sample documents\n",
    "3. Run Cell 20: Test complete pipeline (rule extraction + invoice processing)\n",
    "4. Optionally run Cells 11-18 for step-by-step execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820502",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "To use the agent, run the following cells:\n",
    "1. Initialize the agent\n",
    "2. Process your contract document\n",
    "3. View and save the extracted rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1ae82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
