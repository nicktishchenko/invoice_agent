{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef35da08",
   "metadata": {},
   "source": [
    "# AI Agent for Invoice Processing with RAG + Local LLM (Ollama)\n",
    "\n",
    "This notebook implements a **Complete Invoice Processing Pipeline** using **RAG (Retrieval-Augmented Generation)** with local Ollama models.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The notebook performs two main functions:\n",
    "1. **Rule Extraction** - Extracts invoice processing rules from contract documents using RAG\n",
    "2. **Invoice Processing** - Processes invoices against extracted rules with intelligent validation\n",
    "\n",
    "**Version:** 2.0 - RAG Edition  \n",
    "**Author:** r4 Technologies, Inc 2025\n",
    "\n",
    "## Key Features:\n",
    "- **RAG Architecture** - Retrieval-Augmented Generation for context-aware rule extraction\n",
    "- **Local LLM** - Ollama gemma3:270m (no API keys needed)\n",
    "- **Vector Store** - FAISS for fast semantic search\n",
    "- **Document Processing** - Supports PDF, DOCX, and scanned images (OCR)\n",
    "- **Invoice Validation** - Rule-based compliance checking with detailed reporting\n",
    "- **Automatic Setup** - Auto-generates sample documents if needed\n",
    "- **Cross-Platform** - Works on Windows, Mac, and Linux\n",
    "\n",
    "## Notebook Structure:\n",
    "- **Cells 1-4:** Documentation and setup requirements\n",
    "- **Cells 5-6:** Package installation (document processing + RAG packages)\n",
    "- **Cell 7:** Import all required packages\n",
    "- **Cell 8:** Check and auto-generate sample documents if needed\n",
    "- **Cell 9:** Test Ollama connection and initialize models\n",
    "- **Cells 10-13:** Helper functions and RAG agent class definition\n",
    "- **Cells 14-18:** Part 1 - Rule extraction from contracts\n",
    "- **Cells 19-25:** Part 2 - Invoice processing and validation\n",
    "- **Cells 26-33:** Complete pipeline test and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2ae9",
   "metadata": {},
   "source": [
    "## Quick Start Guide\n",
    "\n",
    "### Execution Order:\n",
    "\n",
    "1. **Run Cells 5-6:** Install all required packages\n",
    "2. **Run Cell 7:** Import all libraries\n",
    "3. **Run Cell 8:** Check for sample documents (auto-generates if missing)\n",
    "4. **Run Cell 9:** Test Ollama connection (requires Ollama running)\n",
    "5. **Run Cells 14-18:** Extract rules from contract documents\n",
    "6. **Run Cells 19-25:** Process invoices using extracted rules\n",
    "7. **Run Cell 29:** Complete pipeline test (extract rules + process invoices)\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- **Python 3.10+**\n",
    "- **Ollama** installed and running (https://ollama.ai)\n",
    "- **Tesseract OCR** binary (for scanned document processing)\n",
    "- Required Ollama models:\n",
    "  ```bash\n",
    "  ollama pull gemma3:270m\n",
    "  ollama pull nomic-embed-text\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc30410",
   "metadata": {},
   "source": [
    "## Installation Requirements\n",
    "\n",
    "### Python Dependencies\n",
    "All dependencies are installed automatically by running the installation cells:\n",
    "\n",
    "- **Cell 5:** Document processing packages\n",
    "  - pdfplumber (PDF parsing)\n",
    "  - python-docx (Word document parsing)\n",
    "  - Pillow (image processing)\n",
    "  - reportlab (PDF generation)\n",
    "  - matplotlib (visualization)\n",
    "\n",
    "- **Cell 6:** RAG and ML packages\n",
    "  - langchain-core, langchain-community, langchain\n",
    "  - langchain-ollama (Ollama integration)\n",
    "  - faiss-cpu (vector store)\n",
    "  - pytesseract (OCR wrapper)\n",
    "  - numpy, pydantic, ipywidgets\n",
    "\n",
    "### External Dependencies\n",
    "\n",
    "**Tesseract OCR Binary** (required for scanned documents):\n",
    "- **macOS:** `brew install tesseract`\n",
    "- **Linux:** `sudo apt-get install tesseract-ocr`\n",
    "- **Windows:** Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
    "\n",
    "**Ollama** (required for local LLM):\n",
    "- Download and install from https://ollama.ai\n",
    "- Pull required models (see Cell 9 for instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6392028",
   "metadata": {},
   "source": [
    "## RAG Setup Requirements\n",
    "\n",
    "### Required Packages\n",
    "All RAG packages are installed automatically in **Cell 6**. The notebook uses:\n",
    "- LangChain framework for RAG orchestration\n",
    "- FAISS vector store for semantic search\n",
    "- Ollama for local LLM processing (no API keys needed)\n",
    "\n",
    "### Ollama Models\n",
    "Make sure Ollama is running and you have the required models:\n",
    "\n",
    "```bash\n",
    "# Pull the LLM model (for rule extraction)\n",
    "ollama pull gemma3:270m\n",
    "\n",
    "# Pull the embedding model (for vector search)\n",
    "ollama pull nomic-embed-text\n",
    "```\n",
    "\n",
    "**Note:** Cell 9 will test the Ollama connection and verify these models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81bc27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Document processing packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Install document processing packages\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Platform-independent pip installation\n",
    "result = subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"pdfplumber\",\n",
    "        \"python-docx\",\n",
    "        \"Pillow\",\n",
    "        \"reportlab\",\n",
    "        \"matplotlib\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(\"[OK] Document processing packages installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38b3614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All packages installed with numpy 1.26.4\n",
      "[OK] pytesseract installed (lightweight OCR)\n",
      "[OK] No dependency conflicts!\n",
      "\n",
      "[INFO] OCR Note: pytesseract requires Tesseract binary to be installed:\n",
      "  - macOS: brew install tesseract\n",
      "  - Linux: sudo apt-get install tesseract-ocr\n",
      "  - Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\n",
      "\n",
      "Make sure Ollama is running with models:\n",
      "  ollama pull gemma3:270m\n",
      "  ollama pull nomic-embed-text\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Install RAG packages (with pytesseract - stable and lightweight)\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Install core packages with numpy constraint\n",
    "subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"numpy==1.26.4\",\n",
    "        \"pdfplumber\",\n",
    "        \"Pillow\",\n",
    "        \"matplotlib\",\n",
    "        \"python-docx\",\n",
    "        \"reportlab\",\n",
    "        \"langchain-core==0.3.6\",\n",
    "        \"langchain-community==0.3.1\",\n",
    "        \"langchain==0.3.1\",\n",
    "        \"langchain-ollama==0.2.0\",\n",
    "        \"faiss-cpu\",\n",
    "        \"ipywidgets\",\n",
    "        \"pydantic==2.9.2\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "# Install pytesseract (lightweight, uses external Tesseract binary)\n",
    "subprocess.run(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-m\",\n",
    "        \"pip\",\n",
    "        \"install\",\n",
    "        \"-q\",\n",
    "        \"--disable-pip-version-check\",\n",
    "        \"pytesseract\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "print(\"[OK] All packages installed with numpy 1.26.4\")\n",
    "print(\"[OK] pytesseract installed (lightweight OCR)\")\n",
    "print(\"[OK] No dependency conflicts!\")\n",
    "print(\"\\n[INFO] OCR Note: pytesseract requires Tesseract binary to be installed:\")\n",
    "print(\"  - macOS: brew install tesseract\")\n",
    "print(\"  - Linux: sudo apt-get install tesseract-ocr\")\n",
    "print(\"  - Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki\")\n",
    "print(\"\\nMake sure Ollama is running with models:\")\n",
    "print(\"  ollama pull gemma3:270m\")\n",
    "print(\"  ollama pull nomic-embed-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3027e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All packages imported successfully\n",
      "Platform: Darwin\n",
      "[APPLE] Detected: Apple Silicon (ARM64)\n",
      "[OK] Environment configured - Using pytesseract for image processing\n"
     ]
    }
   ],
   "source": [
    "# Import all required packages\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "from collections import Counter\n",
    "from contextlib import redirect_stderr\n",
    "import multiprocessing\n",
    "\n",
    "# Document processing\n",
    "import pdfplumber  # For PDF parsing\n",
    "from docx import Document  # For Word (.docx) parsing\n",
    "from PIL import Image, ImageEnhance  # For image processing\n",
    "\n",
    "# RAG and ML\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document as LangchainDocument\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"[OK] All packages imported successfully\")\n",
    "\n",
    "# Cell 7: Configure environment variables + Platform-specific settings\n",
    "import os\n",
    "import warnings\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Detect platform\n",
    "PLATFORM = platform.system()  # 'Darwin' (Mac), 'Windows', 'Linux'\n",
    "IS_MAC = PLATFORM == \"Darwin\"\n",
    "IS_WINDOWS = PLATFORM == \"Windows\"\n",
    "IS_APPLE_SILICON = IS_MAC and platform.machine() == \"arm64\"\n",
    "\n",
    "print(f\"Platform: {PLATFORM}\")\n",
    "if IS_APPLE_SILICON:\n",
    "    print(\"[APPLE] Detected: Apple Silicon (ARM64)\")\n",
    "elif IS_MAC:\n",
    "    print(\"[APPLE] Detected: macOS (Intel)\")\n",
    "elif IS_WINDOWS:\n",
    "    print(\"[WIN] Detected: Windows\")\n",
    "\n",
    "# Environment variables (cross-platform)\n",
    "os.environ[\"USER_AGENT\"] = \"InvoiceProcessingRAGAgent\"\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "print(\"[OK] Environment configured - Using pytesseract for image processing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents already exist. Skipping generation.\n",
      "  Contracts: 5 files\n",
      "  Invoices: 10 files\n"
     ]
    }
   ],
   "source": [
    "# Check if sample documents exist, generate if needed\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Helper function to filter out temp/system files\n",
    "def is_valid_file(file_path: Path) -> bool:\n",
    "    \"\"\"Check if a file is valid (not a temp/system file).\"\"\"\n",
    "    name = file_path.name\n",
    "    if name.startswith('.') or name.startswith('~$'):\n",
    "        return False\n",
    "    system_files = {'.DS_Store', 'Thumbs.db', 'desktop.ini', '.gitkeep', '.gitignore'}\n",
    "    if name in system_files:\n",
    "        return False\n",
    "    temp_extensions = {'.tmp', '.bak', '.swp', '.~', '.old'}\n",
    "    if file_path.suffix.lower() in temp_extensions:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Define directories\n",
    "data_dir = Path(\"docs\")\n",
    "contracts_dir = data_dir / \"contracts\"\n",
    "invoices_dir = data_dir / \"invoices\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "contracts_dir.mkdir(parents=True, exist_ok=True)\n",
    "invoices_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if directories contain any valid files (excluding temp/system files)\n",
    "contracts_has_files = any(f.is_file() and is_valid_file(f) for f in contracts_dir.iterdir())\n",
    "invoices_has_files = any(f.is_file() and is_valid_file(f) for f in invoices_dir.iterdir())\n",
    "\n",
    "if not contracts_has_files or not invoices_has_files:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Sample documents not found. Generating sample documents...\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nRunning Generate_Sample_Documents.ipynb...\")\n",
    "    \n",
    "    # Execute the generation notebook using nbconvert\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"jupyter\", \"nbconvert\", \"--to\", \"notebook\", \"--execute\", \"--inplace\", \"Generate_Sample_Documents.ipynb\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=Path.cwd()\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n[OK] Sample documents generated successfully!\")\n",
    "        else:\n",
    "            print(f\"\\n[ERROR] Failed to generate documents.\")\n",
    "            print(f\"Error: {result.stderr[:500] if result.stderr else 'Unknown error'}\")\n",
    "            print(\"\\nPlease run Generate_Sample_Documents.ipynb manually.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[WARN] Could not auto-generate documents: {e}\")\n",
    "        print(\"\\nPlease run Generate_Sample_Documents.ipynb manually.\")\n",
    "else:\n",
    "    # Count only valid files (excluding temp/system files)\n",
    "    valid_contracts = [f for f in contracts_dir.glob('*.*') if f.is_file() and is_valid_file(f)]\n",
    "    valid_invoices = [f for f in invoices_dir.glob('*.*') if f.is_file() and is_valid_file(f)]\n",
    "    print(\"Sample documents already exist. Skipping generation.\")\n",
    "    print(f\"  Contracts: {len(valid_contracts)} files\")\n",
    "    print(f\"  Invoices: {len(valid_invoices)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All libraries imported successfully (Standard + RAG components)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Import necessary libraries (Standard + RAG)\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from multiprocessing import Manager\n",
    "from datetime import datetime, timedelta\n",
    "from contextlib import redirect_stderr\n",
    "\n",
    "import pdfplumber  # For PDF parsing\n",
    "from docx import Document  # For Word (.docx) parsing\n",
    "from PIL import ImageEnhance  # For contrast enhancement in scanned PDFs\n",
    "\n",
    "# RAG imports\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document as LangchainDocument\n",
    "\n",
    "# Set up logging (prevent duplicate handlers when re-running cells)\n",
    "# Clear any existing handlers to prevent duplicates\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Function: Filter out temp/system files\n",
    "# ============================================================================\n",
    "\n",
    "def is_valid_file(file_path: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a file is valid (not a temp/system file).\n",
    "    \n",
    "    Filters out:\n",
    "    - Hidden files (starting with .)\n",
    "    - System files (.DS_Store, Thumbs.db, etc.)\n",
    "    - Temp files (~$ files, .tmp, etc.)\n",
    "    - Backup files\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path object to check\n",
    "        \n",
    "    Returns:\n",
    "        True if file should be processed, False if it should be skipped\n",
    "    \"\"\"\n",
    "    name = file_path.name\n",
    "    \n",
    "    # Skip hidden files (starting with .)\n",
    "    if name.startswith('.'):\n",
    "        return False\n",
    "    \n",
    "    # Skip temp files (starting with ~$)\n",
    "    if name.startswith('~$'):\n",
    "        return False\n",
    "    \n",
    "    # Skip system files\n",
    "    system_files = {\n",
    "        '.DS_Store',           # macOS\n",
    "        'Thumbs.db',           # Windows\n",
    "        'desktop.ini',         # Windows\n",
    "        '.gitkeep',            # Git\n",
    "        '.gitignore',          # Git\n",
    "    }\n",
    "    if name in system_files:\n",
    "        return False\n",
    "    \n",
    "    # Skip temp/backup extensions\n",
    "    temp_extensions = {'.tmp', '.bak', '.swp', '.~', '.old'}\n",
    "    if file_path.suffix.lower() in temp_extensions:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def filter_valid_files(file_list: List[Path]) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Filter a list of files to exclude temp/system files.\n",
    "    \n",
    "    Args:\n",
    "        file_list: List of Path objects\n",
    "        \n",
    "    Returns:\n",
    "        Filtered list containing only valid files\n",
    "    \"\"\"\n",
    "    return [f for f in file_list if is_valid_file(f)]\n",
    "\n",
    "\n",
    "print(\"[OK] All libraries imported successfully (Standard + RAG components)\")\n",
    "print(\"[OK] File filtering helper functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3d17e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:01:42,077 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Ollama embeddings working (nomic-embed-text)\n",
      "Testing Ollama LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:01:48,692 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Ollama LLM working (gemma3:270m)\n",
      "\n",
      "[OK] All Ollama models ready!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Test Ollama connection and initialize models (cross-platform)\n",
    "\n",
    "try:\n",
    "    # Test embeddings (suppress noise output)\n",
    "    print(\"Testing Ollama embeddings...\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        test_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        test_embedding.embed_query(\"test\")\n",
    "    print(\"[OK] Ollama embeddings working (nomic-embed-text)\")\n",
    "\n",
    "    # Initialize LLM with response length limit for faster generation\n",
    "    print(\"Testing Ollama LLM...\")\n",
    "    with redirect_stderr(io.StringIO()):\n",
    "        llm = ChatOllama(\n",
    "            model=\"gemma3:270m\",\n",
    "            temperature=0,\n",
    "            num_predict=100,  # Limit response length for speed\n",
    "        )\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "    print(\"[OK] Ollama LLM working (gemma3:270m)\")\n",
    "\n",
    "    # Initialize embeddings for later use\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "    print(\"\\n[OK] All Ollama models ready!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Ollama error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Make sure Ollama is running:\")\n",
    "    if IS_WINDOWS:\n",
    "        print(\"     - Windows: Check system tray for Ollama icon\")\n",
    "        print(\"     - Or run: ollama serve\")\n",
    "    elif IS_MAC:\n",
    "        print(\"     - Mac: Check menu bar for Ollama icon\")\n",
    "        print(\"     - Or run: ollama serve\")\n",
    "\n",
    "    print(\"\\n  2. Pull required models:\")\n",
    "    print(\"     ollama pull gemma3:270m\")\n",
    "    print(\"     ollama pull nomic-embed-text\")\n",
    "\n",
    "    print(\"\\n  3. Verify Ollama is accessible:\")\n",
    "    print(\"     ollama list\")\n",
    "\n",
    "    if IS_APPLE_SILICON:\n",
    "        print(\"\\n  4. Apple Silicon specific:\")\n",
    "        print(\"     - Make sure you have the ARM64 version of Ollama\")\n",
    "        print(\"     - Download from: https://ollama.ai/download\")\n",
    "\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee7af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Garbled text detection function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Helper function to detect garbled text\n",
    "\n",
    "\n",
    "def is_garbled_text(\n",
    "    text: str, non_alpha_threshold: float = 0.4, min_word_length: int = 3\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Detect if text is likely garbled (low-confidence OCR output).\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to check.\n",
    "        non_alpha_threshold (float): Max proportion of non-alphanumeric characters.\n",
    "        min_word_length (int): Minimum average word length to consider valid.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if text is likely garbled, False otherwise.\n",
    "    \"\"\"\n",
    "    if not text.strip():\n",
    "        return True\n",
    "\n",
    "    # Check proportion of non-alphanumeric characters\n",
    "    non_alpha_count = len(re.findall(r\"[^a-zA-Z0-9\\s]\", text))\n",
    "    if non_alpha_count / max(len(text), 1) > non_alpha_threshold:\n",
    "        return True\n",
    "\n",
    "    # Check average word length\n",
    "    words = [w for w in text.split() if w.strip()]\n",
    "    if not words:\n",
    "        return True\n",
    "    avg_word_length = sum(len(w) for w in words) / len(words)\n",
    "    if avg_word_length < min_word_length:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "print(\"[OK] Garbled text detection function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea1462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Invoice terms validation function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Helper function to validate invoice-related terms\n",
    "\n",
    "\n",
    "def validate_invoice_terms(text: str, min_terms: int = 2) -> bool:\n",
    "    \"\"\"\n",
    "    Validate if text contains enough invoice-related terms.\n",
    "\n",
    "    Args:\n",
    "        text (str): Extracted text to validate.\n",
    "        min_terms (int): Minimum number of invoice-related terms required.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if sufficient invoice-related terms are found, False otherwise.\n",
    "    \"\"\"\n",
    "    invoice_keywords = [\n",
    "        r\"\\bpayment\\b\",\n",
    "        r\"\\binvoice\\b\",\n",
    "        r\"\\bdue\\b\",\n",
    "        r\"\\bnet\\s*\\d+\\b\",\n",
    "        r\"\\bterms\\b\",\n",
    "        r\"\\bapproval\\b\",\n",
    "        r\"\\bpenalty\\b\",\n",
    "        r\"\\bPO\\s*number\\b\",\n",
    "        r\"\\btax\\b\",\n",
    "        r\"\\bbilling\\b\",\n",
    "    ]\n",
    "    found_terms = sum(\n",
    "        1 for keyword in invoice_keywords if re.search(keyword, text, re.IGNORECASE)\n",
    "    )\n",
    "    return found_terms >= min_terms\n",
    "\n",
    "\n",
    "print(\"[OK] Invoice terms validation function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985e5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InvoiceRuleExtractorAgent class defined with FAISS vector store\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: InvoiceRuleExtractorAgent class definition (RAG-powered with FAISS vector store)\n",
    "\n",
    "\n",
    "class InvoiceRuleExtractorAgent:\n",
    "    \"\"\"\n",
    "    AI Agent for extracting invoice processing rules from contract documents using RAG.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm=None, embeddings=None):\n",
    "        \"\"\"\n",
    "        Initialize the agent with RAG components.\n",
    "\n",
    "        Args:\n",
    "            llm: ChatOllama instance (defaults to gemma3:270m)\n",
    "            embeddings: OllamaEmbeddings instance (defaults to nomic-embed-text)\n",
    "        \"\"\"\n",
    "        logger.info(\"Initializing RAG-powered Invoice Rule Extractor Agent\")\n",
    "\n",
    "        # Use provided models or create defaults\n",
    "        # Set num_predict to limit response length (faster generation)\n",
    "        self.llm = (\n",
    "            llm\n",
    "            if llm\n",
    "            else ChatOllama(\n",
    "                model=\"gemma3:270m\",\n",
    "                temperature=0,\n",
    "                num_predict=100,  # Limit to ~100 tokens for faster responses\n",
    "            )\n",
    "        )\n",
    "        self.embeddings = (\n",
    "            embeddings if embeddings else OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        )\n",
    "\n",
    "        # Expanded keyword patterns for better matching\n",
    "        self.rule_keywords = [\n",
    "            \"payment\",\n",
    "            \"terms\",\n",
    "            \"due\",\n",
    "            \"net\",\n",
    "            \"days\",\n",
    "            \"invoice\",\n",
    "            \"approval\",\n",
    "            \"submission\",\n",
    "            \"requirement\",\n",
    "            \"late\",\n",
    "            \"fee\",\n",
    "            \"penalty\",\n",
    "            \"penalties\",\n",
    "            \"PO\",\n",
    "            \"purchase order\",\n",
    "            \"tax\",\n",
    "            \"dispute\",\n",
    "            \"month\",\n",
    "            \"overdue\",\n",
    "            \"rejection\",\n",
    "        ]\n",
    "\n",
    "        # RAG chain will be created after document parsing\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "        self.num_chunks = 0\n",
    "\n",
    "    def parse_document(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Parse the contract document (PDF or Word), extract text, and create vector store for RAG.\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Extract text from document\n",
    "            if file_path.suffix.lower() == \".pdf\":\n",
    "                logger.info(f\"Parsing PDF: {file_path}\")\n",
    "                with pdfplumber.open(file_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text + \"\\n\"\n",
    "                        else:\n",
    "                            # Use pytesseract for scanned pages\n",
    "                            import pytesseract\n",
    "                            import tempfile\n",
    "\n",
    "                            img = page.to_image().original\n",
    "                            # Optimize image for OCR\n",
    "                            img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                            img = ImageEnhance.Sharpness(img).enhance(1.5)\n",
    "\n",
    "                            # Save and process with tesseract\n",
    "                            with tempfile.NamedTemporaryFile(\n",
    "                                suffix=\".png\", delete=False\n",
    "                            ) as tmp:\n",
    "                                img.save(tmp.name, \"PNG\", optimize=True)\n",
    "                                try:\n",
    "                                    # Use optimized tesseract config\n",
    "                                    extracted_text = pytesseract.image_to_string(\n",
    "                                        tmp.name, config=\"--psm 6\"\n",
    "                                    )\n",
    "                                    if extracted_text.strip():\n",
    "                                        text += extracted_text + \"\\n\"\n",
    "                                except Exception as ocr_err:\n",
    "                                    logger.warning(f\"OCR failed for page: {ocr_err}\")\n",
    "                                finally:\n",
    "                                    Path(tmp.name).unlink()  # Clean up temp file\n",
    "\n",
    "            elif file_path.suffix.lower() == \".docx\":\n",
    "                logger.info(f\"Parsing Word doc: {file_path}\")\n",
    "                doc = Document(file_path)\n",
    "                for para in doc.paragraphs:\n",
    "                    if para.text.strip():\n",
    "                        text += para.text + \"\\n\"\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unsupported file format: {file_path.suffix}. Use PDF or DOCX.\"\n",
    "                )\n",
    "\n",
    "            if not text.strip():\n",
    "                raise ValueError(\n",
    "                    \"No text extracted from document. Check scan quality or OCR setup.\"\n",
    "                )\n",
    "\n",
    "            logger.info(f\"Successfully parsed {len(text)} characters.\")\n",
    "\n",
    "            # Create document chunks for RAG\n",
    "            logger.info(\"Creating vector store for RAG...\")\n",
    "            self._create_vectorstore(text)\n",
    "\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing document: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _create_vectorstore(self, text: str):\n",
    "        \"\"\"Create vector store from document text using FAISS.\"\"\"\n",
    "        from langchain_community.vectorstores import FAISS\n",
    "\n",
    "        # Create a document object\n",
    "        doc = LangchainDocument(page_content=text, metadata={\"source\": \"contract\"})\n",
    "\n",
    "        # Split document into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "        )\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        self.num_chunks = len(splits)\n",
    "        logger.info(f\"Created {self.num_chunks} document chunks\")\n",
    "\n",
    "        # Create FAISS vector store (fast and reliable)\n",
    "        try:\n",
    "            with redirect_stderr(io.StringIO()):\n",
    "                self.vectorstore = FAISS.from_documents(\n",
    "                    documents=splits, embedding=self.embeddings\n",
    "                )\n",
    "            logger.info(\"[OK] Vector store created with FAISS\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to create FAISS vector store: {str(e)}\")\n",
    "\n",
    "        # Adaptive k: use min(3, num_chunks)\n",
    "        k_value = min(3, self.num_chunks)\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": k_value})\n",
    "        logger.info(\n",
    "            f\"Vector store created successfully (retrieving top {k_value} chunks)\"\n",
    "        )\n",
    "\n",
    "    def extract_rules(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Use RAG to extract invoice-related rules from the document.\n",
    "        \"\"\"\n",
    "        logger.info(\"Extracting rules using RAG...\")\n",
    "\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\n",
    "                \"Vector store not initialized. Call parse_document() first.\"\n",
    "            )\n",
    "\n",
    "        # Create RAG chain\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        prompt_template = ChatPromptTemplate.from_template(\n",
    "            \"\"\"Extract invoice processing rules from this contract.\n",
    "\n",
    "Contract text:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer concisely with key details only (1-2 sentences). If not found, say \"Not specified\".\"\"\"\n",
    "        )\n",
    "\n",
    "        rag_chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # Simplified questions for faster extraction\n",
    "        questions = {\n",
    "            \"payment_terms\": \"What are the payment terms (Net days, PO requirements)?\",\n",
    "            \"approval_process\": \"What is the invoice approval process?\",\n",
    "            \"late_penalties\": \"What are the late payment penalties?\",\n",
    "            \"submission_requirements\": \"What must be included on every invoice?\",\n",
    "        }\n",
    "\n",
    "        raw_rules = {}\n",
    "        for key, question in questions.items():\n",
    "            try:\n",
    "                with redirect_stderr(io.StringIO()):\n",
    "                    answer = rag_chain.invoke(question)\n",
    "\n",
    "                # Accept answer if it has substance\n",
    "                if (\n",
    "                    answer\n",
    "                    and len(answer.strip()) > 15\n",
    "                    and \"not specified\" not in answer.lower()\n",
    "                ):\n",
    "                    raw_rules[key] = answer.strip()\n",
    "                    logger.info(f\"Extracted {key}: {answer[:100]}...\")\n",
    "                else:\n",
    "                    raw_rules[key] = \"Not found\"\n",
    "                    logger.warning(f\"Rule {key} not found in contract\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error extracting {key}: {e}\")\n",
    "                raw_rules[key] = \"Not found\"\n",
    "\n",
    "        return raw_rules\n",
    "\n",
    "    def refine_rules(self, raw_rules: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Refine and structure the raw rules into a standardized format.\n",
    "        \"\"\"\n",
    "        logger.info(\"Refining rules...\")\n",
    "        structured_rules = []\n",
    "        rule_mapping = {\n",
    "            \"payment_terms\": {\"type\": \"payment_term\", \"priority\": \"high\"},\n",
    "            \"approval_process\": {\"type\": \"approval\", \"priority\": \"medium\"},\n",
    "            \"late_penalties\": {\"type\": \"penalty\", \"priority\": \"high\"},\n",
    "            \"submission_requirements\": {\"type\": \"submission\", \"priority\": \"medium\"},\n",
    "        }\n",
    "\n",
    "        for key, description in raw_rules.items():\n",
    "            if key in rule_mapping and description != \"Not found\":\n",
    "                # Accept if content is substantial (>15 chars)\n",
    "                if len(description.strip()) > 15:\n",
    "                    rule = {\n",
    "                        \"rule_id\": key,\n",
    "                        \"type\": rule_mapping[key][\"type\"],\n",
    "                        \"description\": description.strip(),\n",
    "                        \"priority\": rule_mapping[key][\"priority\"],\n",
    "                        \"confidence\": \"medium\",\n",
    "                    }\n",
    "                    structured_rules.append(rule)\n",
    "                    logger.info(\n",
    "                        f\"[OK] Structured rule: {rule['type']} - {rule['description'][:60]}...\"\n",
    "                    )\n",
    "                else:\n",
    "                    logger.warning(f\"Rule {key} too short: '{description}'\")\n",
    "\n",
    "        return structured_rules\n",
    "\n",
    "    def run(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Main execution method for the agent.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            text = self.parse_document(file_path)\n",
    "            raw_rules = self.extract_rules(text)\n",
    "            refined_rules = self.refine_rules(raw_rules)\n",
    "            logger.info(f\"Extraction complete. Found {len(refined_rules)} rules.\")\n",
    "            return refined_rules\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Agent run failed: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "print(\"[OK] InvoiceRuleExtractorAgent class defined with FAISS vector store\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42712e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Rule Extraction with RAG\n",
    "\n",
    "This section extracts invoice processing rules from contract documents using RAG.\n",
    "\n",
    "### Workflow:\n",
    "1. **Cell 14:** Initialize the RAG-powered agent\n",
    "2. **Cell 15:** Process a contract document and extract rules\n",
    "3. **Cell 16:** Save extracted rules to JSON file (`extracted_rules.json`)\n",
    "4. **Cell 17:** Display extracted rules in formatted output\n",
    "\n",
    "### Input:\n",
    "- Contract documents (PDF, DOCX, or scanned images) in `docs/contracts/` directory\n",
    "\n",
    "### Output:\n",
    "- `extracted_rules.json` - Structured rules ready for invoice validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476f9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:01:48,840 - INFO - Initializing RAG-powered Invoice Rule Extractor Agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] RAG-powered Agent initialized successfully\n",
      "  - LLM: gemma3:270m\n",
      "  - Embeddings: nomic-embed-text\n",
      "  - Vector Store: FAISS\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Initialize the RAG-powered agent\n",
    "\n",
    "# Use the global llm and embeddings initialized earlier\n",
    "agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "print(\"[OK] RAG-powered Agent initialized successfully\")\n",
    "print(f\"  - LLM: gemma3:270m\")\n",
    "print(f\"  - Embeddings: nomic-embed-text\")\n",
    "print(f\"  - Vector Store: FAISS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ececbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:01:48,846 - INFO - Parsing PDF: docs/contracts/sample_contract_net30.pdf\n",
      "2025-11-06 19:01:48,864 - INFO - Successfully parsed 1171 characters.\n",
      "2025-11-06 19:01:48,864 - INFO - Creating vector store for RAG...\n",
      "2025-11-06 19:01:48,865 - INFO - Created 2 document chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing contract: docs/contracts/sample_contract_net30.pdf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 19:01:49,082 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:49,086 - INFO - Loading faiss.\n",
      "2025-11-06 19:01:49,101 - INFO - Successfully loaded faiss.\n",
      "2025-11-06 19:01:49,106 - INFO - [OK] Vector store created with FAISS\n",
      "2025-11-06 19:01:49,106 - INFO - Vector store created successfully (retrieving top 2 chunks)\n",
      "2025-11-06 19:01:49,107 - INFO - Extracting rules using RAG...\n",
      "2025-11-06 19:01:49,137 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:49,526 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:49,694 - INFO - Extracted payment_terms: The payment terms are Net 30 days from invoice date and in monthly installments.\n",
      "...\n",
      "2025-11-06 19:01:49,723 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:49,969 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:50,071 - INFO - Extracted approval_process: The invoice approval process is to approve invoices by the Project Manager.\n",
      "...\n",
      "2025-11-06 19:01:50,096 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:50,358 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:50,487 - INFO - Extracted late_penalties: The late payment penalty is 1.5% per month on overdue balance.\n",
      "...\n",
      "2025-11-06 19:01:50,531 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:50,795 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-11-06 19:01:51,610 - INFO - Extracted submission_requirements: The invoice processing rules are:\n",
      "\n",
      "*   All invoices must include:\n",
      "    *   Valid PO number (format: P...\n",
      "2025-11-06 19:01:51,612 - INFO - Refining rules...\n",
      "2025-11-06 19:01:51,613 - INFO - [OK] Structured rule: payment_term - The payment terms are Net 30 days from invoice date and in m...\n",
      "2025-11-06 19:01:51,614 - INFO - [OK] Structured rule: approval - The invoice approval process is to approve invoices by the P...\n",
      "2025-11-06 19:01:51,615 - INFO - [OK] Structured rule: penalty - The late payment penalty is 1.5% per month on overdue balanc...\n",
      "2025-11-06 19:01:51,616 - INFO - [OK] Structured rule: submission - The invoice processing rules are:\n",
      "\n",
      "*   All invoices must inc...\n",
      "2025-11-06 19:01:51,616 - INFO - Extraction complete. Found 4 rules.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Extracted 4 rules using RAG:\n",
      "============================================================\n",
      "[\n",
      "  {\n",
      "    \"rule_id\": \"payment_terms\",\n",
      "    \"type\": \"payment_term\",\n",
      "    \"description\": \"The payment terms are Net 30 days from invoice date and in monthly installments.\",\n",
      "    \"priority\": \"high\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"approval_process\",\n",
      "    \"type\": \"approval\",\n",
      "    \"description\": \"The invoice approval process is to approve invoices by the Project Manager.\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"late_penalties\",\n",
      "    \"type\": \"penalty\",\n",
      "    \"description\": \"The late payment penalty is 1.5% per month on overdue balance.\",\n",
      "    \"priority\": \"high\",\n",
      "    \"confidence\": \"medium\"\n",
      "  },\n",
      "  {\n",
      "    \"rule_id\": \"submission_requirements\",\n",
      "    \"type\": \"submission\",\n",
      "    \"description\": \"The invoice processing rules are:\\n\\n*   All invoices must include:\\n    *   Valid PO number (format: PO-YYYY-####)\\n    *   Detailed description of services\\n    *   Invoice date and due date\\n    *   Vendor tax identification number\\n*   Invoices must be approved by the Project Manager\\n*   Approval required within 5 business days\\n*   Finance department will process payment after approval\\n*   Penalties and fees\\n*   Late\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"confidence\": \"medium\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Process a contract document with RAG - WITH DIAGNOSTICS\n",
    "\n",
    "# Use sample contract or specify your own path\n",
    "file_path = \"docs/contracts/sample_contract_net30.pdf\"  # Change this to your file path\n",
    "\n",
    "try:\n",
    "    print(f\"Processing contract: {file_path}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Use the agent initialized in Cell 14 (faster - no re-initialization)\n",
    "    # Note: If you need a clean state, uncomment the line below:\n",
    "    # agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "\n",
    "    rules = agent.run(file_path)\n",
    "\n",
    "    print(f\"\\n[OK] Extracted {len(rules)} rules using RAG:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(rules, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] File not found: {file_path}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error: {e}\")\n",
    "    print(\"\\nCreating fallback rules...\")\n",
    "\n",
    "    # Provide manual fallback rules\n",
    "    print(\"\\n1. Creating fallback rules (manual extraction)...\")\n",
    "    rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number, Detailed description of services\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"approval_process\",\n",
    "            \"type\": \"approval\",\n",
    "            \"description\": \"All invoices must be approved by the Project Manager within 5 business days. Finance department will process payment after approval.\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    print(f\"[OK] Created {len(rules)} fallback rules\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(json.dumps(rules, indent=2))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"[WARN] Using manually extracted rules due to error\")\n",
    "    print(\"NOTE: These fallback rules work fine for testing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fde6ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Rules saved to extracted_rules.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Save extracted rules to JSON file\n",
    "\n",
    "output_file = \"extracted_rules.json\"\n",
    "\n",
    "try:\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(rules, f, indent=2)\n",
    "    print(f\"[OK] Rules saved to {output_file}\")\n",
    "except NameError:\n",
    "    print(\"[WARN] No rules to save. Run Cell 15 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a29ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTED INVOICE PROCESSING RULES\n",
      "============================================================\n",
      "\n",
      "[Rule 1]\n",
      "Type: payment_term\n",
      "Priority: high\n",
      "Description: The payment terms are Net 30 days from invoice date and in monthly installments.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 2]\n",
      "Type: approval\n",
      "Priority: medium\n",
      "Description: The invoice approval process is to approve invoices by the Project Manager.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 3]\n",
      "Type: penalty\n",
      "Priority: high\n",
      "Description: The late payment penalty is 1.5% per month on overdue balance.\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Rule 4]\n",
      "Type: submission\n",
      "Priority: medium\n",
      "Description: The invoice processing rules are:\n",
      "\n",
      "*   All invoices must include:\n",
      "    *   Valid PO number (format: PO-YYYY-####)\n",
      "    *   Detailed description of services\n",
      "    *   Invoice date and due date\n",
      "    *   Vendor tax identification number\n",
      "*   Invoices must be approved by the Project Manager\n",
      "*   Approval required within 5 business days\n",
      "*   Finance department will process payment after approval\n",
      "*   Penalties and fees\n",
      "*   Late\n",
      "Confidence: medium\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Display extracted rules in a formatted way\n",
    "\n",
    "try:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXTRACTED INVOICE PROCESSING RULES\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        print(f\"\\n[Rule {i}]\")\n",
    "        print(f\"Type: {rule['type']}\")\n",
    "        print(f\"Priority: {rule['priority']}\")\n",
    "        print(f\"Description: {rule['description']}\")\n",
    "        print(f\"Confidence: {rule['confidence']}\")\n",
    "        print(\"-\" * 60)\n",
    "except NameError:\n",
    "    print(\"[WARN] No rules to display. Run Cell 15 first to extract rules.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b95f48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Invoice Processor - Apply Extracted Rules\n",
    "\n",
    "This section processes invoices against the extracted rules.\n",
    "\n",
    "### Components:\n",
    "- **Cell 19:** InvoiceProcessor class definition\n",
    "- **Cell 21:** Initialize processor with extracted rules\n",
    "- **Cell 22:** Process a single invoice (optional - for testing/debugging)\n",
    "- **Cell 23:** Batch process all invoices (recommended for production use)\n",
    "- **Cell 24:** Generate processing report\n",
    "\n",
    "### When to use each:\n",
    "- **Cell 22 (Single Invoice):** Use for testing, debugging, or when you need to process just one specific invoice with detailed output\n",
    "- **Cell 23 (Batch Processing):** Use for production workflows - processes all invoices and generates summary statistics\n",
    "\n",
    "### Input:\n",
    "- Invoice documents (PDF, DOCX, PNG, JPG, TIFF, BMP) in `docs/invoices/` directory\n",
    "- `extracted_rules.json` (generated in Part 1)\n",
    "\n",
    "### Output:\n",
    "- Validation results (APPROVED/FLAGGED/REJECTED)\n",
    "- Detailed processing reports\n",
    "- JSON output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InvoiceContractMatcher class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: InvoiceContractMatcher Class Definition\n",
    "\n",
    "# Import additional modules needed for contract matching\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# ============================================================================\n",
    "# InvoiceContractMatcher Class\n",
    "# ============================================================================\n",
    "\n",
    "class InvoiceContractMatcher:\n",
    "    \"\"\"\n",
    "    Matches invoices to their source contracts using multiple detection methods.\n",
    "    \n",
    "    Matching priority (stops at first successful match):\n",
    "    1. PO Number (confidence: 0.95) - searches contract CONTENT\n",
    "    2. Vendor + Program Code (confidence: 0.85)\n",
    "    3. Vendor + Date Range (confidence: 0.80)\n",
    "    4. Program Code only (confidence: 0.70)\n",
    "    5. Vendor only (confidence: 0.60) - last resort, may be ambiguous\n",
    "    6. No match \u2192 UNMATCHED status (requires manual review)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, contracts_data: Dict):\n",
    "        \"\"\"\n",
    "        Initialize matcher with contracts data.\n",
    "        \n",
    "        Args:\n",
    "            contracts_data: Dict with structure:\n",
    "                {\n",
    "                    \"contracts\": [\n",
    "                        {\n",
    "                            \"contract_id\": \"...\",\n",
    "                            \"contract_path\": \"...\",\n",
    "                            \"parties\": [...],\n",
    "                            \"program_code\": \"...\",\n",
    "                            \"date_range\": {\"start\": \"...\", \"end\": \"...\"},\n",
    "                            ...\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.contracts = contracts_data.get(\"contracts\", [])\n",
    "        self.contract_index = self._build_contract_index()\n",
    "        # Cache for parsed contract content (to avoid re-parsing)\n",
    "        self._contract_content_cache = {}\n",
    "    \n",
    "    def _build_contract_index(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Build searchable index of contract metadata.\n",
    "        \n",
    "        Includes:\n",
    "        - contract_id\n",
    "        - contract_path\n",
    "        - parties (normalized, lowercase)\n",
    "        - program_code (uppercase)\n",
    "        - date_range (start, end dates)\n",
    "        \"\"\"\n",
    "        index = {}\n",
    "        for contract in self.contracts:\n",
    "            contract_id = contract.get(\"contract_id\", \"UNKNOWN\")\n",
    "            index[contract_id] = {\n",
    "                \"contract_id\": contract_id,\n",
    "                \"contract_path\": contract.get(\"contract_path\", \"\"),\n",
    "                \"parties\": [p.lower() for p in contract.get(\"parties\", [])],\n",
    "                \"program_code\": contract.get(\"program_code\", \"\").upper(),\n",
    "                \"date_range\": contract.get(\"date_range\"),  # {\"start\": \"...\", \"end\": \"...\"}\n",
    "            }\n",
    "        return index\n",
    "    \n",
    "    def match_invoice_to_contract(self, invoice_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Detect which contract an invoice belongs to.\n",
    "        \n",
    "        Args:\n",
    "            invoice_data: Parsed invoice data from parse_invoice()\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"contract_id\": \"...\" or None,\n",
    "                \"contract_path\": \"...\" or None,\n",
    "                \"match_method\": \"PO_NUMBER|VENDOR_PROGRAM|VENDOR_DATE|PROGRAM_CODE|VENDOR_ONLY|UNMATCHED\",\n",
    "                \"confidence\": 0.0-1.0,\n",
    "                \"status\": \"MATCHED|AMBIGUOUS|UNMATCHED\",\n",
    "                \"matching_details\": {...},\n",
    "                \"alternative_matches\": [...]\n",
    "            }\n",
    "        \"\"\"\n",
    "        matches = []\n",
    "        \n",
    "        # 1. Try PO number matching (highest priority, unique identifier)\n",
    "        po_matches = self._match_by_po_number(invoice_data)\n",
    "        if po_matches:\n",
    "            matches.extend(po_matches)\n",
    "        \n",
    "        # 2. Try vendor + program code (if no PO match)\n",
    "        if not matches:\n",
    "            vendor_program_matches = self._match_by_vendor_and_program(invoice_data)\n",
    "            if vendor_program_matches:\n",
    "                matches.extend(vendor_program_matches)\n",
    "        \n",
    "        # 3. Try vendor + date range (if no previous matches)\n",
    "        if not matches:\n",
    "            vendor_date_matches = self._match_by_vendor_and_date(invoice_data)\n",
    "            if vendor_date_matches:\n",
    "                matches.extend(vendor_date_matches)\n",
    "        \n",
    "        # 4. Try program code only (if no previous matches)\n",
    "        if not matches:\n",
    "            program_matches = self._match_by_program_code(invoice_data)\n",
    "            if program_matches:\n",
    "                matches.extend(program_matches)\n",
    "        \n",
    "        # 5. Try vendor only (last resort, lowest confidence)\n",
    "        if not matches:\n",
    "            vendor_matches = self._match_by_vendor_only(invoice_data)\n",
    "            if vendor_matches:\n",
    "                matches.extend(vendor_matches)\n",
    "        \n",
    "        # Build result\n",
    "        result = {\n",
    "            \"contract_id\": None,\n",
    "            \"contract_path\": None,\n",
    "            \"match_method\": None,\n",
    "            \"confidence\": 0.0,\n",
    "            \"status\": \"UNMATCHED\",\n",
    "            \"matching_details\": {},\n",
    "            \"alternative_matches\": [],\n",
    "        }\n",
    "        \n",
    "        if len(matches) == 1:\n",
    "            # Unique match\n",
    "            contract_id, method, confidence = matches[0]\n",
    "            contract_info = self.contract_index.get(contract_id, {})\n",
    "            result[\"contract_id\"] = contract_id\n",
    "            result[\"contract_path\"] = contract_info.get(\"contract_path\", \"\")\n",
    "            result[\"match_method\"] = method\n",
    "            result[\"confidence\"] = confidence\n",
    "            result[\"status\"] = \"MATCHED\"\n",
    "            result[\"matching_details\"] = self._get_matching_details(invoice_data, contract_id)\n",
    "        \n",
    "        elif len(matches) > 1:\n",
    "            # Multiple matches - ambiguous\n",
    "            contract_id, method, confidence = matches[0]\n",
    "            contract_info = self.contract_index.get(contract_id, {})\n",
    "            result[\"contract_id\"] = contract_id\n",
    "            result[\"contract_path\"] = contract_info.get(\"contract_path\", \"\")\n",
    "            result[\"match_method\"] = method\n",
    "            result[\"confidence\"] = confidence\n",
    "            result[\"status\"] = \"AMBIGUOUS\"\n",
    "            result[\"alternative_matches\"] = [\n",
    "                {\"contract_id\": m[0], \"method\": m[1], \"confidence\": m[2]}\n",
    "                for m in matches[1:]\n",
    "            ]\n",
    "            result[\"matching_details\"] = self._get_matching_details(invoice_data, contract_id)\n",
    "        \n",
    "        else:\n",
    "            # No match - UNMATCHED (no fallback)\n",
    "            result[\"status\"] = \"UNMATCHED\"\n",
    "            result[\"matching_details\"] = {\n",
    "                \"reason\": \"No matching contract found. Manual review required.\",\n",
    "                \"invoice_po\": invoice_data.get(\"po_number\"),\n",
    "                \"invoice_vendor\": invoice_data.get(\"vendor_name\"),\n",
    "                \"invoice_date\": str(invoice_data.get(\"invoice_date\")) if invoice_data.get(\"invoice_date\") else None,\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _match_by_po_number(self, invoice_data: Dict) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Match by PO number - searches contract CONTENT (not filenames).\n",
    "        \n",
    "        Requires parsing contract documents to search for PO references in content.\n",
    "        \n",
    "        Returns: List of (contract_id, method, confidence) tuples\n",
    "        \"\"\"\n",
    "        invoice_po = invoice_data.get(\"po_number\")\n",
    "        if not invoice_po:\n",
    "            return []\n",
    "        \n",
    "        matches = []\n",
    "        invoice_po_upper = invoice_po.upper()\n",
    "        \n",
    "        # Parse each contract and search content for PO number\n",
    "        for contract in self.contracts:\n",
    "            contract_id = contract.get(\"contract_id\", \"UNKNOWN\")\n",
    "            contract_path = contract.get(\"contract_path\", \"\")\n",
    "            \n",
    "            if not contract_path:\n",
    "                continue\n",
    "            \n",
    "            # Parse contract document to get text content\n",
    "            contract_text = self._parse_contract_content(contract_path)\n",
    "            \n",
    "            # Search for PO number in contract content\n",
    "            if invoice_po_upper in contract_text.upper():\n",
    "                matches.append((contract_id, \"PO_NUMBER\", 0.95))\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def _parse_contract_content(self, contract_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Parse contract document and extract text content.\n",
    "        Reuses parsing logic from InvoiceRuleExtractorAgent.\n",
    "        \n",
    "        Supports: PDF and DOCX formats\n",
    "        \"\"\"\n",
    "        # Check cache first\n",
    "        if contract_path in self._contract_content_cache:\n",
    "            return self._contract_content_cache[contract_path]\n",
    "        \n",
    "        contract_file = Path(contract_path)\n",
    "        if not contract_file.exists():\n",
    "            logger.warning(f\"Contract file not found: {contract_path}\")\n",
    "            return \"\"\n",
    "        \n",
    "        text = \"\"\n",
    "        try:\n",
    "            # Extract text from document\n",
    "            if contract_file.suffix.lower() == \".pdf\":\n",
    "                logger.debug(f\"Parsing PDF contract: {contract_path}\")\n",
    "                import pdfplumber\n",
    "                with pdfplumber.open(contract_path) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text + \"\\n\"\n",
    "            \n",
    "            elif contract_file.suffix.lower() in [\".docx\", \".doc\"]:\n",
    "                logger.debug(f\"Parsing DOCX contract: {contract_path}\")\n",
    "                from docx import Document\n",
    "                doc = Document(contract_path)\n",
    "                text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            \n",
    "            else:\n",
    "                logger.warning(f\"Unsupported contract format: {contract_file.suffix}\")\n",
    "                return \"\"\n",
    "            \n",
    "            # Cache the parsed content\n",
    "            self._contract_content_cache[contract_path] = text\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing contract {contract_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _match_by_vendor_and_program(self, invoice_data: Dict) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Match by vendor AND program code - handles multiple contracts between same parties.\n",
    "        \n",
    "        Returns: List of (contract_id, method, confidence) tuples\n",
    "        \"\"\"\n",
    "        invoice_vendor = invoice_data.get(\"vendor_name\") or \"\"\n",
    "        invoice_vendor = invoice_vendor.lower() if invoice_vendor else \"\"\n",
    "        raw_text = invoice_data.get(\"raw_text\", \"\").upper()\n",
    "        \n",
    "        if not invoice_vendor:\n",
    "            return []\n",
    "        \n",
    "        # Extract program codes from invoice raw_text (2-4 uppercase letters)\n",
    "        program_codes = re.findall(r'\\b([A-Z]{2,4})\\b', raw_text)\n",
    "        \n",
    "        if not program_codes:\n",
    "            return []\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        for contract_id, contract_info in self.contract_index.items():\n",
    "            # Check vendor match\n",
    "            parties = contract_info.get(\"parties\", [])\n",
    "            vendor_matches = any(\n",
    "                party in invoice_vendor or invoice_vendor in party\n",
    "                for party in parties\n",
    "            )\n",
    "            \n",
    "            if not vendor_matches:\n",
    "                continue\n",
    "            \n",
    "            # Check program code match\n",
    "            contract_program = contract_info.get(\"program_code\", \"\")\n",
    "            if contract_program and contract_program in program_codes:\n",
    "                matches.append((contract_id, \"VENDOR_PROGRAM\", 0.85))\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def _match_by_vendor_and_date(self, invoice_data: Dict) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Match by vendor AND date range - requires contract date range info.\n",
    "        \n",
    "        Checks if:\n",
    "        1. Vendor matches contract party\n",
    "        2. Invoice date falls within contract date range\n",
    "        \n",
    "        Returns: List of (contract_id, method, confidence) tuples\n",
    "        \"\"\"\n",
    "        invoice_vendor = invoice_data.get(\"vendor_name\") or \"\"\n",
    "        invoice_vendor = invoice_vendor.lower() if invoice_vendor else \"\"\n",
    "        invoice_date = invoice_data.get(\"invoice_date\")\n",
    "        \n",
    "        if not invoice_vendor or not invoice_date:\n",
    "            return []\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        for contract_id, contract_info in self.contract_index.items():\n",
    "            # Check vendor match\n",
    "            parties = contract_info.get(\"parties\", [])\n",
    "            vendor_matches = any(\n",
    "                party in invoice_vendor or invoice_vendor in party\n",
    "                for party in parties\n",
    "            )\n",
    "            \n",
    "            if not vendor_matches:\n",
    "                continue\n",
    "            \n",
    "            # Check date range\n",
    "            date_range = contract_info.get(\"date_range\")\n",
    "            if date_range and self._date_in_range(invoice_date, date_range):\n",
    "                matches.append((contract_id, \"VENDOR_DATE\", 0.80))\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def _date_in_range(self, date: datetime, date_range: Dict) -> bool:\n",
    "        \"\"\"Check if date falls within contract date range.\"\"\"\n",
    "        start_date = date_range.get(\"start\")\n",
    "        end_date = date_range.get(\"end\")\n",
    "        \n",
    "        if not start_date or not end_date:\n",
    "            return False\n",
    "        \n",
    "        # Parse dates if strings\n",
    "        try:\n",
    "            if isinstance(start_date, str):\n",
    "                start_date = datetime.fromisoformat(start_date.split(\"T\")[0])\n",
    "            if isinstance(end_date, str):\n",
    "                end_date = datetime.fromisoformat(end_date.split(\"T\")[0])\n",
    "            \n",
    "            return start_date <= date <= end_date\n",
    "        except (ValueError, AttributeError) as e:\n",
    "            logger.warning(f\"Error parsing date range: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _match_by_program_code(self, invoice_data: Dict) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Match by program code only.\n",
    "        \n",
    "        Returns: List of (contract_id, method, confidence) tuples\n",
    "        \"\"\"\n",
    "        raw_text = invoice_data.get(\"raw_text\", \"\").upper()\n",
    "        if not raw_text:\n",
    "            return []\n",
    "        \n",
    "        # Extract potential program codes (2-4 uppercase letters)\n",
    "        program_codes = re.findall(r'\\b([A-Z]{2,4})\\b', raw_text)\n",
    "        \n",
    "        if not program_codes:\n",
    "            return []\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        for contract_id, contract_info in self.contract_index.items():\n",
    "            contract_program = contract_info.get(\"program_code\", \"\")\n",
    "            if contract_program and contract_program in program_codes:\n",
    "                matches.append((contract_id, \"PROGRAM_CODE\", 0.70))\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def _match_by_vendor_only(self, invoice_data: Dict) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Match by vendor only - last resort, low confidence.\n",
    "        \n",
    "        Returns: List of (contract_id, method, confidence) tuples\n",
    "        \"\"\"\n",
    "        invoice_vendor = invoice_data.get(\"vendor_name\") or \"\"\n",
    "        invoice_vendor = invoice_vendor.lower() if invoice_vendor else \"\"\n",
    "        if not invoice_vendor:\n",
    "            return []\n",
    "        \n",
    "        matches = []\n",
    "        \n",
    "        for contract_id, contract_info in self.contract_index.items():\n",
    "            parties = contract_info.get(\"parties\", [])\n",
    "            for party in parties:\n",
    "                if party in invoice_vendor or invoice_vendor in party:\n",
    "                    matches.append((contract_id, \"VENDOR_ONLY\", 0.60))\n",
    "                    break\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def _get_matching_details(self, invoice_data: Dict, contract_id: str) -> Dict:\n",
    "        \"\"\"Get details of why invoice matched this contract.\"\"\"\n",
    "        return {\n",
    "            \"po_number\": invoice_data.get(\"po_number\"),\n",
    "            \"vendor\": invoice_data.get(\"vendor_name\"),\n",
    "            \"invoice_date\": str(invoice_data.get(\"invoice_date\")) if invoice_data.get(\"invoice_date\") else None,\n",
    "            \"contract_id\": contract_id,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"[OK] InvoiceContractMatcher class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226b50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] InvoiceProcessor class defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: InvoiceProcessor Class Definition\n",
    "\n",
    "class InvoiceProcessor:\n",
    "    \"\"\"\n",
    "    AI-powered Invoice Processor that applies extracted rules to validate invoices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rules_file: str = \"extracted_rules.json\"):\n",
    "        \"\"\"\n",
    "        Initialize the processor with extracted rules and contract matcher.\n",
    "\n",
    "        Args:\n",
    "            rules_file: Path to JSON file with extracted rules (multi-contract format)\n",
    "        \"\"\"\n",
    "        self.rules_file = rules_file\n",
    "        # Load rules structure (multi-contract format only)\n",
    "        self.rules_data = self._load_rules_data(rules_file)\n",
    "        \n",
    "        # Initialize contract matcher\n",
    "        if not isinstance(self.rules_data, dict) or \"contracts\" not in self.rules_data:\n",
    "            raise ValueError(\n",
    "                f\"Invalid rules file format. Expected multi-contract format with 'contracts' key. \"\n",
    "                f\"File: {rules_file}\"\n",
    "            )\n",
    "        \n",
    "        self.matcher = InvoiceContractMatcher(self.rules_data)\n",
    "        logger.info(f\"Invoice Processor initialized with {len(self.rules_data.get('contracts', []))} contract(s)\")\n",
    "        \n",
    "        # Current contract-specific rules (loaded per invoice)\n",
    "        self.current_contract_id = None\n",
    "        self.current_rules = []\n",
    "        self.payment_terms = None\n",
    "\n",
    "    def _load_rules_data(self, rules_file: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Load rules structure from JSON file (multi-contract format only).\n",
    "        \n",
    "        Expected format:\n",
    "        {\n",
    "            \"extracted_at\": \"...\",\n",
    "            \"contracts\": [\n",
    "                {\n",
    "                    \"contract_id\": \"...\",\n",
    "                    \"contract_path\": \"...\",\n",
    "                    \"parties\": [...],\n",
    "                    \"program_code\": \"...\",\n",
    "                    \"date_range\": {...},\n",
    "                    \"rules\": [...]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        Returns:\n",
    "            Rules structure dict\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(rules_file, \"r\") as f:\n",
    "                rules_data = json.load(f)\n",
    "            \n",
    "            # Validate format\n",
    "            if not isinstance(rules_data, dict):\n",
    "                raise ValueError(f\"Rules file must be a JSON object, got {type(rules_data)}\")\n",
    "            \n",
    "            if \"contracts\" not in rules_data:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid rules file format. Missing 'contracts' key. \"\n",
    "                    f\"Expected multi-contract format. File: {rules_file}\"\n",
    "                )\n",
    "            \n",
    "            if not isinstance(rules_data[\"contracts\"], list):\n",
    "                raise ValueError(f\"'contracts' must be a list, got {type(rules_data['contracts'])}\")\n",
    "            \n",
    "            logger.info(f\"Loaded rules data from {rules_file}: {len(rules_data.get('contracts', []))} contract(s)\")\n",
    "            return rules_data\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Rules file not found: {rules_file}. \"\n",
    "                f\"Please run rule extraction (Cell 28) first to generate extracted_rules.json\"\n",
    "            )\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Invalid JSON in rules file {rules_file}: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading rules file {rules_file}: {e}\")\n",
    "\n",
    "    def _load_contract_rules(self, contract_id: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Load rules for a specific contract.\n",
    "        \n",
    "        Args:\n",
    "            contract_id: Contract ID to load rules for\n",
    "            \n",
    "        Returns:\n",
    "            List of rules for the specified contract\n",
    "        \"\"\"\n",
    "        if not isinstance(self.rules_data, dict) or \"contracts\" not in self.rules_data:\n",
    "            return []\n",
    "        \n",
    "        for contract in self.rules_data.get(\"contracts\", []):\n",
    "            if contract.get(\"contract_id\") == contract_id:\n",
    "                rules = contract.get(\"rules\", [])\n",
    "                logger.info(f\"Loaded {len(rules)} rules for contract {contract_id}\")\n",
    "                return rules\n",
    "        \n",
    "        logger.warning(f\"No rules found for contract {contract_id}\")\n",
    "        return []\n",
    "\n",
    "    def _extract_payment_terms(self, rules: Optional[List[Dict[str, Any]]] = None) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Extract net days from payment terms rule.\n",
    "        \n",
    "        Args:\n",
    "            rules: Rules to search (defaults to self.current_rules)\n",
    "        \"\"\"\n",
    "        if rules is None:\n",
    "            rules = self.current_rules\n",
    "            \n",
    "        for rule in rules:\n",
    "            if rule.get(\"type\") == \"payment_term\":\n",
    "                description = rule.get(\"description\", \"\")\n",
    "                # Look for \"net 30\", \"net 60\", etc.\n",
    "                match = re.search(r\"net\\s*(\\d+)\", description, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return int(match.group(1))\n",
    "        return None\n",
    "\n",
    "    def parse_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Parse invoice document and extract key fields.\n",
    "\n",
    "        Args:\n",
    "            invoice_path: Path to invoice PDF/image\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with invoice data\n",
    "        \"\"\"\n",
    "        logger.info(f\"Parsing invoice: {invoice_path}\")\n",
    "        invoice_path = Path(invoice_path)\n",
    "\n",
    "        if not invoice_path.exists():\n",
    "            raise FileNotFoundError(f\"Invoice not found: {invoice_path}\")\n",
    "\n",
    "        # Extract text from invoice\n",
    "        text = \"\"\n",
    "\n",
    "        # Handle image files (PNG, JPG, JPEG, TIFF, BMP) with pytesseract\n",
    "        if invoice_path.suffix.lower() in [\".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\"]:\n",
    "            try:\n",
    "                import pytesseract\n",
    "                from PIL import Image, ImageEnhance\n",
    "\n",
    "                logger.info(f\"Using pytesseract for image file: {invoice_path.name}\")\n",
    "\n",
    "                # Load and optimize image for OCR\n",
    "                img = Image.open(invoice_path)\n",
    "\n",
    "                # Convert to RGB if needed\n",
    "                if img.mode != \"RGB\":\n",
    "                    img = img.convert(\"RGB\")\n",
    "\n",
    "                # Enhance image quality for better OCR\n",
    "                img = ImageEnhance.Contrast(img).enhance(2.0)\n",
    "                img = ImageEnhance.Sharpness(img).enhance(1.5)\n",
    "\n",
    "                # Extract text using tesseract with optimized config\n",
    "                # --psm 6: Assume a single uniform block of text\n",
    "                # --oem 3: Use LSTM OCR Engine\n",
    "                text = pytesseract.image_to_string(img, config=\"--psm 6 --oem 3\")\n",
    "\n",
    "                logger.info(f\"pytesseract extracted {len(text)} characters\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"pytesseract extraction failed: {e}\")\n",
    "                logger.info(\"Make sure Tesseract is installed:\")\n",
    "                logger.info(\"  macOS: brew install tesseract\")\n",
    "                logger.info(\"  Linux: sudo apt-get install tesseract-ocr\")\n",
    "                text = \"\"\n",
    "\n",
    "        # Handle PDF files\n",
    "        elif invoice_path.suffix.lower() == \".pdf\":\n",
    "            with pdfplumber.open(invoice_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "\n",
    "        # Extract key invoice fields using regex patterns\n",
    "        invoice_data = {\n",
    "            \"file\": invoice_path.name,\n",
    "            \"invoice_number\": self._extract_field(\n",
    "                text, r\"invoice\\s*#\\s*:?\\s*([A-Z0-9-]+)\", \"Invoice Number\"\n",
    "            ),\n",
    "            \"po_number\": self._extract_field(\n",
    "                text, r\"(?:purchase\\s+order\\s+number|po\\s*(?:number|#)?):?\\s*(PO-[\\w-]+)\", \"PO Number\"\n",
    "            ),\n",
    "            \"invoice_date\": self._extract_date(\n",
    "                text, r\"invoice\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"due_date\": self._extract_date(\n",
    "                text, r\"due\\s*date:?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\"\n",
    "            ),\n",
    "            \"total_amount\": self._extract_amount(text),\n",
    "            \"vendor_name\": self._extract_vendor_name(text),\n",
    "            \"raw_text\": text[:500],  # First 500 chars for reference\n",
    "        }\n",
    "\n",
    "        return invoice_data\n",
    "\n",
    "    def _extract_field(self, text: str, pattern: str, field_name: str) -> Optional[str]:\n",
    "        \"\"\"Extract a field using regex pattern.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        logger.warning(f\"{field_name} not found in invoice\")\n",
    "        return None\n",
    "\n",
    "    def _extract_vendor_name(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract vendor name from invoice with multiple pattern attempts.\"\"\"\n",
    "        patterns = [\n",
    "            # Pattern 1: After \"INVOICE\" heading, capture text before \"Invoice #\"\n",
    "            r\"INVOICE\\s*\\n\\s*(.+?)\\s+Invoice\\s*#\",\n",
    "            # Pattern 2: \"From:\" line (common in some formats)\n",
    "            r\"from:?\\s*([^\\n]+)\",\n",
    "            # Pattern 3: First line containing \"Inc.\" or \"LLC\" or \"Ltd\" or \"Corp\"\n",
    "            r\"(?:^|\\n)([^\\n]*?(?:Inc\\.|LLC|Ltd\\.|Corp\\.|Corporation|Company)[^\\n]*?)(?:\\s+Invoice|$)\",\n",
    "            # Pattern 4: Text between INVOICE and first address/date line\n",
    "            r\"INVOICE\\s*\\n\\s*([^\\n]+?)(?:\\s+\\d{1,4}\\s|$)\",\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                vendor = match.group(1).strip()\n",
    "                # Clean up and validate\n",
    "                # Remove trailing text after company name indicators\n",
    "                vendor = re.sub(\n",
    "                    r\"\\s+(Invoice|Tax|PO|Date).*$\", \"\", vendor, flags=re.IGNORECASE\n",
    "                )\n",
    "                # Filter out invalid extractions\n",
    "                if (\n",
    "                    vendor\n",
    "                    and len(vendor) > 3\n",
    "                    and not vendor.lower().startswith(\"invoice\")\n",
    "                ):\n",
    "                    return vendor\n",
    "\n",
    "        logger.warning(\"Vendor not found in invoice\")\n",
    "        return None\n",
    "\n",
    "    def _extract_date(self, text: str, pattern: str) -> Optional[datetime]:\n",
    "        \"\"\"Extract and parse a date field.\"\"\"\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            date_str = match.group(1)\n",
    "            # Try common date formats\n",
    "            for fmt in [\n",
    "                \"%m/%d/%Y\",\n",
    "                \"%d/%m/%Y\",\n",
    "                \"%m-%d-%Y\",\n",
    "                \"%d-%m-%Y\",\n",
    "                \"%m/%d/%y\",\n",
    "                \"%d/%m/%y\",\n",
    "            ]:\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, fmt)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def _extract_amount(self, text: str) -> Optional[float]:\n",
    "        \"\"\"Extract total amount from invoice.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:total\\s*amount\\s*due|total|amount\\s*due|balance\\s*due)[:\\s]*\\$\\s*([\\d,]+\\.?\\d*)\",\n",
    "            r\"\\$\\s*([\\d,]+\\.\\d{2})\\s*$\",  # Last dollar amount in text\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                amount_str = match.group(1).replace(\",\", \"\")\n",
    "                try:\n",
    "                    return float(amount_str)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    def validate_invoice(self, invoice_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate invoice against extracted rules.\n",
    "\n",
    "        Args:\n",
    "            invoice_data: Parsed invoice data\n",
    "\n",
    "        Returns:\n",
    "            Validation result with status and issues\n",
    "        \"\"\"\n",
    "        logger.info(f\"Validating invoice: {invoice_data['file']}\")\n",
    "\n",
    "        issues = []\n",
    "        warnings = []\n",
    "\n",
    "        # Check for required fields based on submission requirements rule\n",
    "        required_fields = self._get_required_fields()\n",
    "        for field in required_fields:\n",
    "            if not invoice_data.get(field):\n",
    "                issue_msg = f\"Missing required field: {field}\"\n",
    "                issues.append(issue_msg)\n",
    "                # Print critical validation issues to stdout (bypasses logging suppression)\n",
    "                print(f\"[!] VALIDATION ISSUE: {invoice_data['file']} - {issue_msg}\")\n",
    "\n",
    "        # Validate payment terms\n",
    "        if (\n",
    "            self.payment_terms\n",
    "            and invoice_data.get(\"invoice_date\")\n",
    "            and invoice_data.get(\"due_date\")\n",
    "        ):\n",
    "            expected_due = invoice_data[\"invoice_date\"] + timedelta(\n",
    "                days=self.payment_terms\n",
    "            )\n",
    "            actual_due = invoice_data[\"due_date\"]\n",
    "\n",
    "            if abs((actual_due - expected_due).days) > 2:  # Allow 2-day tolerance\n",
    "                issue_msg = (\n",
    "                    f\"Due date mismatch: Expected {expected_due.strftime('%m/%d/%Y')}, \"\n",
    "                    f\"got {actual_due.strftime('%m/%d/%Y')} (Net {self.payment_terms} terms)\"\n",
    "                )\n",
    "                issues.append(issue_msg)\n",
    "                print(f\"[!] VALIDATION ISSUE: {invoice_data['file']} - {issue_msg}\")\n",
    "\n",
    "        # Check if invoice is overdue\n",
    "        if invoice_data.get(\"due_date\"):\n",
    "            if invoice_data[\"due_date\"] < datetime.now():\n",
    "                days_overdue = (datetime.now() - invoice_data[\"due_date\"]).days\n",
    "                warnings.append(f\"Invoice is {days_overdue} days overdue\")\n",
    "\n",
    "                # Check for late penalties\n",
    "                penalty_rule = self._get_penalty_rule()\n",
    "                if penalty_rule:\n",
    "                    warnings.append(f\"Late penalty may apply: {penalty_rule}\")\n",
    "\n",
    "        # Determine approval status\n",
    "        if issues:\n",
    "            status = \"REJECTED\"\n",
    "            action = \"Manual review required\"\n",
    "        elif warnings:\n",
    "            status = \"FLAGGED\"\n",
    "            action = \"Review recommended\"\n",
    "        else:\n",
    "            status = \"APPROVED\"\n",
    "            action = \"Auto-approved for payment\"\n",
    "\n",
    "        result = {\n",
    "            \"invoice_file\": invoice_data[\"file\"],\n",
    "            \"invoice_number\": invoice_data.get(\"invoice_number\"),\n",
    "            \"status\": status,\n",
    "            \"action\": action,\n",
    "            \"issues\": issues,\n",
    "            \"warnings\": warnings,\n",
    "            \"invoice_data\": invoice_data,\n",
    "            \"validation_timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        logger.info(f\"Validation complete: {status}\")\n",
    "        return result\n",
    "\n",
    "    def _get_required_fields(self) -> List[str]:\n",
    "        \"\"\"Extract required fields from submission requirements rule.\"\"\"\n",
    "        # Core required fields for any valid invoice\n",
    "        required = [\"invoice_number\", \"invoice_date\", \"total_amount\", \"vendor_name\"]\n",
    "\n",
    "        for rule in self.current_rules:\n",
    "            if rule.get(\"type\") == \"submission\":\n",
    "                description = rule.get(\"description\", \"\").lower()\n",
    "                if \"po\" in description or \"purchase order\" in description:\n",
    "                    required.append(\"po_number\")\n",
    "\n",
    "        return required\n",
    "\n",
    "    def _get_penalty_rule(self) -> Optional[str]:\n",
    "        \"\"\"Get late payment penalty description.\"\"\"\n",
    "        for rule in self.current_rules:\n",
    "            if rule.get(\"type\") == \"penalty\":\n",
    "                return rule.get(\"description\")\n",
    "        return None\n",
    "\n",
    "    def process_invoice(self, invoice_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Complete invoice processing pipeline with contract matching.\n",
    "        \n",
    "        Args:\n",
    "            invoice_path: Path to invoice file\n",
    "\n",
    "        Returns:\n",
    "            Processing result with validation and decision, including contract match info\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1. Parse invoice\n",
    "            invoice_data = self.parse_invoice(invoice_path)\n",
    "            \n",
    "            # 2. Match invoice to contract\n",
    "            contract_match = self.matcher.match_invoice_to_contract(invoice_data)\n",
    "            \n",
    "            if contract_match[\"status\"] == \"MATCHED\" or contract_match[\"status\"] == \"AMBIGUOUS\":\n",
    "                # Load contract-specific rules\n",
    "                contract_id = contract_match[\"contract_id\"]\n",
    "                self.current_contract_id = contract_id\n",
    "                self.current_rules = self._load_contract_rules(contract_id)\n",
    "                self.payment_terms = self._extract_payment_terms()\n",
    "                \n",
    "                logger.info(f\"Invoice matched to contract {contract_id} via {contract_match['match_method']} (confidence: {contract_match['confidence']})\")\n",
    "            elif contract_match[\"status\"] == \"UNMATCHED\":\n",
    "                # No contract match - cannot validate\n",
    "                logger.warning(f\"Invoice {invoice_data.get('file')} could not be matched to any contract\")\n",
    "                return {\n",
    "                    \"invoice_file\": invoice_data[\"file\"],\n",
    "                    \"invoice_number\": invoice_data.get(\"invoice_number\"),\n",
    "                    \"status\": \"UNMATCHED\",\n",
    "                    \"action\": \"Manual review required - no matching contract found\",\n",
    "                    \"issues\": [contract_match[\"matching_details\"].get(\"reason\", \"No matching contract found\")],\n",
    "                    \"warnings\": [],\n",
    "                    \"invoice_data\": invoice_data,\n",
    "                    \"contract_match\": contract_match,\n",
    "                    \"validation_timestamp\": datetime.now().isoformat(),\n",
    "                }\n",
    "            \n",
    "            # 3. Validate against rules\n",
    "            result = self.validate_invoice(invoice_data)\n",
    "            \n",
    "            # 4. Add contract match info to result\n",
    "            result[\"contract_match\"] = contract_match\n",
    "            result[\"contract_id\"] = contract_match.get(\"contract_id\")\n",
    "            result[\"match_method\"] = contract_match.get(\"match_method\")\n",
    "            result[\"match_confidence\"] = contract_match.get(\"confidence\")\n",
    "            \n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing invoice: {e}\")\n",
    "            return {\n",
    "                \"invoice_file\": str(invoice_path),\n",
    "                \"status\": \"ERROR\",\n",
    "                \"action\": \"System error - manual review required\",\n",
    "                \"issues\": [str(e)],\n",
    "                \"warnings\": [],\n",
    "                \"validation_timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "\n",
    "    def batch_process(self, invoice_folder: str):\n",
    "        \"\"\"\n",
    "        Process multiple invoices from a folder.\n",
    "            invoice_folder: Path to folder containing invoices\n",
    "        Args:\n",
    "            invoice_folder: Path to folder containing invoices\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (results list, summary dict)\n",
    "        \"\"\"\n",
    "        folder = Path(invoice_folder)\n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Folder not found: {invoice_folder}\")\n",
    "\n",
    "        results = []\n",
    "        # Collect all invoice files and filter out temp/system files\n",
    "        all_files = (\n",
    "            list(folder.glob(\"*.pdf\"))\n",
    "            + list(folder.glob(\"*.png\"))\n",
    "            + list(folder.glob(\"*.jpg\"))\n",
    "        )\n",
    "        # Filter out temp/system files (using helper function from Cell 8)\n",
    "        invoice_files = [f for f in all_files if f.is_file() and is_valid_file(f)]\n",
    "\n",
    "        logger.info(f\"Processing {len(invoice_files)} invoices from {invoice_folder}\")\n",
    "\n",
    "        for invoice_file in invoice_files:\n",
    "            result = self.process_invoice(str(invoice_file))\n",
    "            results.append(result)\n",
    "\n",
    "        # Generate summary\n",
    "        summary = {\n",
    "            \"total\": len(results),\n",
    "            \"approved\": sum(1 for r in results if r[\"status\"] == \"APPROVED\"),\n",
    "            \"flagged\": sum(1 for r in results if r[\"status\"] == \"FLAGGED\"),\n",
    "            \"rejected\": sum(1 for r in results if r[\"status\"] == \"REJECTED\"),\n",
    "            \"errors\": sum(1 for r in results if r[\"status\"] == \"ERROR\"),\n",
    "        }\n",
    "        return results, summary\n",
    "\n",
    "\n",
    "print(\"[OK] InvoiceProcessor class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING InvoiceContractMatcher\n",
      "================================================================================\n",
      "\n",
      "Found 4 contract file(s) in docs/contracts/\n",
      "  - sample_contract_net60.pdf\n",
      "  - sample_contract_net30.pdf\n",
      "  - sample_contract_net60.docx\n",
      "  - sample_contract_net30.docx\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 1: PO Number Matching\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Invoice PO: PO-2021-1234\n",
      "Invoice Vendor: R4 Technologies\n",
      "\n",
      "Match Result:\n",
      "  Status: MATCHED\n",
      "  Contract ID: CONTRACT_NET30\n",
      "  Match Method: VENDOR_DATE\n",
      "  Confidence: 0.8\n",
      "  Details: {'po_number': 'PO-2021-1234', 'vendor': 'R4 Technologies', 'invoice_date': '2022-06-15 00:00:00', 'contract_id': 'CONTRACT_NET30'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 2: Vendor + Program Code Matching\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Invoice Vendor: R4 Technologies\n",
      "Invoice Text contains: BCH\n",
      "\n",
      "Match Result:\n",
      "  Status: MATCHED\n",
      "  Contract ID: CONTRACT_NET30\n",
      "  Match Method: VENDOR_PROGRAM\n",
      "  Confidence: 0.85\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 3: Vendor + Date Range Matching\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Invoice Vendor: BAYER\n",
      "Invoice Date: 2022-06-15\n",
      "\n",
      "Match Result:\n",
      "  Status: MATCHED\n",
      "  Contract ID: CONTRACT_NET30\n",
      "  Match Method: VENDOR_DATE\n",
      "  Confidence: 0.8\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 4: Unmatched Invoice (No Contract Found)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Invoice Vendor: Unknown Vendor\n",
      "Invoice Date: 2025-01-15\n",
      "\n",
      "Match Result:\n",
      "  Status: UNMATCHED\n",
      "  Contract ID: None\n",
      "  Match Method: None\n",
      "  Details: {'reason': 'No matching contract found. Manual review required.', 'invoice_po': None, 'invoice_vendor': 'Unknown Vendor', 'invoice_date': '2025-01-15 00:00:00'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TEST 5: Test with Actual extracted_rules.json\n",
      "--------------------------------------------------------------------------------\n",
      "Converting very old format (list) to new format...\n",
      "\u2713 Converted list format to new format\n",
      "\u2713 Loaded 1 contract(s)\n",
      "\n",
      "Test Match Result:\n",
      "  Status: UNMATCHED\n",
      "  Contract ID: None\n",
      "\n",
      "================================================================================\n",
      "MATCHER TESTING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 20.5: Test InvoiceContractMatcher\n",
    "\n",
    "# Test the contract matching logic before integrating with InvoiceProcessor\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TESTING InvoiceContractMatcher\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use REAL contracts from docs/contracts directory\n",
    "# Check what contracts we actually have\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "contracts_dir = Path(\"docs/contracts\")\n",
    "all_contracts = list(contracts_dir.glob(\"*.pdf\")) + list(contracts_dir.glob(\"*.docx\"))\n",
    "# Filter out temp/system files (using helper function from Cell 8)\n",
    "real_contracts = [f for f in all_contracts if f.is_file() and is_valid_file(f)]\n",
    "print(f\"\\nFound {len(real_contracts)} contract file(s) in docs/contracts/\")\n",
    "for contract in real_contracts:\n",
    "    print(f\"  - {contract.name}\")\n",
    "\n",
    "# Helper function to extract basic metadata from contract files\n",
    "def extract_contract_metadata(contract_path: Path) -> Dict:\n",
    "    \"\"\"Extract parties, program codes, and dates from contract file.\"\"\"\n",
    "    metadata = {\n",
    "        \"contract_id\": f\"CONTRACT_{contract_path.stem.upper()}\",\n",
    "        \"contract_path\": str(contract_path),\n",
    "        \"parties\": [],\n",
    "        \"program_code\": \"\",\n",
    "        \"date_range\": None,\n",
    "    }\n",
    "    \n",
    "    # Try to parse contract content to extract metadata\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if contract_path.suffix.lower() == \".pdf\":\n",
    "            import pdfplumber\n",
    "            with pdfplumber.open(contract_path) as pdf:\n",
    "                for page in pdf.pages[:3]:  # First 3 pages usually have party info\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "        elif contract_path.suffix.lower() in [\".docx\", \".doc\"]:\n",
    "            from docx import Document\n",
    "            doc = Document(contract_path)\n",
    "            text = \"\\n\".join([para.text for para in doc.paragraphs[:20]])  # First 20 paragraphs\n",
    "        \n",
    "        text_upper = text.upper()\n",
    "        \n",
    "        # Extract program code from contract content first (more reliable)\n",
    "        program_match = re.search(r'PROGRAM CODE:\\s*([A-Z]{2,4})', text_upper)\n",
    "        if program_match:\n",
    "            metadata[\"program_code\"] = program_match.group(1)\n",
    "        else:\n",
    "            # Fallback: Extract from filename (convert to uppercase first)\n",
    "            filename_upper = contract_path.name.upper()\n",
    "            program_match = re.search(r'\\b([A-Z]{2,4})\\b', filename_upper)\n",
    "            if program_match:\n",
    "                code = program_match.group(1)\n",
    "                # Filter out common words\n",
    "                if code not in [\"FOR\", \"PDF\", \"SOW\", \"MSA\", \"THE\", \"NET\", \"CONTRACT\"]:\n",
    "                    metadata[\"program_code\"] = code\n",
    "        \n",
    "        # Extract parties (common patterns)\n",
    "        parties = set()\n",
    "        if \"BAYER\" in text_upper:\n",
    "            parties.add(\"BAYER\")\n",
    "        if \"R4\" in text_upper or \"R4 TECHNOLOGIES\" in text_upper:\n",
    "            parties.add(\"R4 Technologies\")\n",
    "        if \"ACME\" in text_upper:\n",
    "            parties.add(\"ACME Corp\")\n",
    "        if \"CLIENT\" in text_upper and \"CLIENT INC\" in text_upper:\n",
    "            parties.add(\"Client Inc\")\n",
    "        \n",
    "        # Extract dates from text (YYYY-MM-DD or YYYY/MM/DD)\n",
    "        date_patterns = [\n",
    "            r'\\b(20\\d{2}[-/]\\d{2}[-/]\\d{2})\\b',\n",
    "            r'\\b(20\\d{2})\\b',  # Year only\n",
    "        ]\n",
    "        dates = []\n",
    "        for pattern in date_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            dates.extend(matches)\n",
    "        \n",
    "        if dates:\n",
    "            # Try to create date range from extracted dates\n",
    "            years = [int(d[:4]) for d in dates if len(d) >= 4]\n",
    "            if years:\n",
    "                start_year = min(years)\n",
    "                end_year = max(years) + 1  # Assume 1 year contract\n",
    "                metadata[\"date_range\"] = {\n",
    "                    \"start\": f\"{start_year}-01-01\",\n",
    "                    \"end\": f\"{end_year}-12-31\"\n",
    "                }\n",
    "        \n",
    "        metadata[\"parties\"] = list(parties)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Could not extract metadata from {contract_path.name}: {e}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Extract real metadata from each contract file\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Extracting metadata from real contract files...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "real_contracts_data = {\n",
    "    \"extracted_at\": datetime.now().isoformat(),\n",
    "    \"contracts\": []\n",
    "}\n",
    "\n",
    "for contract_file in real_contracts:\n",
    "    print(f\"\\n\ud83d\udcc4 {contract_file.name}:\")\n",
    "    metadata = extract_contract_metadata(contract_file)\n",
    "    \n",
    "    # Add default rules (will be replaced with actual extracted rules later)\n",
    "    metadata[\"extracted_at\"] = datetime.now().isoformat()\n",
    "    metadata[\"rules\"] = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms extracted from contract\",\n",
    "            \"priority\": \"high\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    real_contracts_data[\"contracts\"].append(metadata)\n",
    "    \n",
    "    print(f\"  Contract ID: {metadata['contract_id']}\")\n",
    "    print(f\"  Parties: {metadata['parties']}\")\n",
    "    print(f\"  Program Code: {metadata['program_code']}\")\n",
    "    print(f\"  Date Range: {metadata['date_range']}\")\n",
    "\n",
    "if not real_contracts_data[\"contracts\"]:\n",
    "    print(\"\\n\u26a0 No contracts found. Using sample data for testing...\")\n",
    "    # Fallback to sample data if no contracts found\n",
    "    real_contracts_data = {\n",
    "        \"extracted_at\": datetime.now().isoformat(),\n",
    "        \"contracts\": [\n",
    "            {\n",
    "                \"contract_id\": \"CONTRACT_NET30\",\n",
    "                \"contract_path\": \"docs/contracts/sample_contract_net30.pdf\",\n",
    "                \"parties\": [\"BAYER\", \"R4 Technologies\"],\n",
    "                \"program_code\": \"BCH\",\n",
    "                \"date_range\": {\"start\": \"2021-01-01\", \"end\": \"2023-12-31\"},\n",
    "                \"extracted_at\": datetime.now().isoformat(),\n",
    "                \"rules\": [{\"rule_id\": \"payment_terms\", \"type\": \"payment_term\", \"description\": \"Net 30 days\", \"priority\": \"high\"}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "matcher = InvoiceContractMatcher(real_contracts_data)\n",
    "\n",
    "# Test with REAL invoice files\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TEST 1: Testing with Real Invoice Files\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Find real invoice files\n",
    "invoice_dir = Path(\"docs/invoices\")\n",
    "all_invoice_files = (\n",
    "    list(invoice_dir.glob(\"*.pdf\")) + \n",
    "    list(invoice_dir.glob(\"*.docx\")) + \n",
    "    list(invoice_dir.glob(\"*.png\"))\n",
    ")\n",
    "# Filter out temp/system files\n",
    "real_invoice_files = [f for f in all_invoice_files if f.is_file() and is_valid_file(f)]\n",
    "\n",
    "print(f\"\\nFound {len(real_invoice_files)} real invoice file(s):\")\n",
    "for inv_file in real_invoice_files[:5]:  # Show first 5\n",
    "    print(f\"  - {inv_file.name}\")\n",
    "\n",
    "if real_invoice_files:\n",
    "    # Initialize a temporary processor just for parsing invoices\n",
    "    try:\n",
    "        processor_temp = InvoiceProcessor()\n",
    "    except:\n",
    "        # If processor not initialized, create minimal parser\n",
    "        print(\"\\n\u26a0 InvoiceProcessor not initialized. Using basic parsing...\")\n",
    "        processor_temp = None\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Testing each real invoice file:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for inv_file in real_invoice_files[:5]:  # Test first 5 files\n",
    "        try:\n",
    "            print(f\"\\n\ud83d\udcc4 {inv_file.name}:\")\n",
    "            \n",
    "            # Parse the invoice\n",
    "            if processor_temp:\n",
    "                invoice_data = processor_temp.parse_invoice(str(inv_file))\n",
    "            else:\n",
    "                # Basic parsing fallback\n",
    "                print(\"  \u26a0 Skipping - InvoiceProcessor not available\")\n",
    "                continue\n",
    "            \n",
    "            # Match to contract\n",
    "            match_result = matcher.match_invoice_to_contract(invoice_data)\n",
    "            \n",
    "            # Display results\n",
    "            status_icon = {\n",
    "                \"MATCHED\": \"\u2713\",\n",
    "                \"AMBIGUOUS\": \"\u26a0\",\n",
    "                \"UNMATCHED\": \"\u2717\"\n",
    "            }.get(match_result['status'], \"?\")\n",
    "            \n",
    "            print(f\"  {status_icon} Status: {match_result['status']}\")\n",
    "            print(f\"     Contract: {match_result['contract_id']}\")\n",
    "            print(f\"     Method: {match_result['match_method']}\")\n",
    "            print(f\"     Confidence: {match_result['confidence']}\")\n",
    "            if match_result.get('matching_details'):\n",
    "                details = match_result['matching_details']\n",
    "                if details.get('po_number'):\n",
    "                    print(f\"     PO: {details['po_number']}\")\n",
    "                if details.get('vendor'):\n",
    "                    print(f\"     Vendor: {details['vendor']}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  \u2717 Error processing {inv_file.name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "else:\n",
    "    print(\"\u26a0 No invoice files found in docs/invoices/\")\n",
    "    print(\"Using simulated data for testing...\")\n",
    "    \n",
    "    # Fallback to simulated tests if no real files\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"TEST 1: PO Number Matching (Simulated)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    invoice_with_po = {\n",
    "        \"file\": \"invoice_001.pdf\",\n",
    "        \"invoice_number\": \"INV-001\",\n",
    "        \"po_number\": \"PO-2021-1234\",\n",
    "        \"vendor_name\": \"R4 Technologies\",\n",
    "        \"invoice_date\": datetime(2022, 6, 15),\n",
    "        \"raw_text\": \"INVOICE\\nR4 Technologies\\nPO Number: PO-2021-1234\\nAmount: $1000\"\n",
    "    }\n",
    "    \n",
    "    match_result = matcher.match_invoice_to_contract(invoice_with_po)\n",
    "    print(f\"  Status: {match_result['status']}\")\n",
    "    print(f\"  Contract ID: {match_result['contract_id']}\")\n",
    "    print(f\"  Match Method: {match_result['match_method']}\")\n",
    "\n",
    "# Test 2: Test with actual extracted_rules.json (if exists)\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TEST 2: Test with Actual extracted_rules.json\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    with open(\"extracted_rules.json\", \"r\") as f:\n",
    "        actual_rules_data = json.load(f)\n",
    "    \n",
    "    # Convert old format to new format if needed\n",
    "    if isinstance(actual_rules_data, list):\n",
    "        print(\"Converting very old format (list) to new format...\")\n",
    "        actual_rules_data = {\n",
    "            \"version\": \"2.0\",\n",
    "            \"extracted_at\": datetime.now().isoformat(),\n",
    "            \"contracts\": [\n",
    "                {\n",
    "                    \"contract_id\": \"CONTRACT_DEFAULT\",\n",
    "                    \"contract_path\": \"docs/contracts/sample_contract_net30.pdf\",\n",
    "                    \"parties\": [],\n",
    "                    \"program_code\": \"\",\n",
    "                    \"date_range\": None,\n",
    "                    \"extracted_at\": datetime.now().isoformat(),\n",
    "                    \"rules\": actual_rules_data\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        print(\"\u2713 Converted list format to new format\")\n",
    "    elif isinstance(actual_rules_data, dict):\n",
    "        if \"contract_path\" in actual_rules_data and \"contracts\" not in actual_rules_data:\n",
    "            print(\"Converting old format (single contract) to new format...\")\n",
    "            actual_rules_data = {\n",
    "                \"version\": \"2.0\",\n",
    "                \"extracted_at\": actual_rules_data.get(\"extracted_at\", datetime.now().isoformat()),\n",
    "                \"contracts\": [\n",
    "                    {\n",
    "                        \"contract_id\": \"CONTRACT_DEFAULT\",\n",
    "                        \"contract_path\": actual_rules_data.get(\"contract_path\", \"docs/contracts/sample_contract_net30.pdf\"),\n",
    "                        \"parties\": [],\n",
    "                        \"program_code\": \"\",\n",
    "                        \"date_range\": None,\n",
    "                        \"extracted_at\": actual_rules_data.get(\"extracted_at\", datetime.now().isoformat()),\n",
    "                        \"rules\": actual_rules_data.get(\"rules\", [])\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            print(\"\u2713 Converted single contract format to new format\")\n",
    "        else:\n",
    "            print(\"\u2713 Already in new format\")\n",
    "    \n",
    "    actual_matcher = InvoiceContractMatcher(actual_rules_data)\n",
    "    print(f\"\u2713 Loaded {len(actual_rules_data.get('contracts', []))} contract(s)\")\n",
    "    \n",
    "    # Test with a real invoice file if available\n",
    "    if real_invoice_files and processor_temp:\n",
    "        test_invoice_file = real_invoice_files[0]\n",
    "        print(f\"\\nTesting with real invoice: {test_invoice_file.name}\")\n",
    "        test_invoice_data = processor_temp.parse_invoice(str(test_invoice_file))\n",
    "        test_match = actual_matcher.match_invoice_to_contract(test_invoice_data)\n",
    "        print(f\"  Status: {test_match['status']}\")\n",
    "        print(f\"  Contract ID: {test_match['contract_id']}\")\n",
    "    else:\n",
    "        # Fallback to simulated test\n",
    "        test_invoice = {\n",
    "            \"file\": \"test_invoice.pdf\",\n",
    "            \"invoice_number\": \"TEST-001\",\n",
    "            \"po_number\": None,\n",
    "            \"vendor_name\": \"Test Vendor\",\n",
    "            \"invoice_date\": datetime.now(),\n",
    "            \"raw_text\": \"TEST INVOICE\"\n",
    "        }\n",
    "        test_match = actual_matcher.match_invoice_to_contract(test_invoice)\n",
    "        print(f\"\\nTest Match Result (simulated):\")\n",
    "        print(f\"  Status: {test_match['status']}\")\n",
    "        print(f\"  Contract ID: {test_match['contract_id']}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\u26a0 extracted_rules.json not found - skipping test with actual data\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0 Error testing with actual data: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MATCHER TESTING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b57cf",
   "metadata": {},
   "source": [
    "## Usage: Process Invoices with Extracted Rules\n",
    "\n",
    "After extracting rules from contracts (Part 1), use these cells to process invoices:\n",
    "\n",
    "- **Cell 21:** Initialize Invoice Processor (loads rules from `extracted_rules.json`)\n",
    "- **Cell 22:** Process a single invoice file (optional - for testing/debugging)\n",
    "  - Useful for: Testing specific invoices, debugging issues, learning how validation works\n",
    "  - Shows detailed output for one invoice\n",
    "- **Cell 23:** Batch process all invoices (recommended for production)\n",
    "  - Processes all invoices in `docs/invoices/` directory\n",
    "  - Generates summary statistics and saves results to JSON\n",
    "  - Use this for normal workflow\n",
    "- **Cell 24:** Generate a summary report of all processed invoices\n",
    "\n",
    "### Recommendation:\n",
    "- **For production:** Use Cell 23 (batch processing) - it's more efficient and provides summary statistics\n",
    "- **For testing/debugging:** Use Cell 22 (single invoice) - easier to see detailed output for one file\n",
    "\n",
    "### Validation Status:\n",
    "- **APPROVED** - Invoice meets all requirements\n",
    "- **FLAGGED** - Invoice has warnings but may be acceptable\n",
    "- **REJECTED** - Invoice fails critical requirements (e.g., missing PO number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Initialize Invoice Processor (with robust error handling)\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if rules file exists and is valid\n",
    "rules_file = \"extracted_rules.json\"\n",
    "\n",
    "if not os.path.exists(rules_file):\n",
    "    print(f\"[WARN] Rules file not found: {rules_file}\")\n",
    "    print(\"\\nCreating default rules file...\")\n",
    "\n",
    "    # Create default rules\n",
    "    default_rules = [\n",
    "        {\n",
    "            \"rule_id\": \"payment_terms\",\n",
    "            \"type\": \"payment_term\",\n",
    "            \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"submission_requirements\",\n",
    "            \"type\": \"submission\",\n",
    "            \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "            \"priority\": \"medium\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "        {\n",
    "            \"rule_id\": \"late_penalties\",\n",
    "            \"type\": \"penalty\",\n",
    "            \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "            \"priority\": \"high\",\n",
    "            \"confidence\": \"high\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    with open(rules_file, \"w\") as f:\n",
    "        json.dump(default_rules, f, indent=2)\n",
    "\n",
    "    print(f\"[OK] Created {rules_file} with {len(default_rules)} default rules\")\n",
    "\n",
    "else:\n",
    "    # Check if file is empty or invalid\n",
    "    try:\n",
    "        with open(rules_file, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:\n",
    "                raise ValueError(\"File is empty\")\n",
    "            # Try to parse JSON\n",
    "            json.loads(content)\n",
    "    except (ValueError, json.JSONDecodeError) as e:\n",
    "        print(f\"[WARN] Invalid JSON in {rules_file}: {e}\")\n",
    "        print(\"\\nCreating default rules file...\")\n",
    "\n",
    "        default_rules = [\n",
    "            {\n",
    "                \"rule_id\": \"payment_terms\",\n",
    "                \"type\": \"payment_term\",\n",
    "                \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "                \"priority\": \"high\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "            {\n",
    "                \"rule_id\": \"submission_requirements\",\n",
    "                \"type\": \"submission\",\n",
    "                \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "                \"priority\": \"medium\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "            {\n",
    "                \"rule_id\": \"late_penalties\",\n",
    "                \"type\": \"penalty\",\n",
    "                \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "                \"priority\": \"high\",\n",
    "                \"confidence\": \"high\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        with open(rules_file, \"w\") as f:\n",
    "            json.dump(default_rules, f, indent=2)\n",
    "\n",
    "        print(f\"[OK] Created {rules_file} with {len(default_rules)} default rules\")\n",
    "\n",
    "# Now initialize processor\n",
    "try:\n",
    "    processor = InvoiceProcessor(rules_file=rules_file)\n",
    "\n",
    "    # Display loaded rules\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Loaded Contract Rules:\")\n",
    "    print(\"=\" * 60)\n",
    "    for rule in processor.rules:\n",
    "        print(f\"\\n[{rule['type'].upper()}] - Priority: {rule['priority']}\")\n",
    "        print(f\"Description: {rule['description'][:100]}...\")\n",
    "\n",
    "    if processor.payment_terms:\n",
    "        print(f\"\\n[OK] Payment Terms: Net {processor.payment_terms} days\")\n",
    "    else:\n",
    "        print(\"\\n[WARN] No payment terms found in rules\")\n",
    "\n",
    "    print(\"\\n[OK] Invoice Processor ready\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error initializing processor: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Run Cell 15 to extract rules from contract\")\n",
    "    print(\"  2. Or run Generate_Sample_Documents.ipynb to create sample documents first\")\n",
    "    print(\"  3. Or run Cell 28 for complete pipeline test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Process a Single Invoice\n",
    "\n",
    "# NOTE: This cell is OPTIONAL - for testing/debugging individual invoices\n",
    "# For production use, skip to Cell 23 (Batch Processing) which processes all invoices\n",
    "# Use this cell when you need to:\n",
    "#   - Test a specific invoice\n",
    "#   - Debug validation issues\n",
    "#   - See detailed output for one invoice\n",
    "\n",
    "\n",
    "# Process a single invoice file\n",
    "invoice_file = \"docs/invoices/invoice_005_ocr_valid.png\"  # Change to your invoice file\n",
    "\n",
    "try:\n",
    "    result = processor.process_invoice(invoice_file)\n",
    "\n",
    "    # Display results\n",
    "    print(\"=\" * 70)\n",
    "    print(\"INVOICE VALIDATION RESULT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nInvoice File: {result['invoice_file']}\")\n",
    "    print(f\"Invoice Number: {result.get('invoice_number', 'N/A')}\")\n",
    "    print(f\"\\nStatus: {result['status']}\")\n",
    "    print(f\"Action: {result['action']}\")\n",
    "\n",
    "    if result[\"issues\"]:\n",
    "        print(f\"\\n[FAIL] ISSUES ({len(result['issues'])}):\")\n",
    "        for i, issue in enumerate(result[\"issues\"], 1):\n",
    "            print(f\"  {i}. {issue}\")\n",
    "\n",
    "    if result[\"warnings\"]:\n",
    "        print(f\"\\n[WARN] WARNINGS ({len(result['warnings'])}):\")\n",
    "        for i, warning in enumerate(result[\"warnings\"], 1):\n",
    "            print(f\"  {i}. {warning}\")\n",
    "\n",
    "    if result[\"status\"] == \"APPROVED\":\n",
    "        print(\"\\n[OK] Invoice approved for payment\")\n",
    "\n",
    "    print(f\"\\nValidation Timestamp: {result['validation_timestamp']}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Display invoice data\n",
    "    if \"invoice_data\" in result:\n",
    "        print(\"\\nExtracted Invoice Data:\")\n",
    "        inv_data = result[\"invoice_data\"]\n",
    "        print(f\"  Invoice Date: {inv_data.get('invoice_date', 'N/A')}\")\n",
    "        print(f\"  Due Date: {inv_data.get('due_date', 'N/A')}\")\n",
    "        print(\n",
    "            f\"  Total Amount: ${inv_data.get('total_amount', 0):.2f}\"\n",
    "            if inv_data.get(\"total_amount\")\n",
    "            else \"  Total Amount: N/A\"\n",
    "        )\n",
    "        print(f\"  PO Number: {inv_data.get('po_number', 'N/A')}\")\n",
    "        print(f\"  Vendor: {inv_data.get('vendor_name', 'N/A')}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] Invoice file not found: {invoice_file}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error processing invoice: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Batch Process Multiple Invoices\n",
    "\n",
    "# Process multiple invoices from a folder\n",
    "invoice_folder = \"docs/invoices\"  # Change to your invoices folder\n",
    "\n",
    "try:\n",
    "    results, summary = processor.batch_process(invoice_folder)\n",
    "\n",
    "    # Display summary\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BATCH PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTotal Invoices Processed: {summary['total']}\")\n",
    "    print(f\"\\n[OK] Approved: {summary['approved']}\")\n",
    "    print(f\"[WARN] Flagged for Review: {summary['flagged']}\")\n",
    "    print(f\"[FAIL] Rejected: {summary['rejected']}\")\n",
    "    print(f\"[ERROR] Errors: {summary['errors']}\")\n",
    "\n",
    "    # Calculate approval rate\n",
    "    if summary[\"total\"] > 0:\n",
    "        approval_rate = (summary[\"approved\"] / summary[\"total\"]) * 100\n",
    "        print(f\"\\nApproval Rate: {approval_rate:.1f}%\")\n",
    "\n",
    "    # Display individual results\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INDIVIDUAL INVOICE RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for i, result in enumerate(results, 1):\n",
    "        status_icon = {\n",
    "            \"APPROVED\": \"[OK]\",\n",
    "            \"FLAGGED\": \"[WARN]\",\n",
    "            \"REJECTED\": \"[FAIL]\",\n",
    "            \"ERROR\": \"[ERROR]\",\n",
    "        }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "        print(f\"\\n{i}. {status_icon} {result['invoice_file']}\")\n",
    "        print(f\"   Status: {result['status']} - {result['action']}\")\n",
    "\n",
    "        if result[\"issues\"]:\n",
    "            print(f\"   Issues: {', '.join(result['issues'][:2])}\")\n",
    "        if result[\"warnings\"]:\n",
    "            print(f\"   Warnings: {', '.join(result['warnings'][:2])}\")\n",
    "\n",
    "    # Save results to JSON\n",
    "    output_file = \"invoice_processing_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"summary\": summary,\n",
    "                \"results\": results,\n",
    "                \"processed_at\": datetime.now().isoformat(),\n",
    "            },\n",
    "            f,\n",
    "            indent=2,\n",
    "            default=str,\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[OK] Results saved to {output_file}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[WARN] Invoice folder not found: {invoice_folder}\")\n",
    "    print(\"Please create sample documents first (run Generate_Sample_Documents.ipynb)\")\n",
    "except Exception as e:\n",
    "    print(f\"[FAIL] Error in batch processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Generate Processing Report\n",
    "\n",
    "\n",
    "def generate_processing_report(results_file: str = \"invoice_processing_results.json\"):\n",
    "    \"\"\"Generate a detailed processing report with statistics and insights.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(results_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        summary = data[\"summary\"]\n",
    "        results = data[\"results\"]\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"INVOICE PROCESSING REPORT\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nGenerated: {data.get('processed_at', 'N/A')}\")\n",
    "\n",
    "        # Overall Statistics\n",
    "        print(\"\\nOVERALL STATISTICS\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Total Invoices: {summary['total']}\")\n",
    "        print(\n",
    "            f\"Approved: {summary['approved']} ({summary['approved']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Flagged: {summary['flagged']} ({summary['flagged']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Rejected: {summary['rejected']} ({summary['rejected']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Errors: {summary['errors']} ({summary['errors']/max(summary['total'],1)*100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        # Most Common Issues\n",
    "        print(\"\\nMOST COMMON ISSUES\")\n",
    "        print(\"-\" * 80)\n",
    "        all_issues = []\n",
    "        for result in results:\n",
    "            all_issues.extend(result.get(\"issues\", []))\n",
    "\n",
    "        if all_issues:\n",
    "            from collections import Counter\n",
    "\n",
    "            issue_counts = Counter(all_issues)\n",
    "            for issue, count in issue_counts.most_common(5):\n",
    "                print(f\"  \u2022 {issue}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No issues found\")\n",
    "\n",
    "        # Most Common Warnings\n",
    "        print(\"\\nMOST COMMON WARNINGS\")\n",
    "        print(\"-\" * 80)\n",
    "        all_warnings = []\n",
    "        for result in results:\n",
    "            all_warnings.extend(result.get(\"warnings\", []))\n",
    "\n",
    "        if all_warnings:\n",
    "            from collections import Counter\n",
    "\n",
    "            warning_counts = Counter(all_warnings)\n",
    "            for warning, count in warning_counts.most_common(5):\n",
    "                print(f\"  \u2022 {warning}: {count} occurrence(s)\")\n",
    "        else:\n",
    "            print(\"  No warnings found\")\n",
    "\n",
    "        # Recommended Actions\n",
    "        print(\"\\nRECOMMENDED ACTIONS\")\n",
    "        print(\"-\" * 80)\n",
    "        if summary[\"rejected\"] > 0:\n",
    "            print(f\"  1. Review {summary['rejected']} rejected invoice(s) manually\")\n",
    "        if summary[\"flagged\"] > 0:\n",
    "            print(f\"  2. Investigate {summary['flagged']} flagged invoice(s)\")\n",
    "        if summary[\"errors\"] > 0:\n",
    "            print(f\"  3. Fix processing errors for {summary['errors']} invoice(s)\")\n",
    "        if summary[\"approved\"] == summary[\"total\"]:\n",
    "            print(\"  [OK] All invoices approved - ready for payment processing\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARN] Results file not found: {results_file}\")\n",
    "        print(\"Please run batch processing first (Cell 23)\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] Error generating report: {e}\")\n",
    "\n",
    "\n",
    "# Run the report if results exist\n",
    "generate_processing_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af20a1e",
   "metadata": {},
   "source": [
    "## Summary: Complete AI Agent Pipeline\n",
    "\n",
    "This notebook provides a complete end-to-end invoice processing solution:\n",
    "\n",
    "1. **Rule Extraction** (Cells 14-17) - Extract rules from contracts using RAG\n",
    "2. **Invoice Processing** (Cells 19-24) - Validate invoices against rules\n",
    "3. **Complete Pipeline** (Cell 29) - Run both steps together\n",
    "4. **Reporting** (Cell 30) - Export results to JSON reports\n",
    "\n",
    "### Key Files Generated:\n",
    "- `extracted_rules.json` - Extracted invoice processing rules\n",
    "- `invoice_processing_results.json` - Processing results and validation status\n",
    "- `validation_report.json` - Detailed validation report\n",
    "\n",
    "### Sample Documents:\n",
    "Sample contracts and invoices are automatically generated if the `docs/` directories are empty (see Cell 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d011522",
   "metadata": {},
   "source": [
    "# Cell 26: Sample Document Generation\n",
    "\n",
    "**Note:** Sample document generation has been moved to a separate notebook.\n",
    "\n",
    "**To generate sample documents:**\n",
    "- Run the notebook: **`Generate_Sample_Documents.ipynb`**\n",
    "- Or let the main notebook auto-generate them (check runs at startup)\n",
    "\n",
    "The main notebook automatically checks for sample documents at startup (Cell 8) and will prompt you to generate them if the folders are empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a47a1",
   "metadata": {},
   "source": [
    "## Test the Complete Pipeline\n",
    "\n",
    "**Cell 29** runs the complete pipeline:\n",
    "1. Extracts rules from contract documents\n",
    "2. Processes all invoices in `docs/invoices/`\n",
    "3. Validates invoices against extracted rules\n",
    "4. Generates comprehensive results\n",
    "\n",
    "This is the recommended way to test the entire system end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: Complete RAG Pipeline Test - Extract Rules from ALL Contracts and Process Invoices\n",
    "from datetime import datetime\n",
    "\n",
    "# Temporarily reduce logging noise for cleaner output\n",
    "import logging\n",
    "\n",
    "old_level = logging.getLogger().level\n",
    "logging.getLogger().setLevel(\n",
    "    logging.ERROR\n",
    ")  # Only show errors (suppresses INFO and WARNING)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLETE RAG PIPELINE TEST - MULTI-CONTRACT SUPPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Step 1: Extract rules from ALL contracts using RAG\n",
    "print(\"\\nStep 1: Extracting rules from ALL contracts using RAG...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Helper function to extract contract metadata (reused from Cell 21)\n",
    "def extract_contract_metadata(contract_path: Path) -> Dict:\n",
    "    \"\"\"Extract parties, program codes, and dates from contract file.\"\"\"\n",
    "    metadata = {\n",
    "        \"contract_id\": f\"CONTRACT_{contract_path.stem.upper()}\",\n",
    "        \"contract_path\": str(contract_path),\n",
    "        \"parties\": [],\n",
    "        \"program_code\": \"\",\n",
    "        \"date_range\": None,\n",
    "    }\n",
    "    \n",
    "    # Try to parse contract content to extract metadata\n",
    "    try:\n",
    "        text = \"\"\n",
    "        if contract_path.suffix.lower() == \".pdf\":\n",
    "            import pdfplumber\n",
    "            with pdfplumber.open(contract_path) as pdf:\n",
    "                for page in pdf.pages[:3]:  # First 3 pages usually have party info\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "        elif contract_path.suffix.lower() in [\".docx\", \".doc\"]:\n",
    "            from docx import Document\n",
    "            doc = Document(contract_path)\n",
    "            text = \"\\n\".join([para.text for para in doc.paragraphs[:20]])  # First 20 paragraphs\n",
    "        \n",
    "        text_upper = text.upper()\n",
    "        \n",
    "        # Extract program code from contract content first (more reliable)\n",
    "        program_match = re.search(r'PROGRAM CODE:\\s*([A-Z]{2,4})', text_upper)\n",
    "        if program_match:\n",
    "            metadata[\"program_code\"] = program_match.group(1)\n",
    "        else:\n",
    "            # Fallback: Extract from filename (convert to uppercase first)\n",
    "            filename_upper = contract_path.name.upper()\n",
    "            program_match = re.search(r'\\b([A-Z]{2,4})\\b', filename_upper)\n",
    "            if program_match:\n",
    "                code = program_match.group(1)\n",
    "                # Filter out common words\n",
    "                if code not in [\"FOR\", \"PDF\", \"SOW\", \"MSA\", \"THE\", \"NET\", \"CONTRACT\"]:\n",
    "                    metadata[\"program_code\"] = code\n",
    "        \n",
    "        # Extract parties (common patterns - update based on actual contract content)\n",
    "        parties = set()\n",
    "        # Look for common party patterns in text\n",
    "        # Pattern: \"BETWEEN:\" or \"AND:\" followed by company names\n",
    "        party_patterns = [\n",
    "            r'(?:BETWEEN|AND):\\s*([A-Z][^,\\n]+(?:Inc\\.|LLC|Ltd\\.|Corp\\.|Corporation|Company))',\n",
    "            r'(?:Client|Vendor):\\s*([A-Z][^,\\n]+(?:Inc\\.|LLC|Ltd\\.|Corp\\.|Corporation|Company))',\n",
    "        ]\n",
    "        for pattern in party_patterns:\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                party = match.strip()\n",
    "                if len(party) > 3:\n",
    "                    parties.add(party)\n",
    "        \n",
    "        # Extract dates from text (YYYY-MM-DD or YYYY/MM/DD)\n",
    "        date_patterns = [\n",
    "            r'\\b(20\\d{2}[-/]\\d{2}[-/]\\d{2})\\b',\n",
    "            r'\\b(20\\d{2})\\b',  # Year only\n",
    "        ]\n",
    "        dates = []\n",
    "        for pattern in date_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            dates.extend(matches)\n",
    "        \n",
    "        if dates:\n",
    "            # Try to create date range from extracted dates\n",
    "            years = [int(d[:4]) for d in dates if len(d) >= 4]\n",
    "            if years:\n",
    "                start_year = min(years)\n",
    "                end_year = max(years) + 1  # Assume 1 year contract\n",
    "                metadata[\"date_range\"] = {\n",
    "                    \"start\": f\"{start_year}-01-01\",\n",
    "                    \"end\": f\"{end_year}-12-31\"\n",
    "                }\n",
    "        \n",
    "        metadata[\"parties\"] = list(parties)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Could not extract metadata from {contract_path.name}: {e}\")\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# Find all contract files\n",
    "contracts_dir = Path(\"docs/contracts\")\n",
    "all_contracts = list(contracts_dir.glob(\"*.pdf\")) + list(contracts_dir.glob(\"*.docx\"))\n",
    "# Filter out temp/system files\n",
    "contract_files = [f for f in all_contracts if f.is_file() and is_valid_file(f)]\n",
    "\n",
    "if not contract_files:\n",
    "    print(\"[WARN] No contract files found in docs/contracts/\")\n",
    "    print(\"Using fallback rules...\")\n",
    "    # Fallback to multi-contract format\n",
    "    all_contracts_data = {\n",
    "        \"extracted_at\": datetime.now().isoformat(),\n",
    "        \"contracts\": [\n",
    "            {\n",
    "                \"contract_id\": \"CONTRACT_DEFAULT\",\n",
    "                \"contract_path\": \"Unknown\",\n",
    "                \"parties\": [],\n",
    "                \"program_code\": \"\",\n",
    "                \"date_range\": None,\n",
    "                \"extracted_at\": datetime.now().isoformat(),\n",
    "                \"rules\": [\n",
    "                    {\n",
    "                        \"rule_id\": \"payment_terms\",\n",
    "                        \"type\": \"payment_term\",\n",
    "                        \"description\": \"Payment terms: Net 30 days from invoice date. All invoices must include a valid Purchase Order (PO) number.\",\n",
    "                        \"priority\": \"high\",\n",
    "                        \"confidence\": \"high\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"rule_id\": \"submission_requirements\",\n",
    "                        \"type\": \"submission\",\n",
    "                        \"description\": \"All invoices must include: Valid PO number (format: PO-YYYY-####), Invoice date and due date, Vendor tax identification number\",\n",
    "                        \"priority\": \"medium\",\n",
    "                        \"confidence\": \"high\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"rule_id\": \"late_penalties\",\n",
    "                        \"type\": \"penalty\",\n",
    "                        \"description\": \"Late payment penalty: 1.5% per month on overdue balance. Missing PO number: Automatic rejection.\",\n",
    "                        \"priority\": \"high\",\n",
    "                        \"confidence\": \"high\",\n",
    "                    },\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(all_contracts_data, f, indent=2)\n",
    "    print(f\"Created {len(all_contracts_data['contracts'][0]['rules'])} fallback rules\")\n",
    "else:\n",
    "    print(f\"Found {len(contract_files)} contract file(s) to process\")\n",
    "    \n",
    "    # Initialize RAG-powered agent\n",
    "    rag_agent = InvoiceRuleExtractorAgent(llm=llm, embeddings=embeddings)\n",
    "    \n",
    "    # Process each contract\n",
    "    all_contracts_data = {\n",
    "        \"extracted_at\": datetime.now().isoformat(),\n",
    "        \"contracts\": []\n",
    "    }\n",
    "    \n",
    "    for contract_file in contract_files:\n",
    "        try:\n",
    "            print(f\"\\nProcessing: {contract_file.name}\")\n",
    "            \n",
    "            # Extract metadata\n",
    "            metadata = extract_contract_metadata(contract_file)\n",
    "            print(f\"  Contract ID: {metadata['contract_id']}\")\n",
    "            print(f\"  Parties: {metadata['parties']}\")\n",
    "            print(f\"  Program Code: {metadata['program_code']}\")\n",
    "            print(f\"  Date Range: {metadata['date_range']}\")\n",
    "            \n",
    "            # Extract rules using RAG\n",
    "            print(\"  Extracting rules... (this takes ~4-5 seconds)\")\n",
    "            with redirect_stderr(io.StringIO()):\n",
    "                rules = rag_agent.run(str(contract_file))\n",
    "            \n",
    "            # Combine metadata with rules\n",
    "            contract_data = {\n",
    "                \"contract_id\": metadata[\"contract_id\"],\n",
    "                \"contract_path\": metadata[\"contract_path\"],\n",
    "                \"parties\": metadata[\"parties\"],\n",
    "                \"program_code\": metadata[\"program_code\"],\n",
    "                \"date_range\": metadata[\"date_range\"],\n",
    "                \"extracted_at\": datetime.now().isoformat(),\n",
    "                \"rules\": rules\n",
    "            }\n",
    "            \n",
    "            all_contracts_data[\"contracts\"].append(contract_data)\n",
    "            print(f\"  \u2713 Extracted {len(rules)} rules\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  \u2717 Error processing {contract_file.name}: {e}\")\n",
    "            # Add contract with empty rules\n",
    "            metadata = extract_contract_metadata(contract_file)\n",
    "            all_contracts_data[\"contracts\"].append({\n",
    "                \"contract_id\": metadata[\"contract_id\"],\n",
    "                \"contract_path\": metadata[\"contract_path\"],\n",
    "                \"parties\": metadata[\"parties\"],\n",
    "                \"program_code\": metadata[\"program_code\"],\n",
    "                \"date_range\": metadata[\"date_range\"],\n",
    "                \"extracted_at\": datetime.now().isoformat(),\n",
    "                \"rules\": []\n",
    "            })\n",
    "    \n",
    "    # Save all contracts in multi-contract format\n",
    "    with open(\"extracted_rules.json\", \"w\") as f:\n",
    "        json.dump(all_contracts_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n\u2713 Extracted rules from {len(all_contracts_data['contracts'])} contract(s)\")\n",
    "    print(f\"\u2713 Saved to extracted_rules.json (multi-contract format)\")\n",
    "# Step 2: Process sample invoices\n",
    "print(\"\\nStep 2: Processing sample invoices...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    # Initialize invoice processor\n",
    "    processor = InvoiceProcessor(rules_file=\"extracted_rules.json\")\n",
    "\n",
    "    # Process all invoices found in the invoices directory\n",
    "    # Scan invoices directory for all invoice files (excluding temp/system files)\n",
    "    invoice_dir = Path(\"docs/invoices\")\n",
    "    all_invoice_files = list(invoice_dir.glob(\"*.*\"))\n",
    "    # Filter out temp/system files and only keep valid invoice formats\n",
    "    invoice_files = [\n",
    "        str(f) for f in all_invoice_files\n",
    "        if f.is_file() \n",
    "        and is_valid_file(f)\n",
    "        and f.suffix.lower() in [\".pdf\", \".docx\", \".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\"]\n",
    "    ]\n",
    "\n",
    "    if not invoice_files:\n",
    "        print(\"[WARN] No invoice files found in docs/invoices/\")\n",
    "        print(\"Please add invoice files or run Generate_Sample_Documents.ipynb\")\n",
    "    else:\n",
    "        print(f\"Found {len(invoice_files)} invoice file(s) to process\")\n",
    "        print(f\"Files: {[Path(f).name for f in invoice_files]}\")\n",
    "\n",
    "        results = []\n",
    "        for invoice_file in invoice_files:\n",
    "            try:\n",
    "                result = processor.process_invoice(invoice_file)\n",
    "                results.append(result)\n",
    "\n",
    "                # Display result\n",
    "                status_icon = {\n",
    "                    \"APPROVED\": \"[OK]\",\n",
    "                    \"FLAGGED\": \"[WARN]\",\n",
    "                    \"REJECTED\": \"[FAIL]\",\n",
    "                    \"ERROR\": \"[ERROR]\",\n",
    "                }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "                print(f\"\\n{status_icon} {Path(invoice_file).name}:\")\n",
    "                print(f\"   Status: {result['status']}\")\n",
    "                print(f\"   Action: {result['action']}\")\n",
    "                \n",
    "                # Show contract matching info\n",
    "                if result.get(\"contract_match\"):\n",
    "                    match_info = result[\"contract_match\"]\n",
    "                    if match_info.get(\"status\") == \"MATCHED\":\n",
    "                        print(f\"   Contract: {result.get('contract_id', 'N/A')} (via {result.get('match_method', 'N/A')}, confidence: {result.get('match_confidence', 0):.2f})\")\n",
    "                    elif match_info.get(\"status\") == \"UNMATCHED\":\n",
    "                        print(f\"   Contract: UNMATCHED - Manual review required\")\n",
    "                    elif match_info.get(\"status\") == \"AMBIGUOUS\":\n",
    "                        print(f\"   Contract: AMBIGUOUS - Multiple matches found\")\n",
    "                \n",
    "                if result.get(\"issues\"):\n",
    "                    print(f\"   Issues: {', '.join(result['issues'])}\")\n",
    "                if result.get(\"warnings\"):\n",
    "                    print(f\"   Warnings: {', '.join(result['warnings'])}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"\\n[ERROR] {Path(invoice_file).name}: File not found (skipping)\")\n",
    "\n",
    "        if results:\n",
    "            # Summary\n",
    "            approved = sum(1 for r in results if r[\"status\"] == \"APPROVED\")\n",
    "            flagged = sum(1 for r in results if r[\"status\"] == \"FLAGGED\")\n",
    "            rejected = sum(1 for r in results if r[\"status\"] == \"REJECTED\")\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"PIPELINE TEST RESULTS\")\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"Total Invoices: {len(results)}\")\n",
    "            print(f\"[OK] Approved: {approved}\")\n",
    "            print(f\"[WARN] Flagged: {flagged}\")\n",
    "            print(f\"[FAIL] Rejected: {rejected}\")\n",
    "            \n",
    "            # Contract matching statistics\n",
    "            matched = sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"MATCHED\")\n",
    "            unmatched = sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"UNMATCHED\")\n",
    "            ambiguous = sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"AMBIGUOUS\")\n",
    "            print(f\"\\nContract Matching:\")\n",
    "            print(f\"  [OK] Matched: {matched}\")\n",
    "            print(f\"  [WARN] Unmatched: {unmatched}\")\n",
    "            print(f\"  [WARN] Ambiguous: {ambiguous}\")\n",
    "            \n",
    "            if len(results) > 0:\n",
    "                print(f\"\\nSuccess Rate: {approved/len(results)*100:.1f}%\")\n",
    "        else:\n",
    "            print(\"\\n[WARN] No invoices processed. Create sample documents first (Generate_Sample_Documents.ipynb)\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"[OK] Pipeline test complete!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error in invoice processing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Restore original logging level\n",
    "    logging.getLogger().setLevel(old_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Export Pipeline Results to Report\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Convert datetime objects to strings for JSON serialization\n",
    "def serialize_result(result):\n",
    "    \"\"\"Convert result dict to JSON-serializable format.\"\"\"\n",
    "    serialized = result.copy()\n",
    "    if \"invoice_data\" in serialized:\n",
    "        invoice_data = serialized[\"invoice_data\"].copy()\n",
    "        # Convert datetime objects to ISO format strings\n",
    "        for key in [\"invoice_date\", \"due_date\"]:\n",
    "            if key in invoice_data and invoice_data[key]:\n",
    "                if isinstance(invoice_data[key], datetime):\n",
    "                    invoice_data[key] = invoice_data[key].isoformat()\n",
    "        serialized[\"invoice_data\"] = invoice_data\n",
    "    return serialized\n",
    "\n",
    "\n",
    "# Save results to JSON for reporting\n",
    "# Read contracts info from extracted_rules.json (multi-contract format)\n",
    "try:\n",
    "    with open(\"extracted_rules.json\", \"r\") as f:\n",
    "        rules_data = json.load(f)\n",
    "        # Multi-contract format\n",
    "        if isinstance(rules_data, dict) and \"contracts\" in rules_data:\n",
    "            contracts_info = {\n",
    "                \"total_contracts\": len(rules_data.get(\"contracts\", [])),\n",
    "                \"contracts\": [\n",
    "                    {\n",
    "                        \"contract_id\": c.get(\"contract_id\", \"Unknown\"),\n",
    "                        \"contract_path\": c.get(\"contract_path\", \"Unknown\"),\n",
    "                        \"rules_count\": len(c.get(\"rules\", []))\n",
    "                    }\n",
    "                    for c in rules_data.get(\"contracts\", [])\n",
    "                ]\n",
    "            }\n",
    "            total_rules = sum(len(c.get(\"rules\", [])) for c in rules_data.get(\"contracts\", []))\n",
    "        else:\n",
    "            contracts_info = {\"total_contracts\": 0, \"contracts\": []}\n",
    "            total_rules = 0\n",
    "except (FileNotFoundError, json.JSONDecodeError, KeyError):\n",
    "    contracts_info = {\"total_contracts\": 0, \"contracts\": []}\n",
    "    total_rules = 0\n",
    "\n",
    "# Calculate contract matching statistics\n",
    "contract_matching_stats = {\n",
    "    \"matched\": sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"MATCHED\"),\n",
    "    \"unmatched\": sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"UNMATCHED\"),\n",
    "    \"ambiguous\": sum(1 for r in results if r.get(\"contract_match\", {}).get(\"status\") == \"AMBIGUOUS\"),\n",
    "    \"no_match_info\": sum(1 for r in results if not r.get(\"contract_match\"))\n",
    "}\n",
    "\n",
    "results_data = {\n",
    "    \"processed_at\": datetime.now().isoformat(),\n",
    "    \"contracts_info\": contracts_info,\n",
    "    \"total_rules_extracted\": total_rules,\n",
    "    \"contract_matching\": contract_matching_stats,\n",
    "    \"summary\": {\n",
    "        \"total\": len(results),\n",
    "        \"approved\": sum(1 for r in results if r[\"status\"] == \"APPROVED\"),\n",
    "        \"flagged\": sum(1 for r in results if r[\"status\"] == \"FLAGGED\"),\n",
    "        \"rejected\": sum(1 for r in results if r[\"status\"] == \"REJECTED\"),\n",
    "        \"errors\": sum(1 for r in results if r[\"status\"] == \"ERROR\"),\n",
    "        \"unmatched\": contract_matching_stats[\"unmatched\"],\n",
    "    },\n",
    "    \"results\": [serialize_result(r) for r in results],\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open(\"invoice_processing_results.json\", \"w\") as f:\n",
    "    json.dump(results_data, indent=2, fp=f)\n",
    "\n",
    "print(\"[OK] Results saved to: invoice_processing_results.json\")\n",
    "\n",
    "# Generate detailed report\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED PROCESSING REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {results_data['processed_at']}\")\n",
    "print(f\"Contracts Processed: {results_data['contracts_info']['total_contracts']}\")\n",
    "print(f\"Total Rules Extracted: {results_data['total_rules_extracted']}\")\n",
    "\n",
    "# Show contract matching statistics\n",
    "print(\"\\nCONTRACT MATCHING STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "matching = results_data[\"contract_matching\"]\n",
    "print(f\"Matched: {matching['matched']} ({matching['matched']/max(len(results),1)*100:.1f}%)\")\n",
    "print(f\"Unmatched: {matching['unmatched']} ({matching['unmatched']/max(len(results),1)*100:.1f}%)\")\n",
    "if matching['ambiguous'] > 0:\n",
    "    print(f\"Ambiguous: {matching['ambiguous']} ({matching['ambiguous']/max(len(results),1)*100:.1f}%)\")\n",
    "\n",
    "# Overall Statistics\n",
    "print(\"\\nOVERALL STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "summary = results_data[\"summary\"]\n",
    "print(f\"Total Invoices: {summary['total']}\")\n",
    "print(\n",
    "    f\"[OK] Approved: {summary['approved']} ({summary['approved']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[WARN] Flagged: {summary['flagged']} ({summary['flagged']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[FAIL] Rejected: {summary['rejected']} ({summary['rejected']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"[ERROR] Errors: {summary['errors']} ({summary['errors']/max(summary['total'],1)*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Invoice-by-Invoice Details\n",
    "print(\"\\nINVOICE DETAILS\")\n",
    "print(\"-\" * 80)\n",
    "for i, result in enumerate(results, 1):\n",
    "    status_icon = {\n",
    "        \"APPROVED\": \"[OK]\",\n",
    "        \"FLAGGED\": \"[WARN]\",\n",
    "        \"REJECTED\": \"[FAIL]\",\n",
    "        \"ERROR\": \"[ERROR]\",\n",
    "    }.get(result[\"status\"], \"[?]\")\n",
    "\n",
    "    print(f\"\\n{i}. {status_icon} {result['invoice_file'].split('/')[-1]}\")\n",
    "    print(f\"   Invoice #: {result.get('invoice_number', 'N/A')}\")\n",
    "    print(f\"   Status: {result['status']}\")\n",
    "    print(f\"   Action: {result['action']}\")\n",
    "    \n",
    "    # Show contract matching info\n",
    "    if result.get(\"contract_match\"):\n",
    "        match_info = result[\"contract_match\"]\n",
    "        if match_info.get(\"status\") == \"MATCHED\":\n",
    "            print(f\"   Contract: {result.get('contract_id', 'N/A')} (via {result.get('match_method', 'N/A')}, confidence: {result.get('match_confidence', 0):.2f})\")\n",
    "        elif match_info.get(\"status\") == \"UNMATCHED\":\n",
    "            print(f\"   Contract: UNMATCHED - Manual review required\")\n",
    "        elif match_info.get(\"status\") == \"AMBIGUOUS\":\n",
    "            print(f\"   Contract: AMBIGUOUS - Multiple matches found\")\n",
    "            if match_info.get(\"alternative_matches\"):\n",
    "                print(f\"      Alternative matches: {len(match_info['alternative_matches'])}\")\n",
    "    elif result.get(\"status\") == \"UNMATCHED\":\n",
    "        print(f\"   Contract: UNMATCHED - No matching contract found\")\n",
    "\n",
    "    if result.get(\"issues\"):\n",
    "        print(f\"   Issues: {'; '.join(result['issues'])}\")\n",
    "    if result.get(\"warnings\"):\n",
    "        print(f\"   Warnings: {'; '.join(result['warnings'])}\")\n",
    "\n",
    "# Most Common Issues\n",
    "print(\"\\nMOST COMMON ISSUES\")\n",
    "print(\"-\" * 80)\n",
    "all_issues = []\n",
    "for result in results:\n",
    "    all_issues.extend(result.get(\"issues\", []))\n",
    "\n",
    "if all_issues:\n",
    "    issue_counts = Counter(all_issues)\n",
    "    for issue, count in issue_counts.most_common(5):\n",
    "        print(f\"  \u2022 {issue}: {count} occurrence(s)\")\n",
    "else:\n",
    "    print(\"  [OK] No issues found\")\n",
    "\n",
    "# Most Common Warnings\n",
    "print(\"\\nMOST COMMON WARNINGS\")\n",
    "print(\"-\" * 80)\n",
    "all_warnings = []\n",
    "for result in results:\n",
    "    all_warnings.extend(result.get(\"warnings\", []))\n",
    "\n",
    "if all_warnings:\n",
    "    warning_counts = Counter(all_warnings)\n",
    "    for warning, count in warning_counts.most_common(5):\n",
    "        print(f\"  \u2022 {warning}: {count} occurrence(s)\")\n",
    "else:\n",
    "    print(\"  [OK] No warnings found\")\n",
    "\n",
    "# Extracted Rules Summary\n",
    "print(\"\\nEXTRACTED RULES (from RAG)\")\n",
    "print(\"-\" * 80)\n",
    "for i, rule in enumerate(rules, 1):\n",
    "    print(f\"\\n{i}. {rule['type'].upper()}\")\n",
    "    print(f\"   Priority: {rule['priority']}\")\n",
    "    print(f\"   Description: {rule['description'][:80]}...\")\n",
    "\n",
    "# Recommended Actions\n",
    "print(\"\\nRECOMMENDED ACTIONS\")\n",
    "print(\"-\" * 80)\n",
    "actions_listed = False\n",
    "if summary[\"rejected\"] > 0:\n",
    "    print(f\"  1. Review {summary['rejected']} rejected invoice(s) manually\")\n",
    "    actions_listed = True\n",
    "if summary[\"flagged\"] > 0:\n",
    "    print(f\"  2. Investigate {summary['flagged']} flagged invoice(s)\")\n",
    "    actions_listed = True\n",
    "if summary[\"errors\"] > 0:\n",
    "    print(f\"  3. Fix processing errors for {summary['errors']} invoice(s)\")\n",
    "    actions_listed = True\n",
    "if summary[\"approved\"] == summary[\"total\"]:\n",
    "    print(\"  [OK] All invoices approved - ready for payment processing\")\n",
    "    actions_listed = True\n",
    "\n",
    "if not actions_listed:\n",
    "    print(\"  [OK] No action required at this time\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[OK] Report generated successfully!\")\n",
    "print(f\"Full results saved to: invoice_processing_results.json\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479665e",
   "metadata": {},
   "source": [
    "### Benefits:\n",
    "\n",
    "1. **No API Keys Required** - Uses local Ollama models\n",
    "2. **Fast Processing** - FAISS vector store for efficient semantic search\n",
    "3. **Comprehensive Validation** - Checks multiple rule types (payment terms, PO requirements, penalties, etc.)\n",
    "4. **Detailed Reporting** - JSON output with validation status and issues\n",
    "5. **Cross-Platform** - Works on Windows, Mac, and Linux\n",
    "6. **OCR Support** - Handles scanned documents and images\n",
    "7. **Automatic Setup** - Auto-generates sample documents if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820502",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "### Step-by-Step Execution:\n",
    "\n",
    "1. **Setup** (run once):\n",
    "   - Cells 5-6: Install packages\n",
    "   - Cell 7: Import libraries\n",
    "   - Cell 8: Generate sample documents (if needed)\n",
    "   - Cell 9: Test Ollama connection\n",
    "\n",
    "2. **Extract Rules**:\n",
    "   - Cell 14: Initialize RAG agent\n",
    "   - Cell 15: Process contract and extract rules\n",
    "   - Cell 16: Save rules to JSON\n",
    "\n",
    "3. **Process Invoices** (choose one):\n",
    "   - **Option A (Recommended):** Cell 23 - Batch process all invoices\n",
    "   - **Option B (Testing):** Cell 21 \u2192 Cell 22 - Process single invoice for debugging\n",
    "\n",
    "4. **Complete Pipeline**:\n",
    "   - Cell 29: Run complete pipeline (extract rules + process invoices)\n",
    "   - Cell 30: Export results to report\n",
    "\n",
    "### Quick Start (Production):\n",
    "Run Cells 5-9, then Cell 29 (complete pipeline) for end-to-end processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32: Verification Cell - Check Current Rules\n",
    "print(\"=\" * 70)\n",
    "print(\"CURRENT PROCESSOR STATE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check if processor exists\n",
    "try:\n",
    "    print(f\"\\n[OK] Processor Status: Initialized\")\n",
    "    print(f\"Total Rules Loaded: {len(processor.rules)}\")\n",
    "    print(\n",
    "        f\"Payment Terms: Net {processor.payment_terms} days\"\n",
    "        if processor.payment_terms\n",
    "        else \"Payment Terms: Not specified\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nCurrently Loaded Rules:\")\n",
    "    for i, rule in enumerate(processor.rules, 1):\n",
    "        print(f\"\\n  {i}. [{rule['type'].upper()}]\")\n",
    "        print(f\"     ID: {rule['rule_id']}\")\n",
    "        print(f\"     Priority: {rule['priority']}\")\n",
    "        print(\n",
    "            f\"     Source: {'RAG-extracted' if rule.get('confidence') == 'medium' else 'Default'}\"\n",
    "        )\n",
    "        print(f\"     Description: {rule['description'][:70]}...\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"[OK] Ready to process invoices!\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Run Cell 22 to process a single invoice\")\n",
    "    print(\"  2. Run Cell 23 to batch process all invoices\")\n",
    "    print(\"  3. Run Cell 28 for complete pipeline with RAG extraction\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"[FAIL] Processor not initialized. Run Cell 21 first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}